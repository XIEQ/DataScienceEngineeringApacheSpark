<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>CS105x_lab1a_Spark_tutorial - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/databricks_guide/index.html","displayName":"Databricks Guide","icon":"question"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/sample_applications/index.html","displayName":"Application Examples","icon":"code"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/courses/index.html","displayName":"Training","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","maxCustomTags":5,"enableInstanceProfilesUIInJobs":false,"nodeInfo":{"node_types":[{"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"memory_mb":6144,"category":"Community Edition","num_cores":0.88,"support_ebs_volumes":false}],"default_node_type_id":"dev-tier-node"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableMaxConcurrentRuns":false,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-f29f42e40e335ab9c4b75537bfa39368d1920bca566185c93b29c62be4838bb3","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-cba800015d40393bcd17108fe69d54be3d8ea3833a0bd29b8372796ee14478f0","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-25bd25cbaa26191afd1a56f4670251cacf2b789b33bc2d0800c422da1d6e7254","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-385b531ec7a7bc69a10239924cb8232d6866e92211602f18f055262d0fce0e4c","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"r3.8xlarge":8,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":8,"memory-optimized":1,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"g2.2xlarge":2,"c4.8xlarge":4,"r3.xlarge":1,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":false,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.30","accountsLimit":3,"enableX509Authentication":false,"enableNotebookGitBranching":true,"local":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"disableLegacyDashboards":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"defaultSparkVersion":{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableClusterAclsByTier":false,"disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","enableOrgSwitcherUI":true,"clustersLimit":1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"useFixedStaticNotebookVersionForDevelopment":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableWorkspaceAclService":true,"docsDomain":"https://docs.cloud.databricks.com/","enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"cf91ba6cb552f29d2f374bda4b46622075c9146a-dirty","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":true,"showDevTierBetaVersion":true,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/A%20Gentle%20Introduction%20to%20Apache%20Spark%20on%20Databricks.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/Quick%20Start%20DataFrames.html","displayName":"Quick Start DataFrames","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/GSW%20Passing%20Analysis%20(new).html","displayName":"GSW Passing Analysis (new)","icon":"img/home/Python_icon.svg"}],"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"enableTerminal":false,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":true,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":1305471881461986,"name":"CS105x_lab1a_Spark_tutorial","language":"python","commands":[{"version":"CommandV1","origId":1305471881461988,"guid":"660c1741-dd88-4b93-84e4-6e061d37c9bd","subtype":"command","commandType":"auto","position":1.0,"command":"%md\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47113748971E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ecf0263c-ac3e-4bf3-a9bb-5afecd92fe1d"},{"version":"CommandV1","origId":1305471881461989,"guid":"0a76b98e-58f7-406a-8585-5cbc246ccec6","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n#![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n# **Spark Tutorial: Learning Apache Spark**\n\nThis tutorial will teach you how to use [Apache Spark](http://spark.apache.org/), a framework for large-scale data processing, within a notebook. Many traditional frameworks were designed to be run on a single computer.  However, many datasets today are too large to be stored on a single computer, and even when a dataset can be stored on one computer (such as the datasets in this tutorial), the dataset can often be processed much more quickly using multiple computers.\n\nSpark has efficient implementations of a number of transformations and actions that can be composed together to perform data processing and analysis.  Spark excels at distributing these operations across a cluster while abstracting away many of the underlying implementation details.  Spark has been designed with a focus on scalability and efficiency.  With Spark you can begin developing your solution on your laptop, using a small dataset, and then use that same code to process terabytes or even petabytes across a distributed cluster.\n\n**During this tutorial we will cover:**\n\n* *Part 1:* Basic notebook usage and [Python](https://docs.python.org/2/) integration\n* *Part 2:* An introduction to using [Apache Spark](https://spark.apache.org/) with the [PySpark SQL API](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark-sql-module) running in a notebook\n* *Part 3:* Using DataFrames and chaining together transformations and actions\n* *Part 4*: Python Lambda functions and User Defined Functions\n* *Part 5:* Additional DataFrame actions\n* *Part 6:* Additional DataFrame transformations\n* *Part 7:* Caching DataFrames and storage options\n* *Part 8:* Debugging Spark applications and lazy evaluation\n\nThe following transformations will be covered:\n* `select()`, `filter()`, `distinct()`, `dropDuplicates()`, `orderBy()`, `groupBy()`\n\nThe following actions will be covered:\n* `first()`, `take()`, `count()`, `collect()`, `show()`\n\nAlso covered:\n* `cache()`, `unpersist()`\n\nNote that, for reference, you can look up the details of these methods in the [Spark's PySpark SQL API](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark-sql-module)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489717E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"04789ef5-b20d-412b-9e88-9992eb861143"},{"version":"CommandV1","origId":1305471881461990,"guid":"3df35723-4e98-40be-bf31-3d274f5ca5f0","subtype":"command","commandType":"auto","position":3.0,"command":"%md\n## **Part 1: Basic notebook usage and [Python](https://docs.python.org/2/) integration **","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489752E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4e2d0e56-df52-4797-bc40-e78fe3fc0ddf"},{"version":"CommandV1","origId":1305471881461991,"guid":"7c97333b-5819-40c4-b8d3-58cf2d109901","subtype":"command","commandType":"auto","position":4.0,"command":"%md\n### (1a) Notebook usage\n\nA notebook is comprised of a linear sequence of cells.  These cells can contain either markdown or code, but we won't mix both in one cell.  When a markdown cell is executed it renders formatted text, images, and links just like HTML in a normal webpage.  The text you are reading right now is part of a markdown cell.  Python code cells allow you to execute arbitrary Python commands just like in any Python shell. Place your cursor inside the cell below, and press \"Shift\" + \"Enter\" to execute the code and advance to the next cell.  You can also press \"Ctrl\" + \"Enter\" to execute the code and remain in the cell.  These commands work the same in both markdown and code cells.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489779E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b75b2c4c-8a87-418b-856d-8aa49907653a"},{"version":"CommandV1","origId":1305471881461992,"guid":"b402ee83-0608-4ee9-a8b3-a7d8233a4715","subtype":"command","commandType":"auto","position":5.0,"command":"# This is a Python cell. You can run normal Python code here...\nprint 'The sum of 1 and 1 is {0}'.format(1+1)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">The sum of 1 and 1 is 2\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674090414E12,"submitTime":1.476674095588E12,"finishTime":1.476674090521E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9ae8d631-997f-435e-ad8b-131a293c599b"},{"version":"CommandV1","origId":1305471881461993,"guid":"5ec0c50a-d42b-47de-8e1c-ab104aaf762d","subtype":"command","commandType":"auto","position":6.0,"command":"# Here is another Python cell, this time with a variable (x) declaration and an if statement:\nx = 42\nif x > 40:\n    print 'The sum of 1 and 2 is {0}'.format(1+2)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">The sum of 1 and 2 is 3\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674093602E12,"submitTime":1.476674099076E12,"finishTime":1.476674093675E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"55deffae-bdac-4281-bddd-bd3a035eb334"},{"version":"CommandV1","origId":1305471881461994,"guid":"8aa152e7-89c7-493e-810d-73f6ac9016e2","subtype":"command","commandType":"auto","position":7.0,"command":"%md\n### (1b) Notebook state\n\nAs you work through a notebook it is important that you run all of the code cells.  The notebook is stateful, which means that variables and their values are retained until the notebook is detached (in Databricks) or the kernel is restarted (in Jupyter notebooks).  If you do not run all of the code cells as you proceed through the notebook, your variables will not be properly initialized and later code might fail.  You will also need to rerun any cells that you have modified in order for the changes to be available to other cells.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489848E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d4066747-4c64-45d5-b580-c2bebed7813b"},{"version":"CommandV1","origId":1305471881461995,"guid":"f85d520f-c458-488f-8fd7-637dc76a3b61","subtype":"command","commandType":"auto","position":8.0,"command":"# This cell relies on x being defined already.\n# If we didn't run the cells from part (1a) this code would fail.\nprint x * 2","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">84\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674096746E12,"submitTime":1.476674102219E12,"finishTime":1.476674096789E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"82662ced-5268-4b31-a23b-33c0f4062d9a"},{"version":"CommandV1","origId":1305471881461996,"guid":"cb44843e-5053-4895-a744-71f7b407040d","subtype":"command","commandType":"auto","position":9.0,"command":"%md\n### (1c) Library imports\n\nWe can import standard Python libraries ([modules](https://docs.python.org/2/tutorial/modules.html)) the usual way.  An `import` statement will import the specified module.  In this tutorial and future labs, we will provide any imports that are necessary.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489894E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0bf37d9e-333a-4dd0-91ba-33663c8a69f7"},{"version":"CommandV1","origId":1305471881461997,"guid":"d0101fe7-979a-4552-af1c-7a04f3973a0a","subtype":"command","commandType":"auto","position":10.0,"command":"# Import the regular expression library\nimport re\nm = re.search('(?<=abc)def', 'abcdef')\nm.group(0)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>&apos;def&apos;\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674100103E12,"submitTime":1.476674105575E12,"finishTime":1.476674100176E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"816fccc5-af6e-4190-b0cb-f24fd28ea664"},{"version":"CommandV1","origId":1305471881461998,"guid":"94e4cd66-3003-4f5e-b5d4-126229dd0014","subtype":"command","commandType":"auto","position":11.0,"command":"# Import the datetime library\nimport datetime\nprint 'This was last run on: {0}'.format(datetime.datetime.now())","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">This was last run on: 2016-10-17 03:15:04.326642\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674104275E12,"submitTime":1.476674109749E12,"finishTime":1.476674104349E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"68935334-3221-4c55-a261-dba104cd15c5"},{"version":"CommandV1","origId":1305471881461999,"guid":"9a470b31-6871-4c02-96a5-9c80b9e9253f","subtype":"command","commandType":"auto","position":12.0,"command":"%md\n##  **Part 2: An introduction to using [Apache Spark](https://spark.apache.org/) with the [PySpark SQL API](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark-sql-module) running in a notebook**","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489958E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a09b06cb-1c34-4ca0-b6b2-c1943f2e266e"},{"version":"CommandV1","origId":1305471881462000,"guid":"d1929d17-6f17-41bf-8ae9-73237b477786","subtype":"command","commandType":"auto","position":13.0,"command":"%md\n### Spark Context\n\nIn Spark, communication occurs between a driver and executors.  The driver has Spark jobs that it needs to run and these jobs are split into tasks that are submitted to the executors for completion.  The results from these tasks are delivered back to the driver.\n\nIn part 1, we saw that normal Python code can be executed via cells. When using Databricks this code gets executed in the Spark driver's Java Virtual Machine (JVM) and not in an executor's JVM, and when using an Jupyter notebook it is executed within the kernel associated with the notebook. Since no Spark functionality is actually being used, no tasks are launched on the executors.\n\nIn order to use Spark and its DataFrame API we will need to use a `SQLContext`.  When running Spark, you start a new Spark application by creating a [SparkContext](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext). You can then create a [SQLContext](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SQLContext) from the `SparkContext`. When the `SparkContext` is created, it asks the master for some cores to use to do work.  The master sets these cores aside just for you; they won't be used for other applications. When using Databricks, both a `SparkContext` and a `SQLContext` are created for you automatically. `sc` is your `SparkContext`, and `sqlContext` is your `SQLContext`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137489988E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"967a4e00-73c9-4274-8dad-7c7f8ccd0110"},{"version":"CommandV1","origId":1305471881462001,"guid":"0012ed08-591c-4725-ad23-03fa242f1244","subtype":"command","commandType":"auto","position":14.0,"command":"%md\n### (2a) Example Cluster\nThe diagram shows an example cluster, where the slots allocated for an application are outlined in purple. (Note: We're using the term _slots_ here to indicate threads available to perform parallel work for Spark.\nSpark documentation often refers to these threads as _cores_, which is a confusing term, as the number of slots available on a particular machine does not necessarily have any relationship to the number of physical CPU\ncores on that machine.)\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/cs105x/diagram-2a.png\" style=\"height: 800px;float: right\"/>\n\nYou can view the details of your Spark application in the Spark web UI.  The web UI is accessible in Databricks by going to \"Clusters\" and then clicking on the \"Spark UI\" link for your cluster.  In the web UI, under the \"Jobs\" tab, you can see a list of jobs that have been scheduled or run.  It's likely there isn't any thing interesting here yet because we haven't run any jobs, but we'll return to this page later.\n\nAt a high level, every Spark application consists of a driver program that launches various parallel operations on executor Java Virtual Machines (JVMs) running either in a cluster or locally on the same machine. In Databricks, \"Databricks Shell\" is the driver program.  When running locally, `pyspark` is the driver program. In all cases, this driver program contains the main loop for the program and creates distributed datasets on the cluster, then applies operations (transformations & actions) to those datasets.\nDriver programs access Spark through a SparkContext object, which represents a connection to a computing cluster. A Spark SQL context object (`sqlContext`) is the main entry point for Spark DataFrame and SQL functionality. A `SQLContext` can be used to create DataFrames, which allows you to direct the operations on your data.\n\nTry printing out `sqlContext` to see its type.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490014E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1a4280bd-42d0-4c7f-a87a-9ef9362abe9c"},{"version":"CommandV1","origId":1305471881462002,"guid":"9e5eace7-6821-48d7-bd43-ab2161a38d69","subtype":"command","commandType":"auto","position":15.0,"command":"# Display the type of the Spark sqlContext\ntype(sqlContext)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>pyspark.sql.context.HiveContext\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674112444E12,"submitTime":1.476674117918E12,"finishTime":1.476674112517E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"406096ed-fa8a-4edb-8715-3c564edc6009"},{"version":"CommandV1","origId":1305471881462003,"guid":"0df32653-1148-4c0b-953e-0a5aa6b09db0","subtype":"command","commandType":"auto","position":16.0,"command":"%md\nNote that the type is `HiveContext`. This means we're working with a version of Spark that has Hive support. Compiling Spark with Hive support is a good idea, even if you don't have a Hive metastore. As the\n[Spark Programming Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html#starting-point-sqlcontext) states, a `HiveContext` \"provides a superset of the functionality provided by the basic `SQLContext`. Additional features include the ability to write queries using the more complete HiveQL parser, access to Hive UDFs [user-defined functions], and the ability to read data from Hive tables. To use a `HiveContext`, you do not need to have an existing Hive setup, and all of the data sources available to a `SQLContext` are still available.\"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490063E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1b53f199-c356-4746-85ae-f7886729667c"},{"version":"CommandV1","origId":1305471881462004,"guid":"f6bcca7c-7795-4f35-8e2c-07391b375805","subtype":"command","commandType":"auto","position":17.0,"command":"%md\n### (2b) SparkContext attributes\n\nYou can use Python's [dir()](https://docs.python.org/2/library/functions.html?highlight=dir#dir) function to get a list of all the attributes (including methods) accessible through the `sqlContext` object.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490091E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"df2e5b06-efe6-4a35-8e04-010fe6ea7280"},{"version":"CommandV1","origId":1305471881462005,"guid":"83095cdf-fd17-4261-b87e-1072b9e49546","subtype":"command","commandType":"auto","position":18.0,"command":"# List sqlContext's attributes\ndir(sqlContext)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n[&apos;__class__&apos;,\n &apos;__delattr__&apos;,\n &apos;__dict__&apos;,\n &apos;__doc__&apos;,\n &apos;__format__&apos;,\n &apos;__getattribute__&apos;,\n &apos;__hash__&apos;,\n &apos;__init__&apos;,\n &apos;__module__&apos;,\n &apos;__new__&apos;,\n &apos;__reduce__&apos;,\n &apos;__reduce_ex__&apos;,\n &apos;__repr__&apos;,\n &apos;__setattr__&apos;,\n &apos;__sizeof__&apos;,\n &apos;__str__&apos;,\n &apos;__subclasshook__&apos;,\n &apos;__weakref__&apos;,\n &apos;_createFromLocal&apos;,\n &apos;_createFromRDD&apos;,\n &apos;_get_hive_ctx&apos;,\n &apos;_inferSchema&apos;,\n &apos;_inferSchemaFromList&apos;,\n &apos;_instantiatedContext&apos;,\n &apos;_jsc&apos;,\n &apos;_jvm&apos;,\n &apos;_sc&apos;,\n &apos;_scala_HiveContext&apos;,\n &apos;_scala_SQLContext&apos;,\n &apos;_ssql_ctx&apos;,\n &apos;applySchema&apos;,\n &apos;cacheTable&apos;,\n &apos;clearCache&apos;,\n &apos;createDataFrame&apos;,\n &apos;createExternalTable&apos;,\n &apos;dropTempTable&apos;,\n &apos;getConf&apos;,\n &apos;getOrCreate&apos;,\n &apos;inferSchema&apos;,\n &apos;jsonFile&apos;,\n &apos;jsonRDD&apos;,\n &apos;load&apos;,\n &apos;newSession&apos;,\n &apos;parquetFile&apos;,\n &apos;range&apos;,\n &apos;read&apos;,\n &apos;refreshTable&apos;,\n &apos;registerDataFrameAsTable&apos;,\n &apos;registerFunction&apos;,\n &apos;setConf&apos;,\n &apos;sql&apos;,\n &apos;table&apos;,\n &apos;tableNames&apos;,\n &apos;tables&apos;,\n &apos;udf&apos;,\n &apos;uncacheTable&apos;]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674119006E12,"submitTime":1.47667412448E12,"finishTime":1.476674119033E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"39cdc70d-15f4-4b04-b3c3-df5bbf2cb38c"},{"version":"CommandV1","origId":1305471881462006,"guid":"31cb1826-d9c4-45fa-97e4-a8cf8c54a64f","subtype":"command","commandType":"auto","position":19.0,"command":"%md\n### (2c) Getting help\n\nAlternatively, you can use Python's [help()](https://docs.python.org/2/library/functions.html?highlight=help#help) function to get an easier to read list of all the attributes, including examples, that the `sqlContext` object has.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490135E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c2b0a543-c793-42a7-9de5-da554a5a7c87"},{"version":"CommandV1","origId":1305471881462007,"guid":"dc2c2b01-9a33-4f83-bda7-516c49fdc6d9","subtype":"command","commandType":"auto","position":20.0,"command":"# Use help to obtain more detailed information\nhelp(sqlContext)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Help on HiveContext in module pyspark.sql.context object:\n\nclass HiveContext(SQLContext)\n |  A variant of Spark SQL that integrates with data stored in Hive.\n |  \n |  Configuration for Hive is read from &#96;&#96;hive-site.xml&#96;&#96; on the classpath.\n |  It supports running both SQL and HiveQL commands.\n |  \n |  :param sparkContext: The SparkContext to wrap.\n |  :param hiveContext: An optional JVM Scala HiveContext. If set, we do not instantiate a new\n |      :class:&#96;HiveContext&#96; in the JVM, instead we make all calls to this object.\n |  \n |  Method resolution order:\n |      HiveContext\n |      SQLContext\n |      __builtin__.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, sparkContext, hiveContext=None)\n |  \n |  refreshTable(self, tableName)\n |      Invalidate and refresh all the cached the metadata of the given\n |      table. For performance reasons, Spark SQL or the external data source\n |      library it uses might cache certain metadata about a table, such as the\n |      location of blocks. When those change outside of Spark SQL, users should\n |      call this function to invalidate the cache.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from SQLContext:\n |  \n |  applySchema(self, rdd, schema)\n |      .. note:: Deprecated in 1.3, use :func:&#96;createDataFrame&#96; instead.\n |  \n |  cacheTable(self, tableName)\n |      Caches the specified table in-memory.\n |      \n |      .. versionadded:: 1.0\n |  \n |  clearCache(self)\n |      Removes all cached tables from the in-memory cache.\n |      \n |      .. versionadded:: 1.3\n |  \n |  createDataFrame(self, data, schema=None, samplingRatio=None)\n |      Creates a :class:&#96;DataFrame&#96; from an :class:&#96;RDD&#96; of :class:&#96;tuple&#96;/:class:&#96;list&#96;,\n |      list or :class:&#96;pandas.DataFrame&#96;.\n |      \n |      When &#96;&#96;schema&#96;&#96; is a list of column names, the type of each column\n |      will be inferred from &#96;&#96;data&#96;&#96;.\n |      \n |      When &#96;&#96;schema&#96;&#96; is &#96;&#96;None&#96;&#96;, it will try to infer the schema (column names and types)\n |      from &#96;&#96;data&#96;&#96;, which should be an RDD of :class:&#96;Row&#96;,\n |      or :class:&#96;namedtuple&#96;, or :class:&#96;dict&#96;.\n |      \n |      If schema inference is needed, &#96;&#96;samplingRatio&#96;&#96; is used to determined the ratio of\n |      rows used for schema inference. The first row will be used if &#96;&#96;samplingRatio&#96;&#96; is &#96;&#96;None&#96;&#96;.\n |      \n |      :param data: an RDD of :class:&#96;Row&#96;/:class:&#96;tuple&#96;/:class:&#96;list&#96;/:class:&#96;dict&#96;,\n |          :class:&#96;list&#96;, or :class:&#96;pandas.DataFrame&#96;.\n |      :param schema: a :class:&#96;StructType&#96; or list of column names. default None.\n |      :param samplingRatio: the sample ratio of rows used for inferring\n |      :return: :class:&#96;DataFrame&#96;\n |      \n |      &gt;&gt;&gt; l = [(&apos;Alice&apos;, 1)]\n |      &gt;&gt;&gt; sqlContext.createDataFrame(l).collect()\n |      [Row(_1=u&apos;Alice&apos;, _2=1)]\n |      &gt;&gt;&gt; sqlContext.createDataFrame(l, [&apos;name&apos;, &apos;age&apos;]).collect()\n |      [Row(name=u&apos;Alice&apos;, age=1)]\n |      \n |      &gt;&gt;&gt; d = [{&apos;name&apos;: &apos;Alice&apos;, &apos;age&apos;: 1}]\n |      &gt;&gt;&gt; sqlContext.createDataFrame(d).collect()\n |      [Row(age=1, name=u&apos;Alice&apos;)]\n |      \n |      &gt;&gt;&gt; rdd = sc.parallelize(l)\n |      &gt;&gt;&gt; sqlContext.createDataFrame(rdd).collect()\n |      [Row(_1=u&apos;Alice&apos;, _2=1)]\n |      &gt;&gt;&gt; df = sqlContext.createDataFrame(rdd, [&apos;name&apos;, &apos;age&apos;])\n |      &gt;&gt;&gt; df.collect()\n |      [Row(name=u&apos;Alice&apos;, age=1)]\n |      \n |      &gt;&gt;&gt; from pyspark.sql import Row\n |      &gt;&gt;&gt; Person = Row(&apos;name&apos;, &apos;age&apos;)\n |      &gt;&gt;&gt; person = rdd.map(lambda r: Person(*r))\n |      &gt;&gt;&gt; df2 = sqlContext.createDataFrame(person)\n |      &gt;&gt;&gt; df2.collect()\n |      [Row(name=u&apos;Alice&apos;, age=1)]\n |      \n |      &gt;&gt;&gt; from pyspark.sql.types import *\n |      &gt;&gt;&gt; schema = StructType([\n |      ...    StructField(&quot;name&quot;, StringType(), True),\n |      ...    StructField(&quot;age&quot;, IntegerType(), True)])\n |      &gt;&gt;&gt; df3 = sqlContext.createDataFrame(rdd, schema)\n |      &gt;&gt;&gt; df3.collect()\n |      [Row(name=u&apos;Alice&apos;, age=1)]\n |      \n |      &gt;&gt;&gt; sqlContext.createDataFrame(df.toPandas()).collect()  # doctest: +SKIP\n |      [Row(name=u&apos;Alice&apos;, age=1)]\n |      &gt;&gt;&gt; sqlContext.createDataFrame(pandas.DataFrame([[1, 2]])).collect()  # doctest: +SKIP\n |      [Row(0=1, 1=2)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  createExternalTable(self, tableName, path=None, source=None, schema=None, **options)\n |      Creates an external table based on the dataset in a data source.\n |      \n |      It returns the DataFrame associated with the external table.\n |      \n |      The data source is specified by the &#96;&#96;source&#96;&#96; and a set of &#96;&#96;options&#96;&#96;.\n |      If &#96;&#96;source&#96;&#96; is not specified, the default data source configured by\n |      &#96;&#96;spark.sql.sources.default&#96;&#96; will be used.\n |      \n |      Optionally, a schema can be provided as the schema of the returned :class:&#96;DataFrame&#96; and\n |      created external table.\n |      \n |      :return: :class:&#96;DataFrame&#96;\n |      \n |      .. versionadded:: 1.3\n |  \n |  dropTempTable(self, tableName)\n |      Remove the temp table from catalog.\n |      \n |      &gt;&gt;&gt; sqlContext.registerDataFrameAsTable(df, &quot;table1&quot;)\n |      &gt;&gt;&gt; sqlContext.dropTempTable(&quot;table1&quot;)\n |      \n |      .. versionadded:: 1.6\n |  \n |  getConf(self, key, defaultValue)\n |      Returns the value of Spark SQL configuration property for the given key.\n |      \n |      If the key is not set, returns defaultValue.\n |      \n |      .. versionadded:: 1.3\n |  \n |  inferSchema(self, rdd, samplingRatio=None)\n |      .. note:: Deprecated in 1.3, use :func:&#96;createDataFrame&#96; instead.\n |  \n |  jsonFile(self, path, schema=None, samplingRatio=1.0)\n |      Loads a text file storing one JSON object per line as a :class:&#96;DataFrame&#96;.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameReader.json&#96; instead.\n |      \n |      &gt;&gt;&gt; sqlContext.jsonFile(&apos;python/test_support/sql/people.json&apos;).dtypes\n |      [(&apos;age&apos;, &apos;bigint&apos;), (&apos;name&apos;, &apos;string&apos;)]\n |  \n |  jsonRDD(self, rdd, schema=None, samplingRatio=1.0)\n |      Loads an RDD storing one JSON object per string as a :class:&#96;DataFrame&#96;.\n |      \n |      If the schema is provided, applies the given schema to this JSON dataset.\n |      Otherwise, it samples the dataset with ratio &#96;&#96;samplingRatio&#96;&#96; to determine the schema.\n |      \n |      &gt;&gt;&gt; df1 = sqlContext.jsonRDD(json)\n |      &gt;&gt;&gt; df1.first()\n |      Row(field1=1, field2=u&apos;row1&apos;, field3=Row(field4=11, field5=None), field6=None)\n |      \n |      &gt;&gt;&gt; df2 = sqlContext.jsonRDD(json, df1.schema)\n |      &gt;&gt;&gt; df2.first()\n |      Row(field1=1, field2=u&apos;row1&apos;, field3=Row(field4=11, field5=None), field6=None)\n |      \n |      &gt;&gt;&gt; from pyspark.sql.types import *\n |      &gt;&gt;&gt; schema = StructType([\n |      ...     StructField(&quot;field2&quot;, StringType()),\n |      ...     StructField(&quot;field3&quot;,\n |      ...                 StructType([StructField(&quot;field5&quot;, ArrayType(IntegerType()))]))\n |      ... ])\n |      &gt;&gt;&gt; df3 = sqlContext.jsonRDD(json, schema)\n |      &gt;&gt;&gt; df3.first()\n |      Row(field2=u&apos;row1&apos;, field3=Row(field5=None))\n |      \n |      .. versionadded:: 1.0\n |  \n |  load(self, path=None, source=None, schema=None, **options)\n |      Returns the dataset in a data source as a :class:&#96;DataFrame&#96;.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameReader.load&#96; instead.\n |  \n |  newSession(self)\n |      Returns a new SQLContext as new session, that has separate SQLConf,\n |      registered temporary tables and UDFs, but shared SparkContext and\n |      table cache.\n |      \n |      .. versionadded:: 1.6\n |  \n |  parquetFile(self, *paths)\n |      Loads a Parquet file, returning the result as a :class:&#96;DataFrame&#96;.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameReader.parquet&#96; instead.\n |      \n |      &gt;&gt;&gt; sqlContext.parquetFile(&apos;python/test_support/sql/parquet_partitioned&apos;).dtypes\n |      [(&apos;name&apos;, &apos;string&apos;), (&apos;year&apos;, &apos;int&apos;), (&apos;month&apos;, &apos;int&apos;), (&apos;day&apos;, &apos;int&apos;)]\n |  \n |  range(self, start, end=None, step=1, numPartitions=None)\n |      Create a :class:&#96;DataFrame&#96; with single LongType column named &#96;id&#96;,\n |      containing elements in a range from &#96;start&#96; to &#96;end&#96; (exclusive) with\n |      step value &#96;step&#96;.\n |      \n |      :param start: the start value\n |      :param end: the end value (exclusive)\n |      :param step: the incremental step (default: 1)\n |      :param numPartitions: the number of partitions of the DataFrame\n |      :return: :class:&#96;DataFrame&#96;\n |      \n |      &gt;&gt;&gt; sqlContext.range(1, 7, 2).collect()\n |      [Row(id=1), Row(id=3), Row(id=5)]\n |      \n |      If only one argument is specified, it will be used as the end value.\n |      \n |      &gt;&gt;&gt; sqlContext.range(3).collect()\n |      [Row(id=0), Row(id=1), Row(id=2)]\n |      \n |      .. versionadded:: 1.4\n |  \n |  registerDataFrameAsTable(self, df, tableName)\n |      Registers the given :class:&#96;DataFrame&#96; as a temporary table in the catalog.\n |      \n |      Temporary tables exist only during the lifetime of this instance of :class:&#96;SQLContext&#96;.\n |      \n |      &gt;&gt;&gt; sqlContext.registerDataFrameAsTable(df, &quot;table1&quot;)\n |      \n |      .. versionadded:: 1.3\n |  \n |  registerFunction(self, name, f, returnType=StringType)\n |      Registers a python function (including lambda function) as a UDF\n |      so it can be used in SQL statements.\n |      \n |      In addition to a name and the function itself, the return type can be optionally specified.\n |      When the return type is not given it default to a string and conversion will automatically\n |      be done.  For any other return type, the produced object must match the specified type.\n |      \n |      :param name: name of the UDF\n |      :param f: python function\n |      :param returnType: a :class:&#96;DataType&#96; object\n |      \n |      &gt;&gt;&gt; sqlContext.registerFunction(&quot;stringLengthString&quot;, lambda x: len(x))\n |      &gt;&gt;&gt; sqlContext.sql(&quot;SELECT stringLengthString(&apos;test&apos;)&quot;).collect()\n |      [Row(_c0=u&apos;4&apos;)]\n |      \n |      &gt;&gt;&gt; from pyspark.sql.types import IntegerType\n |      &gt;&gt;&gt; sqlContext.registerFunction(&quot;stringLengthInt&quot;, lambda x: len(x), IntegerType())\n |      &gt;&gt;&gt; sqlContext.sql(&quot;SELECT stringLengthInt(&apos;test&apos;)&quot;).collect()\n |      [Row(_c0=4)]\n |      \n |      &gt;&gt;&gt; from pyspark.sql.types import IntegerType\n |      &gt;&gt;&gt; sqlContext.udf.register(&quot;stringLengthInt&quot;, lambda x: len(x), IntegerType())\n |      &gt;&gt;&gt; sqlContext.sql(&quot;SELECT stringLengthInt(&apos;test&apos;)&quot;).collect()\n |      [Row(_c0=4)]\n |      \n |      .. versionadded:: 1.2\n |  \n |  setConf(self, key, value)\n |      Sets the given Spark SQL configuration property.\n |      \n |      .. versionadded:: 1.3\n |  \n |  sql(self, sqlQuery)\n |      Returns a :class:&#96;DataFrame&#96; representing the result of the given query.\n |      \n |      :return: :class:&#96;DataFrame&#96;\n |      \n |      &gt;&gt;&gt; sqlContext.registerDataFrameAsTable(df, &quot;table1&quot;)\n |      &gt;&gt;&gt; df2 = sqlContext.sql(&quot;SELECT field1 AS f1, field2 as f2 from table1&quot;)\n |      &gt;&gt;&gt; df2.collect()\n |      [Row(f1=1, f2=u&apos;row1&apos;), Row(f1=2, f2=u&apos;row2&apos;), Row(f1=3, f2=u&apos;row3&apos;)]\n |      \n |      .. versionadded:: 1.0\n |  \n |  table(self, tableName)\n |      Returns the specified table as a :class:&#96;DataFrame&#96;.\n |      \n |      :return: :class:&#96;DataFrame&#96;\n |      \n |      &gt;&gt;&gt; sqlContext.registerDataFrameAsTable(df, &quot;table1&quot;)\n |      &gt;&gt;&gt; df2 = sqlContext.table(&quot;table1&quot;)\n |      &gt;&gt;&gt; sorted(df.collect()) == sorted(df2.collect())\n |      True\n |      \n |      .. versionadded:: 1.0\n |  \n |  tableNames(self, dbName=None)\n |      Returns a list of names of tables in the database &#96;&#96;dbName&#96;&#96;.\n |      \n |      :param dbName: string, name of the database to use. Default to the current database.\n |      :return: list of table names, in string\n |      \n |      &gt;&gt;&gt; sqlContext.registerDataFrameAsTable(df, &quot;table1&quot;)\n |      &gt;&gt;&gt; &quot;table1&quot; in sqlContext.tableNames()\n |      True\n |      &gt;&gt;&gt; &quot;table1&quot; in sqlContext.tableNames(&quot;db&quot;)\n |      True\n |      \n |      .. versionadded:: 1.3\n |  \n |  tables(self, dbName=None)\n |      Returns a :class:&#96;DataFrame&#96; containing names of tables in the given database.\n |      \n |      If &#96;&#96;dbName&#96;&#96; is not specified, the current database will be used.\n |      \n |      The returned DataFrame has two columns: &#96;&#96;tableName&#96;&#96; and &#96;&#96;isTemporary&#96;&#96;\n |      (a column with :class:&#96;BooleanType&#96; indicating if a table is a temporary one or not).\n |      \n |      :param dbName: string, name of the database to use.\n |      :return: :class:&#96;DataFrame&#96;\n |      \n |      &gt;&gt;&gt; sqlContext.registerDataFrameAsTable(df, &quot;table1&quot;)\n |      &gt;&gt;&gt; df2 = sqlContext.tables()\n |      &gt;&gt;&gt; df2.filter(&quot;tableName = &apos;table1&apos;&quot;).first()\n |      Row(tableName=u&apos;table1&apos;, isTemporary=True)\n |      \n |      .. versionadded:: 1.3\n |  \n |  uncacheTable(self, tableName)\n |      Removes the specified table from the in-memory cache.\n |      \n |      .. versionadded:: 1.0\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from SQLContext:\n |  \n |  getOrCreate(cls, sc) from __builtin__.type\n |      Get the existing SQLContext or create a new one with given SparkContext.\n |      \n |      :param sc: SparkContext\n |      \n |      .. versionadded:: 1.6\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from SQLContext:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  read\n |      Returns a :class:&#96;DataFrameReader&#96; that can be used to read data\n |      in as a :class:&#96;DataFrame&#96;.\n |      \n |      :return: :class:&#96;DataFrameReader&#96;\n |      \n |      .. versionadded:: 1.4\n |  \n |  udf\n |      Returns a :class:&#96;UDFRegistration&#96; for UDF registration.\n |      \n |      :return: :class:&#96;UDFRegistration&#96;\n |      \n |      .. versionadded:: 1.3.1\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.471137492226E12,"submitTime":1.471137490159E12,"finishTime":1.47113749227E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0783dcc7-d3d8-45d8-affd-4bb056c90c2f"},{"version":"CommandV1","origId":1305471881462008,"guid":"696512dd-9618-497f-a1b0-e312ed71e841","subtype":"command","commandType":"auto","position":21.0,"command":"%md\nOutside of `pyspark` or a notebook, `SQLContext` is created from the lower-level `SparkContext`, which is usually used to create Resilient Distributed Datasets (RDDs). An RDD is the way Spark actually represents data internally; DataFrames are actually implemented in terms of RDDs.\n\nWhile you can interact directly with RDDs, DataFrames are preferred. They're generally faster, and they perform the same no matter what language (Python, R, Scala or Java) you use with Spark.\n\nIn this course, we'll be using DataFrames, so we won't be interacting directly with the Spark Context object very much. However, it's worth knowing that inside `pyspark` or a notebook, you already have an existing `SparkContext` in the `sc` variable. One simple thing we can do with `sc` is check the version of Spark we're using:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490178E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7c536835-2da5-435a-8c5e-93c121f2ed86"},{"version":"CommandV1","origId":1305471881462009,"guid":"dd166d4b-986a-44e8-a576-8427896e168a","subtype":"command","commandType":"auto","position":22.0,"command":"# After reading the help we've decided we want to use sc.version to see what version of Spark we are running\nsc.version","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">8</span><span class=\"ansired\">]: </span>u&apos;1.6.2&apos;\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674122915E12,"submitTime":1.476674128371E12,"finishTime":1.476674122957E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"62c0e90b-c9a8-48fd-bd13-969589384b8a"},{"version":"CommandV1","origId":1305471881462010,"guid":"e1d475a3-9740-4f69-a61a-d4490c30a319","subtype":"command","commandType":"auto","position":23.0,"command":"# Help can be used on any Python object\nhelp(map)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Help on built-in function map in module __builtin__:\n\nmap(...)\n    map(function, sequence[, sequence, ...]) -&gt; list\n    \n    Return a list of the results of applying the function to the items of\n    the argument sequence(s).  If more than one sequence is given, the\n    function is called with an argument list consisting of the corresponding\n    item of each sequence, substituting None for missing values when not all\n    sequences have the same length.  If the function is None, return a list of\n    the items of the sequence (or a list of tuples if more than one sequence).\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674124173E12,"submitTime":1.476674129649E12,"finishTime":1.476674124246E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ee601b93-0f79-4ed8-b1d8-2c86a2e083e8"},{"version":"CommandV1","origId":1305471881462011,"guid":"325c7092-c9da-4019-a225-99356ab217b5","subtype":"command","commandType":"auto","position":24.0,"command":"%md\n## **Part 3: Using DataFrames and chaining together transformations and actions**","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490242E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0459efbe-ea9e-4368-b5bd-263ceb1fe7c1"},{"version":"CommandV1","origId":1305471881462012,"guid":"56d01ea1-1622-45be-af3f-cebc41edec8e","subtype":"command","commandType":"auto","position":25.0,"command":"%md\n### Working with your first DataFrames\n\nIn Spark, we first create a base [DataFrame](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame). We can then apply one or more transformations to that base DataFrame. *A DataFrame is immutable, so once it is created, it cannot be changed.* As a result, each transformation creates a new DataFrame. Finally, we can apply one or more actions to the DataFrames.\n\n> Note that Spark uses lazy evaluation, so transformations are not actually executed until an action occurs.\n\nWe will perform several exercises to obtain a better understanding of DataFrames:\n* Create a Python collection of 10,000 integers\n* Create a Spark DataFrame from that collection\n* Subtract one from each value using `map`\n* Perform action `collect` to view results\n* Perform action `count` to view counts\n* Apply transformation `filter` and view results with `collect`\n* Learn about lambda functions\n* Explore how lazy evaluation works and the debugging challenges that it introduces\n\nA DataFrame consists of a series of `Row` objects; each `Row` object has a set of named columns. You can think of a DataFrame as modeling a table, though the data source being processed does not have to be a table.\n\nMore formally, a DataFrame must have a _schema_, which means it must consist of columns, each of which has a _name_ and a _type_. Some data sources have schemas built into them. Examples include RDBMS databases, Parquet files, and NoSQL databases like Cassandra. Other data sources don't have computer-readable schemas, but you can often apply a schema programmatically.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490276E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c53f55ed-6a25-485e-94fb-3603106fbb13"},{"version":"CommandV1","origId":1305471881462013,"guid":"8c1dd65c-3e07-4801-8818-653a419ec3c3","subtype":"command","commandType":"auto","position":26.0,"command":"%md\n### (3a) Create a Python collection of 10,000 people\n\nWe will use a third-party Python testing library called [fake-factory](https://pypi.python.org/pypi/fake-factory/0.5.3) to create a collection of fake person records.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490303E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f0c28cc6-acf1-4f35-85d9-43524c9fe191"},{"version":"CommandV1","origId":1305471881462014,"guid":"ee167134-a09e-4345-9311-c662fe2201e5","subtype":"command","commandType":"auto","position":27.0,"command":"from faker import Factory\nfake = Factory.create()\nfake.seed(4321)\nprint type(fake)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">&lt;class &apos;faker.generator.Generator&apos;&gt;\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674127583E12,"submitTime":1.47667413304E12,"finishTime":1.476674127705E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"31799c9f-040e-471f-819a-3842068789c5"},{"version":"CommandV1","origId":1305471881462015,"guid":"3497e1eb-b230-4b77-b9d3-ef42446aecea","subtype":"command","commandType":"auto","position":28.0,"command":"%md\nWe're going to use this factory to create a collection of randomly generated people records. In the next section, we'll turn that collection into a DataFrame. We'll use the Spark `Row` class,\nbecause that will help us define the Spark DataFrame schema. There are other ways to define schemas, though; see\nthe Spark Programming Guide's discussion of [schema inference](http://spark.apache.org/docs/latest/sql-programming-guide.html#inferring-the-schema-using-reflection) for more information. (For instance,\nwe could also use a Python `namedtuple`.)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490354E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"77f65754-4e2d-41e0-ad16-0039078a31f7"},{"version":"CommandV1","origId":1305471881462016,"guid":"51ff8436-d191-4c62-9862-10a475bfd484","subtype":"command","commandType":"auto","position":29.0,"command":"# Each entry consists of last_name, first_name, ssn, job, and age (at least 1)\nfrom pyspark.sql import Row\ndef fake_entry():\n  name = fake.name().split()\n  return (name[1], name[0], fake.ssn(), fake.job(), abs(2016 - fake.date_time().year) + 1)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674131638E12,"submitTime":1.476674137114E12,"finishTime":1.47667413168E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"77338024-29e0-48bc-9c07-3642c4aaf5e1"},{"version":"CommandV1","origId":1305471881462017,"guid":"9c7db8d2-5e7a-403a-85f2-34bc5802ad2f","subtype":"command","commandType":"auto","position":30.0,"command":"# Create a helper function to call a function repeatedly\ndef repeat(times, func, *args, **kwargs):\n    for _ in xrange(times):\n        yield func(*args, **kwargs)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674133396E12,"submitTime":1.476674138854E12,"finishTime":1.476674133469E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4e4008e9-d506-4f4f-98a9-9af6bf455381"},{"version":"CommandV1","origId":1305471881462018,"guid":"7dd03bd1-e3de-4657-8260-ec6bbcba08b1","subtype":"command","commandType":"auto","position":31.0,"command":"data = list(repeat(10000, fake_entry))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674350382E12,"submitTime":1.476674355863E12,"finishTime":1.476674360857E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"422241f6-99b9-43af-a9bf-5d8d8c9e64d3"},{"version":"CommandV1","origId":1305471881462019,"guid":"e25ede3a-13b0-436e-9a12-64e044ba638f","subtype":"command","commandType":"auto","position":32.0,"command":"%md\n`data` is just a normal Python list, containing Python tuples objects. Let's look at the first item in the list:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490437E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"eafeb15d-4beb-40b1-9d1c-c445edbcbfc8"},{"version":"CommandV1","origId":1305471881462020,"guid":"f6bc5990-87a9-46b1-800d-132dea26ca1c","subtype":"command","commandType":"auto","position":33.0,"command":"data[0]","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">28</span><span class=\"ansired\">]: </span>\n(u&apos;Curtis&apos;,\n u&apos;Kristen&apos;,\n u&apos;688-09-1018&apos;,\n &apos;Administrator, charities/voluntary organisations&apos;,\n 8)\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.47667438148E12,"submitTime":1.476674386961E12,"finishTime":1.476674381553E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"87ce91a9-b9b2-4733-857e-fb83f63b96b5"},{"version":"CommandV1","origId":1305471881462021,"guid":"c06fb1eb-4451-4eb9-b73d-c1b8e01854f8","subtype":"command","commandType":"auto","position":34.0,"command":"%md\nWe can check the size of the list using the Python `len()` function.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490479E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"374fa292-9511-4691-88e2-559f3b08483f"},{"version":"CommandV1","origId":1305471881462022,"guid":"de53a958-6af6-47d8-8540-d3ffed57f883","subtype":"command","commandType":"auto","position":35.0,"command":"len(data)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">29</span><span class=\"ansired\">]: </span>10000\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674387424E12,"submitTime":1.476674392826E12,"finishTime":1.476674387465E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4e8a930a-2dd0-4570-aa4e-f298be1f4aff"},{"version":"CommandV1","origId":1305471881462023,"guid":"5c2af929-b281-4c15-8d8f-ad49ec28d078","subtype":"command","commandType":"auto","position":36.0,"command":"%md\n### (3b) Distributed data and using a collection to create a DataFrame\n\nIn Spark, datasets are represented as a list of entries, where the list is broken up into many different partitions that are each stored on a different machine.  Each partition holds a unique subset of the entries in the list.  Spark calls datasets that it stores \"Resilient Distributed Datasets\" (RDDs). Even DataFrames are ultimately represented as RDDs, with additional meta-data.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/cs105x/diagram-3b.png\" style=\"width: 900px; float: right; margin: 5px\"/>\n\nOne of the defining features of Spark, compared to other data analytics frameworks (e.g., Hadoop), is that it stores data in memory rather than on disk.  This allows Spark applications to run much more quickly, because they are not slowed down by needing to read data from disk.\nThe figure to the right illustrates how Spark breaks a list of data entries into partitions that are each stored in memory on a worker.\n\n\nTo create the DataFrame, we'll use `sqlContext.createDataFrame()`, and we'll pass our array of data in as an argument to that function. Spark will create a new set of input data based on data that is passed in.  A DataFrame requires a _schema_, which is a list of columns, where each column has a name and a type. Our list of data has elements with types (mostly strings, but one integer). We'll supply the rest of the schema and the column names as the second argument to `createDataFrame()`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490522E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"23184d0e-0e6a-41e3-9ed5-7c81e3224150"},{"version":"CommandV1","origId":1305471881462024,"guid":"7c8fdd5e-18d8-4deb-a784-d291e310e59b","subtype":"command","commandType":"auto","position":37.0,"command":"%md\nLet's view the help for `createDataFrame()`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490555E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a2c43310-ca8f-48aa-85bb-34d55d7f703d"},{"version":"CommandV1","origId":1305471881462025,"guid":"615c311e-dc0f-4324-b732-3515c1ae6673","subtype":"command","commandType":"auto","position":38.0,"command":"help(sqlContext.createDataFrame)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Help on method createDataFrame in module pyspark.sql.context:\n\ncreateDataFrame(self, data, schema=None, samplingRatio=None) method of pyspark.sql.context.HiveContext instance\n    Creates a :class:&#96;DataFrame&#96; from an :class:&#96;RDD&#96; of :class:&#96;tuple&#96;/:class:&#96;list&#96;,\n    list or :class:&#96;pandas.DataFrame&#96;.\n    \n    When &#96;&#96;schema&#96;&#96; is a list of column names, the type of each column\n    will be inferred from &#96;&#96;data&#96;&#96;.\n    \n    When &#96;&#96;schema&#96;&#96; is &#96;&#96;None&#96;&#96;, it will try to infer the schema (column names and types)\n    from &#96;&#96;data&#96;&#96;, which should be an RDD of :class:&#96;Row&#96;,\n    or :class:&#96;namedtuple&#96;, or :class:&#96;dict&#96;.\n    \n    If schema inference is needed, &#96;&#96;samplingRatio&#96;&#96; is used to determined the ratio of\n    rows used for schema inference. The first row will be used if &#96;&#96;samplingRatio&#96;&#96; is &#96;&#96;None&#96;&#96;.\n    \n    :param data: an RDD of :class:&#96;Row&#96;/:class:&#96;tuple&#96;/:class:&#96;list&#96;/:class:&#96;dict&#96;,\n        :class:&#96;list&#96;, or :class:&#96;pandas.DataFrame&#96;.\n    :param schema: a :class:&#96;StructType&#96; or list of column names. default None.\n    :param samplingRatio: the sample ratio of rows used for inferring\n    :return: :class:&#96;DataFrame&#96;\n    \n    &gt;&gt;&gt; l = [(&apos;Alice&apos;, 1)]\n    &gt;&gt;&gt; sqlContext.createDataFrame(l).collect()\n    [Row(_1=u&apos;Alice&apos;, _2=1)]\n    &gt;&gt;&gt; sqlContext.createDataFrame(l, [&apos;name&apos;, &apos;age&apos;]).collect()\n    [Row(name=u&apos;Alice&apos;, age=1)]\n    \n    &gt;&gt;&gt; d = [{&apos;name&apos;: &apos;Alice&apos;, &apos;age&apos;: 1}]\n    &gt;&gt;&gt; sqlContext.createDataFrame(d).collect()\n    [Row(age=1, name=u&apos;Alice&apos;)]\n    \n    &gt;&gt;&gt; rdd = sc.parallelize(l)\n    &gt;&gt;&gt; sqlContext.createDataFrame(rdd).collect()\n    [Row(_1=u&apos;Alice&apos;, _2=1)]\n    &gt;&gt;&gt; df = sqlContext.createDataFrame(rdd, [&apos;name&apos;, &apos;age&apos;])\n    &gt;&gt;&gt; df.collect()\n    [Row(name=u&apos;Alice&apos;, age=1)]\n    \n    &gt;&gt;&gt; from pyspark.sql import Row\n    &gt;&gt;&gt; Person = Row(&apos;name&apos;, &apos;age&apos;)\n    &gt;&gt;&gt; person = rdd.map(lambda r: Person(*r))\n    &gt;&gt;&gt; df2 = sqlContext.createDataFrame(person)\n    &gt;&gt;&gt; df2.collect()\n    [Row(name=u&apos;Alice&apos;, age=1)]\n    \n    &gt;&gt;&gt; from pyspark.sql.types import *\n    &gt;&gt;&gt; schema = StructType([\n    ...    StructField(&quot;name&quot;, StringType(), True),\n    ...    StructField(&quot;age&quot;, IntegerType(), True)])\n    &gt;&gt;&gt; df3 = sqlContext.createDataFrame(rdd, schema)\n    &gt;&gt;&gt; df3.collect()\n    [Row(name=u&apos;Alice&apos;, age=1)]\n    \n    &gt;&gt;&gt; sqlContext.createDataFrame(df.toPandas()).collect()  # doctest: +SKIP\n    [Row(name=u&apos;Alice&apos;, age=1)]\n    &gt;&gt;&gt; sqlContext.createDataFrame(pandas.DataFrame([[1, 2]])).collect()  # doctest: +SKIP\n    [Row(0=1, 1=2)]\n    \n    .. versionadded:: 1.3\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.47667439107E12,"submitTime":1.476674396552E12,"finishTime":1.476674391143E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ba0549b9-0395-40aa-8481-598cf704a1dd"},{"version":"CommandV1","origId":1305471881462026,"guid":"045bf5d6-fe15-4c29-85dd-d8994fed0164","subtype":"command","commandType":"auto","position":39.0,"command":"dataDF = sqlContext.createDataFrame(data, ('last_name', 'first_name', 'ssn', 'occupation', 'age'))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674393172E12,"submitTime":1.476674398636E12,"finishTime":1.476674393803E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8ea51624-e472-4cb4-8ea4-4ef783d86887"},{"version":"CommandV1","origId":1305471881462027,"guid":"646c0c34-ba58-459f-8da4-b629c4094b43","subtype":"command","commandType":"auto","position":40.0,"command":"%md\nLet's see what type `sqlContext.createDataFrame()` returned.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47113749062E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f8f3e006-6341-4105-8683-90d110eafc81"},{"version":"CommandV1","origId":1305471881462028,"guid":"3b7c4b4e-6ddc-49a8-9eca-008fea64349a","subtype":"command","commandType":"auto","position":41.0,"command":"print 'type of dataDF: {0}'.format(type(dataDF))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">type of dataDF: &lt;class &apos;pyspark.sql.dataframe.DataFrame&apos;&gt;\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674395887E12,"submitTime":1.47667440135E12,"finishTime":1.476674395927E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8752bdab-3c12-41f2-92f1-3b197565cc02"},{"version":"CommandV1","origId":1305471881462029,"guid":"48c18305-6a6c-4b51-afdb-f0a002d292e3","subtype":"command","commandType":"auto","position":42.0,"command":"%md\nLet's take a look at the DataFrame's schema and some of its rows.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490662E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1faa6657-ef35-48d4-b755-b1eaf54a7787"},{"version":"CommandV1","origId":1305471881462030,"guid":"f06f28f1-9aaf-429a-8349-25ce8f2a6ad8","subtype":"command","commandType":"auto","position":43.0,"command":"dataDF.printSchema()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">root\n |-- last_name: string (nullable = true)\n |-- first_name: string (nullable = true)\n |-- ssn: string (nullable = true)\n |-- occupation: string (nullable = true)\n |-- age: long (nullable = true)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674399748E12,"submitTime":1.476674405229E12,"finishTime":1.476674399788E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e561a9cb-29dd-4def-947c-191ebe6dc1c8"},{"version":"CommandV1","origId":1305471881462031,"guid":"3753f696-c877-4bef-a496-fa660831ab0e","subtype":"command","commandType":"auto","position":44.0,"command":"%md\nWe can register the newly created DataFrame as a named table, using the `registerDataFrameAsTable()` method.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47113749072E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"61c712b5-8798-4fbb-9937-0cf74f67239b"},{"version":"CommandV1","origId":1305471881462032,"guid":"1c881518-556b-4e8a-82f4-febcb155b39c","subtype":"command","commandType":"auto","position":45.0,"command":"sqlContext.registerDataFrameAsTable(dataDF, 'dataframe')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674402292E12,"submitTime":1.476674407755E12,"finishTime":1.476674402315E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5bc283fc-5d77-4d37-bd23-9fa4599b1bf9"},{"version":"CommandV1","origId":1305471881462033,"guid":"ddc96c78-ea4a-42ab-8208-71644049d583","subtype":"command","commandType":"auto","position":46.0,"command":"%md\nWhat methods can we call on this DataFrame?","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490767E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2b825e98-8854-483e-a2d0-1ccc34e97a59"},{"version":"CommandV1","origId":1305471881462034,"guid":"abd22aab-7b78-4fec-928b-8cef7f021725","subtype":"command","commandType":"auto","position":47.0,"command":"help(dataDF)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Help on DataFrame in module pyspark.sql.dataframe object:\n\nclass DataFrame(__builtin__.object)\n |  A distributed collection of data grouped into named columns.\n |  \n |  A :class:&#96;DataFrame&#96; is equivalent to a relational table in Spark SQL,\n |  and can be created using various functions in :class:&#96;SQLContext&#96;::\n |  \n |      people = sqlContext.read.parquet(&quot;...&quot;)\n |  \n |  Once created, it can be manipulated using the various domain-specific-language\n |  (DSL) functions defined in: :class:&#96;DataFrame&#96;, :class:&#96;Column&#96;.\n |  \n |  To select a column from the data frame, use the apply method::\n |  \n |      ageCol = people.age\n |  \n |  A more concrete example::\n |  \n |      # To create DataFrame using SQLContext\n |      people = sqlContext.read.parquet(&quot;...&quot;)\n |      department = sqlContext.read.parquet(&quot;...&quot;)\n |  \n |      people.filter(people.age &gt; 30).join(department, people.deptId == department.id))           .groupBy(department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;})\n |  \n |  .. note:: Experimental\n |  \n |  .. versionadded:: 1.3\n |  \n |  Methods defined here:\n |  \n |  __getattr__(self, name)\n |      Returns the :class:&#96;Column&#96; denoted by &#96;&#96;name&#96;&#96;.\n |      \n |      &gt;&gt;&gt; df.select(df.age).collect()\n |      [Row(age=2), Row(age=5)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  __getitem__(self, item)\n |      Returns the column as a :class:&#96;Column&#96;.\n |      \n |      &gt;&gt;&gt; df.select(df[&apos;age&apos;]).collect()\n |      [Row(age=2), Row(age=5)]\n |      &gt;&gt;&gt; df[ [&quot;name&quot;, &quot;age&quot;]].collect()\n |      [Row(name=u&apos;Alice&apos;, age=2), Row(name=u&apos;Bob&apos;, age=5)]\n |      &gt;&gt;&gt; df[ df.age &gt; 3 ].collect()\n |      [Row(age=5, name=u&apos;Bob&apos;)]\n |      &gt;&gt;&gt; df[df[0] &gt; 3].collect()\n |      [Row(age=5, name=u&apos;Bob&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  __init__(self, jdf, sql_ctx)\n |  \n |  __repr__(self)\n |  \n |  agg(self, *exprs)\n |      Aggregate on the entire :class:&#96;DataFrame&#96; without groups\n |      (shorthand for &#96;&#96;df.groupBy.agg()&#96;&#96;).\n |      \n |      &gt;&gt;&gt; df.agg({&quot;age&quot;: &quot;max&quot;}).collect()\n |      [Row(max(age)=5)]\n |      &gt;&gt;&gt; from pyspark.sql import functions as F\n |      &gt;&gt;&gt; df.agg(F.min(df.age)).collect()\n |      [Row(min(age)=2)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  alias(self, alias)\n |      Returns a new :class:&#96;DataFrame&#96; with an alias set.\n |      \n |      &gt;&gt;&gt; from pyspark.sql.functions import *\n |      &gt;&gt;&gt; df_as1 = df.alias(&quot;df_as1&quot;)\n |      &gt;&gt;&gt; df_as2 = df.alias(&quot;df_as2&quot;)\n |      &gt;&gt;&gt; joined_df = df_as1.join(df_as2, col(&quot;df_as1.name&quot;) == col(&quot;df_as2.name&quot;), &apos;inner&apos;)\n |      &gt;&gt;&gt; joined_df.select(col(&quot;df_as1.name&quot;), col(&quot;df_as2.name&quot;), col(&quot;df_as2.age&quot;)).collect()\n |      [Row(name=u&apos;Alice&apos;, name=u&apos;Alice&apos;, age=2), Row(name=u&apos;Bob&apos;, name=u&apos;Bob&apos;, age=5)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  cache(self)\n |      Persists with the default storage level (C{MEMORY_ONLY_SER}).\n |      \n |      .. versionadded:: 1.3\n |  \n |  coalesce(self, numPartitions)\n |      Returns a new :class:&#96;DataFrame&#96; that has exactly &#96;numPartitions&#96; partitions.\n |      \n |      Similar to coalesce defined on an :class:&#96;RDD&#96;, this operation results in a\n |      narrow dependency, e.g. if you go from 1000 partitions to 100 partitions,\n |      there will not be a shuffle, instead each of the 100 new partitions will\n |      claim 10 of the current partitions.\n |      \n |      &gt;&gt;&gt; df.coalesce(1).rdd.getNumPartitions()\n |      1\n |      \n |      .. versionadded:: 1.4\n |  \n |  collect(self)\n |      Returns all the records as a list of :class:&#96;Row&#96;.\n |      \n |      &gt;&gt;&gt; df.collect()\n |      [Row(age=2, name=u&apos;Alice&apos;), Row(age=5, name=u&apos;Bob&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  corr(self, col1, col2, method=None)\n |      Calculates the correlation of two columns of a DataFrame as a double value.\n |      Currently only supports the Pearson Correlation Coefficient.\n |      :func:&#96;DataFrame.corr&#96; and :func:&#96;DataFrameStatFunctions.corr&#96; are aliases of each other.\n |      \n |      :param col1: The name of the first column\n |      :param col2: The name of the second column\n |      :param method: The correlation method. Currently only supports &quot;pearson&quot;\n |      \n |      .. versionadded:: 1.4\n |  \n |  count(self)\n |      Returns the number of rows in this :class:&#96;DataFrame&#96;.\n |      \n |      &gt;&gt;&gt; df.count()\n |      2\n |      \n |      .. versionadded:: 1.3\n |  \n |  cov(self, col1, col2)\n |      Calculate the sample covariance for the given columns, specified by their names, as a\n |      double value. :func:&#96;DataFrame.cov&#96; and :func:&#96;DataFrameStatFunctions.cov&#96; are aliases.\n |      \n |      :param col1: The name of the first column\n |      :param col2: The name of the second column\n |      \n |      .. versionadded:: 1.4\n |  \n |  crosstab(self, col1, col2)\n |      Computes a pair-wise frequency table of the given columns. Also known as a contingency\n |      table. The number of distinct values for each column should be less than 1e4. At most 1e6\n |      non-zero pair frequencies will be returned.\n |      The first column of each row will be the distinct values of &#96;col1&#96; and the column names\n |      will be the distinct values of &#96;col2&#96;. The name of the first column will be &#96;$col1_$col2&#96;.\n |      Pairs that have no occurrences will have zero as their counts.\n |      :func:&#96;DataFrame.crosstab&#96; and :func:&#96;DataFrameStatFunctions.crosstab&#96; are aliases.\n |      \n |      :param col1: The name of the first column. Distinct items will make the first item of\n |          each row.\n |      :param col2: The name of the second column. Distinct items will make the column names\n |          of the DataFrame.\n |      \n |      .. versionadded:: 1.4\n |  \n |  cube(self, *cols)\n |      Create a multi-dimensional cube for the current :class:&#96;DataFrame&#96; using\n |      the specified columns, so we can run aggregation on them.\n |      \n |      &gt;&gt;&gt; df.cube(&apos;name&apos;, df.age).count().show()\n |      +-----+----+-----+\n |      | name| age|count|\n |      +-----+----+-----+\n |      | null|   2|    1|\n |      |Alice|null|    1|\n |      |  Bob|   5|    1|\n |      |  Bob|null|    1|\n |      | null|   5|    1|\n |      | null|null|    2|\n |      |Alice|   2|    1|\n |      +-----+----+-----+\n |      \n |      .. versionadded:: 1.4\n |  \n |  describe(self, *cols)\n |      Computes statistics for numeric columns.\n |      \n |      This include count, mean, stddev, min, and max. If no columns are\n |      given, this function computes statistics for all numerical columns.\n |      \n |      .. note:: This function is meant for exploratory data analysis, as we make no         guarantee about the backward compatibility of the schema of the resulting DataFrame.\n |      \n |      &gt;&gt;&gt; df.describe().show()\n |      +-------+------------------+\n |      |summary|               age|\n |      +-------+------------------+\n |      |  count|                 2|\n |      |   mean|               3.5|\n |      | stddev|2.1213203435596424|\n |      |    min|                 2|\n |      |    max|                 5|\n |      +-------+------------------+\n |      &gt;&gt;&gt; df.describe([&apos;age&apos;, &apos;name&apos;]).show()\n |      +-------+------------------+-----+\n |      |summary|               age| name|\n |      +-------+------------------+-----+\n |      |  count|                 2|    2|\n |      |   mean|               3.5| null|\n |      | stddev|2.1213203435596424| null|\n |      |    min|                 2|Alice|\n |      |    max|                 5|  Bob|\n |      +-------+------------------+-----+\n |      \n |      .. versionadded:: 1.3.1\n |  \n |  distinct(self)\n |      Returns a new :class:&#96;DataFrame&#96; containing the distinct rows in this :class:&#96;DataFrame&#96;.\n |      \n |      &gt;&gt;&gt; df.distinct().count()\n |      2\n |      \n |      .. versionadded:: 1.3\n |  \n |  drop(self, col)\n |      Returns a new :class:&#96;DataFrame&#96; that drops the specified column.\n |      \n |      :param col: a string name of the column to drop, or a\n |          :class:&#96;Column&#96; to drop.\n |      \n |      &gt;&gt;&gt; df.drop(&apos;age&apos;).collect()\n |      [Row(name=u&apos;Alice&apos;), Row(name=u&apos;Bob&apos;)]\n |      \n |      &gt;&gt;&gt; df.drop(df.age).collect()\n |      [Row(name=u&apos;Alice&apos;), Row(name=u&apos;Bob&apos;)]\n |      \n |      &gt;&gt;&gt; df.join(df2, df.name == df2.name, &apos;inner&apos;).drop(df.name).collect()\n |      [Row(age=5, height=85, name=u&apos;Bob&apos;)]\n |      \n |      &gt;&gt;&gt; df.join(df2, df.name == df2.name, &apos;inner&apos;).drop(df2.name).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;, height=85)]\n |      \n |      .. versionadded:: 1.4\n |  \n |  dropDuplicates(self, subset=None)\n |      Return a new :class:&#96;DataFrame&#96; with duplicate rows removed,\n |      optionally only considering certain columns.\n |      \n |      :func:&#96;drop_duplicates&#96; is an alias for :func:&#96;dropDuplicates&#96;.\n |      \n |      &gt;&gt;&gt; from pyspark.sql import Row\n |      &gt;&gt;&gt; df = sc.parallelize([             Row(name=&apos;Alice&apos;, age=5, height=80),             Row(name=&apos;Alice&apos;, age=5, height=80),             Row(name=&apos;Alice&apos;, age=10, height=80)]).toDF()\n |      &gt;&gt;&gt; df.dropDuplicates().show()\n |      +---+------+-----+\n |      |age|height| name|\n |      +---+------+-----+\n |      |  5|    80|Alice|\n |      | 10|    80|Alice|\n |      +---+------+-----+\n |      \n |      &gt;&gt;&gt; df.dropDuplicates([&apos;name&apos;, &apos;height&apos;]).show()\n |      +---+------+-----+\n |      |age|height| name|\n |      +---+------+-----+\n |      |  5|    80|Alice|\n |      +---+------+-----+\n |      \n |      .. versionadded:: 1.4\n |  \n |  drop_duplicates = dropDuplicates(self, subset=None)\n |  \n |  dropna(self, how=&apos;any&apos;, thresh=None, subset=None)\n |      Returns a new :class:&#96;DataFrame&#96; omitting rows with null values.\n |      :func:&#96;DataFrame.dropna&#96; and :func:&#96;DataFrameNaFunctions.drop&#96; are aliases of each other.\n |      \n |      :param how: &apos;any&apos; or &apos;all&apos;.\n |          If &apos;any&apos;, drop a row if it contains any nulls.\n |          If &apos;all&apos;, drop a row only if all its values are null.\n |      :param thresh: int, default None\n |          If specified, drop rows that have less than &#96;thresh&#96; non-null values.\n |          This overwrites the &#96;how&#96; parameter.\n |      :param subset: optional list of column names to consider.\n |      \n |      &gt;&gt;&gt; df4.na.drop().show()\n |      +---+------+-----+\n |      |age|height| name|\n |      +---+------+-----+\n |      | 10|    80|Alice|\n |      +---+------+-----+\n |      \n |      .. versionadded:: 1.3.1\n |  \n |  explain(self, extended=False)\n |      Prints the (logical and physical) plans to the console for debugging purpose.\n |      \n |      :param extended: boolean, default &#96;&#96;False&#96;&#96;. If &#96;&#96;False&#96;&#96;, prints only the physical plan.\n |      \n |      &gt;&gt;&gt; df.explain()\n |      == Physical Plan ==\n |      Scan ExistingRDD[age#0,name#1]\n |      \n |      &gt;&gt;&gt; df.explain(True)\n |      == Parsed Logical Plan ==\n |      ...\n |      == Analyzed Logical Plan ==\n |      ...\n |      == Optimized Logical Plan ==\n |      ...\n |      == Physical Plan ==\n |      ...\n |      \n |      .. versionadded:: 1.3\n |  \n |  fillna(self, value, subset=None)\n |      Replace null values, alias for &#96;&#96;na.fill()&#96;&#96;.\n |      :func:&#96;DataFrame.fillna&#96; and :func:&#96;DataFrameNaFunctions.fill&#96; are aliases of each other.\n |      \n |      :param value: int, long, float, string, or dict.\n |          Value to replace null values with.\n |          If the value is a dict, then &#96;subset&#96; is ignored and &#96;value&#96; must be a mapping\n |          from column name (string) to replacement value. The replacement value must be\n |          an int, long, float, or string.\n |      :param subset: optional list of column names to consider.\n |          Columns specified in subset that do not have matching data type are ignored.\n |          For example, if &#96;value&#96; is a string, and subset contains a non-string column,\n |          then the non-string column is simply ignored.\n |      \n |      &gt;&gt;&gt; df4.na.fill(50).show()\n |      +---+------+-----+\n |      |age|height| name|\n |      +---+------+-----+\n |      | 10|    80|Alice|\n |      |  5|    50|  Bob|\n |      | 50|    50|  Tom|\n |      | 50|    50| null|\n |      +---+------+-----+\n |      \n |      &gt;&gt;&gt; df4.na.fill({&apos;age&apos;: 50, &apos;name&apos;: &apos;unknown&apos;}).show()\n |      +---+------+-------+\n |      |age|height|   name|\n |      +---+------+-------+\n |      | 10|    80|  Alice|\n |      |  5|  null|    Bob|\n |      | 50|  null|    Tom|\n |      | 50|  null|unknown|\n |      +---+------+-------+\n |      \n |      .. versionadded:: 1.3.1\n |  \n |  filter(self, condition)\n |      Filters rows using the given condition.\n |      \n |      :func:&#96;where&#96; is an alias for :func:&#96;filter&#96;.\n |      \n |      :param condition: a :class:&#96;Column&#96; of :class:&#96;types.BooleanType&#96;\n |          or a string of SQL expression.\n |      \n |      &gt;&gt;&gt; df.filter(df.age &gt; 3).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;)]\n |      &gt;&gt;&gt; df.where(df.age == 2).collect()\n |      [Row(age=2, name=u&apos;Alice&apos;)]\n |      \n |      &gt;&gt;&gt; df.filter(&quot;age &gt; 3&quot;).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;)]\n |      &gt;&gt;&gt; df.where(&quot;age = 2&quot;).collect()\n |      [Row(age=2, name=u&apos;Alice&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  first(self)\n |      Returns the first row as a :class:&#96;Row&#96;.\n |      \n |      &gt;&gt;&gt; df.first()\n |      Row(age=2, name=u&apos;Alice&apos;)\n |      \n |      .. versionadded:: 1.3\n |  \n |  flatMap(self, f)\n |      Returns a new :class:&#96;RDD&#96; by first applying the &#96;&#96;f&#96;&#96; function to each :class:&#96;Row&#96;,\n |      and then flattening the results.\n |      \n |      This is a shorthand for &#96;&#96;df.rdd.flatMap()&#96;&#96;.\n |      \n |      &gt;&gt;&gt; df.flatMap(lambda p: p.name).collect()\n |      [u&apos;A&apos;, u&apos;l&apos;, u&apos;i&apos;, u&apos;c&apos;, u&apos;e&apos;, u&apos;B&apos;, u&apos;o&apos;, u&apos;b&apos;]\n |      \n |      .. versionadded:: 1.3\n |  \n |  foreach(self, f)\n |      Applies the &#96;&#96;f&#96;&#96; function to all :class:&#96;Row&#96; of this :class:&#96;DataFrame&#96;.\n |      \n |      This is a shorthand for &#96;&#96;df.rdd.foreach()&#96;&#96;.\n |      \n |      &gt;&gt;&gt; def f(person):\n |      ...     print(person.name)\n |      &gt;&gt;&gt; df.foreach(f)\n |      \n |      .. versionadded:: 1.3\n |  \n |  foreachPartition(self, f)\n |      Applies the &#96;&#96;f&#96;&#96; function to each partition of this :class:&#96;DataFrame&#96;.\n |      \n |      This a shorthand for &#96;&#96;df.rdd.foreachPartition()&#96;&#96;.\n |      \n |      &gt;&gt;&gt; def f(people):\n |      ...     for person in people:\n |      ...         print(person.name)\n |      &gt;&gt;&gt; df.foreachPartition(f)\n |      \n |      .. versionadded:: 1.3\n |  \n |  freqItems(self, cols, support=None)\n |      Finding frequent items for columns, possibly with false positives. Using the\n |      frequent element count algorithm described in\n |      &quot;http://dx.doi.org/10.1145/762471.762473, proposed by Karp, Schenker, and Papadimitriou&quot;.\n |      :func:&#96;DataFrame.freqItems&#96; and :func:&#96;DataFrameStatFunctions.freqItems&#96; are aliases.\n |      \n |      .. note::  This function is meant for exploratory data analysis, as we make no         guarantee about the backward compatibility of the schema of the resulting DataFrame.\n |      \n |      :param cols: Names of the columns to calculate frequent items for as a list or tuple of\n |          strings.\n |      :param support: The frequency with which to consider an item &apos;frequent&apos;. Default is 1%.\n |          The support must be greater than 1e-4.\n |      \n |      .. versionadded:: 1.4\n |  \n |  groupBy(self, *cols)\n |      Groups the :class:&#96;DataFrame&#96; using the specified columns,\n |      so we can run aggregation on them. See :class:&#96;GroupedData&#96;\n |      for all the available aggregate functions.\n |      \n |      :func:&#96;groupby&#96; is an alias for :func:&#96;groupBy&#96;.\n |      \n |      :param cols: list of columns to group by.\n |          Each element should be a column name (string) or an expression (:class:&#96;Column&#96;).\n |      \n |      &gt;&gt;&gt; df.groupBy().avg().collect()\n |      [Row(avg(age)=3.5)]\n |      &gt;&gt;&gt; df.groupBy(&apos;name&apos;).agg({&apos;age&apos;: &apos;mean&apos;}).collect()\n |      [Row(name=u&apos;Alice&apos;, avg(age)=2.0), Row(name=u&apos;Bob&apos;, avg(age)=5.0)]\n |      &gt;&gt;&gt; df.groupBy(df.name).avg().collect()\n |      [Row(name=u&apos;Alice&apos;, avg(age)=2.0), Row(name=u&apos;Bob&apos;, avg(age)=5.0)]\n |      &gt;&gt;&gt; df.groupBy([&apos;name&apos;, df.age]).count().collect()\n |      [Row(name=u&apos;Bob&apos;, age=5, count=1), Row(name=u&apos;Alice&apos;, age=2, count=1)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  groupby = groupBy(self, *cols)\n |  \n |  head(self, n=None)\n |      Returns the first &#96;&#96;n&#96;&#96; rows.\n |      \n |      :param n: int, default 1. Number of rows to return.\n |      :return: If n is greater than 1, return a list of :class:&#96;Row&#96;.\n |          If n is 1, return a single Row.\n |      \n |      &gt;&gt;&gt; df.head()\n |      Row(age=2, name=u&apos;Alice&apos;)\n |      &gt;&gt;&gt; df.head(1)\n |      [Row(age=2, name=u&apos;Alice&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  insertInto(self, tableName, overwrite=False)\n |      Inserts the contents of this :class:&#96;DataFrame&#96; into the specified table.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameWriter.insertInto&#96; instead.\n |  \n |  intersect(self, other)\n |      Return a new :class:&#96;DataFrame&#96; containing rows only in\n |      both this frame and another frame.\n |      \n |      This is equivalent to &#96;INTERSECT&#96; in SQL.\n |      \n |      .. versionadded:: 1.3\n |  \n |  isLocal(self)\n |      Returns &#96;&#96;True&#96;&#96; if the :func:&#96;collect&#96; and :func:&#96;take&#96; methods can be run locally\n |      (without any Spark executors).\n |      \n |      .. versionadded:: 1.3\n |  \n |  join(self, other, on=None, how=None)\n |      Joins with another :class:&#96;DataFrame&#96;, using the given join expression.\n |      \n |      The following performs a full outer join between &#96;&#96;df1&#96;&#96; and &#96;&#96;df2&#96;&#96;.\n |      \n |      :param other: Right side of the join\n |      :param on: a string for join column name, a list of column names,\n |          , a join expression (Column) or a list of Columns.\n |          If &#96;on&#96; is a string or a list of string indicating the name of the join column(s),\n |          the column(s) must exist on both sides, and this performs an equi-join.\n |      :param how: str, default &apos;inner&apos;.\n |          One of &#96;inner&#96;, &#96;outer&#96;, &#96;left_outer&#96;, &#96;right_outer&#96;, &#96;leftsemi&#96;.\n |      \n |      &gt;&gt;&gt; df.join(df2, df.name == df2.name, &apos;outer&apos;).select(df.name, df2.height).collect()\n |      [Row(name=None, height=80), Row(name=u&apos;Alice&apos;, height=None), Row(name=u&apos;Bob&apos;, height=85)]\n |      \n |      &gt;&gt;&gt; df.join(df2, &apos;name&apos;, &apos;outer&apos;).select(&apos;name&apos;, &apos;height&apos;).collect()\n |      [Row(name=u&apos;Tom&apos;, height=80), Row(name=u&apos;Alice&apos;, height=None), Row(name=u&apos;Bob&apos;, height=85)]\n |      \n |      &gt;&gt;&gt; cond = [df.name == df3.name, df.age == df3.age]\n |      &gt;&gt;&gt; df.join(df3, cond, &apos;outer&apos;).select(df.name, df3.age).collect()\n |      [Row(name=u&apos;Bob&apos;, age=5), Row(name=u&apos;Alice&apos;, age=2)]\n |      \n |      &gt;&gt;&gt; df.join(df2, &apos;name&apos;).select(df.name, df2.height).collect()\n |      [Row(name=u&apos;Bob&apos;, height=85)]\n |      \n |      &gt;&gt;&gt; df.join(df4, [&apos;name&apos;, &apos;age&apos;]).select(df.name, df.age).collect()\n |      [Row(name=u&apos;Bob&apos;, age=5)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  limit(self, num)\n |      Limits the result count to the number specified.\n |      \n |      &gt;&gt;&gt; df.limit(1).collect()\n |      [Row(age=2, name=u&apos;Alice&apos;)]\n |      &gt;&gt;&gt; df.limit(0).collect()\n |      []\n |      \n |      .. versionadded:: 1.3\n |  \n |  map(self, f)\n |      Returns a new :class:&#96;RDD&#96; by applying a the &#96;&#96;f&#96;&#96; function to each :class:&#96;Row&#96;.\n |      \n |      This is a shorthand for &#96;&#96;df.rdd.map()&#96;&#96;.\n |      \n |      &gt;&gt;&gt; df.map(lambda p: p.name).collect()\n |      [u&apos;Alice&apos;, u&apos;Bob&apos;]\n |      \n |      .. versionadded:: 1.3\n |  \n |  mapPartitions(self, f, preservesPartitioning=False)\n |      Returns a new :class:&#96;RDD&#96; by applying the &#96;&#96;f&#96;&#96; function to each partition.\n |      \n |      This is a shorthand for &#96;&#96;df.rdd.mapPartitions()&#96;&#96;.\n |      \n |      &gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4], 4)\n |      &gt;&gt;&gt; def f(iterator): yield 1\n |      &gt;&gt;&gt; rdd.mapPartitions(f).sum()\n |      4\n |      \n |      .. versionadded:: 1.3\n |  \n |  orderBy = sort(self, *cols, **kwargs)\n |  \n |  persist(self, storageLevel=StorageLevel(False, True, False, False, 1))\n |      Sets the storage level to persist its values across operations\n |      after the first time it is computed. This can only be used to assign\n |      a new storage level if the RDD does not have a storage level set yet.\n |      If no storage level is specified defaults to (C{MEMORY_ONLY_SER}).\n |      \n |      .. versionadded:: 1.3\n |  \n |  printSchema(self)\n |      Prints out the schema in the tree format.\n |      \n |      &gt;&gt;&gt; df.printSchema()\n |      root\n |       |-- age: integer (nullable = true)\n |       |-- name: string (nullable = true)\n |      &lt;BLANKLINE&gt;\n |      \n |      .. versionadded:: 1.3\n |  \n |  randomSplit(self, weights, seed=None)\n |      Randomly splits this :class:&#96;DataFrame&#96; with the provided weights.\n |      \n |      :param weights: list of doubles as weights with which to split the DataFrame. Weights will\n |          be normalized if they don&apos;t sum up to 1.0.\n |      :param seed: The seed for sampling.\n |      \n |      &gt;&gt;&gt; splits = df4.randomSplit([1.0, 2.0], 24)\n |      &gt;&gt;&gt; splits[0].count()\n |      1\n |      \n |      &gt;&gt;&gt; splits[1].count()\n |      3\n |      \n |      .. versionadded:: 1.4\n |  \n |  registerAsTable(self, name)\n |      .. note:: Deprecated in 1.4, use :func:&#96;registerTempTable&#96; instead.\n |  \n |  registerTempTable(self, name)\n |      Registers this RDD as a temporary table using the given name.\n |      \n |      The lifetime of this temporary table is tied to the :class:&#96;SQLContext&#96;\n |      that was used to create this :class:&#96;DataFrame&#96;.\n |      \n |      &gt;&gt;&gt; df.registerTempTable(&quot;people&quot;)\n |      &gt;&gt;&gt; df2 = sqlContext.sql(&quot;select * from people&quot;)\n |      &gt;&gt;&gt; sorted(df.collect()) == sorted(df2.collect())\n |      True\n |      \n |      .. versionadded:: 1.3\n |  \n |  repartition(self, numPartitions, *cols)\n |      Returns a new :class:&#96;DataFrame&#96; partitioned by the given partitioning expressions. The\n |      resulting DataFrame is hash partitioned.\n |      \n |      &#96;&#96;numPartitions&#96;&#96; can be an int to specify the target number of partitions or a Column.\n |      If it is a Column, it will be used as the first partitioning column. If not specified,\n |      the default number of partitions is used.\n |      \n |      .. versionchanged:: 1.6\n |         Added optional arguments to specify the partitioning columns. Also made numPartitions\n |         optional if partitioning columns are specified.\n |      \n |      &gt;&gt;&gt; df.repartition(10).rdd.getNumPartitions()\n |      10\n |      &gt;&gt;&gt; data = df.unionAll(df).repartition(&quot;age&quot;)\n |      &gt;&gt;&gt; data.show()\n |      +---+-----+\n |      |age| name|\n |      +---+-----+\n |      |  2|Alice|\n |      |  2|Alice|\n |      |  5|  Bob|\n |      |  5|  Bob|\n |      +---+-----+\n |      &gt;&gt;&gt; data = data.repartition(7, &quot;age&quot;)\n |      &gt;&gt;&gt; data.show()\n |      +---+-----+\n |      |age| name|\n |      +---+-----+\n |      |  5|  Bob|\n |      |  5|  Bob|\n |      |  2|Alice|\n |      |  2|Alice|\n |      +---+-----+\n |      &gt;&gt;&gt; data.rdd.getNumPartitions()\n |      7\n |      &gt;&gt;&gt; data = data.repartition(&quot;name&quot;, &quot;age&quot;)\n |      &gt;&gt;&gt; data.show()\n |      +---+-----+\n |      |age| name|\n |      +---+-----+\n |      |  5|  Bob|\n |      |  5|  Bob|\n |      |  2|Alice|\n |      |  2|Alice|\n |      +---+-----+\n |      \n |      .. versionadded:: 1.3\n |  \n |  replace(self, to_replace, value, subset=None)\n |      Returns a new :class:&#96;DataFrame&#96; replacing a value with another value.\n |      :func:&#96;DataFrame.replace&#96; and :func:&#96;DataFrameNaFunctions.replace&#96; are\n |      aliases of each other.\n |      \n |      :param to_replace: int, long, float, string, or list.\n |          Value to be replaced.\n |          If the value is a dict, then &#96;value&#96; is ignored and &#96;to_replace&#96; must be a\n |          mapping from column name (string) to replacement value. The value to be\n |          replaced must be an int, long, float, or string.\n |      :param value: int, long, float, string, or list.\n |          Value to use to replace holes.\n |          The replacement value must be an int, long, float, or string. If &#96;value&#96; is a\n |          list or tuple, &#96;value&#96; should be of the same length with &#96;to_replace&#96;.\n |      :param subset: optional list of column names to consider.\n |          Columns specified in subset that do not have matching data type are ignored.\n |          For example, if &#96;value&#96; is a string, and subset contains a non-string column,\n |          then the non-string column is simply ignored.\n |      \n |      &gt;&gt;&gt; df4.na.replace(10, 20).show()\n |      +----+------+-----+\n |      | age|height| name|\n |      +----+------+-----+\n |      |  20|    80|Alice|\n |      |   5|  null|  Bob|\n |      |null|  null|  Tom|\n |      |null|  null| null|\n |      +----+------+-----+\n |      \n |      &gt;&gt;&gt; df4.na.replace([&apos;Alice&apos;, &apos;Bob&apos;], [&apos;A&apos;, &apos;B&apos;], &apos;name&apos;).show()\n |      +----+------+----+\n |      | age|height|name|\n |      +----+------+----+\n |      |  10|    80|   A|\n |      |   5|  null|   B|\n |      |null|  null| Tom|\n |      |null|  null|null|\n |      +----+------+----+\n |      \n |      .. versionadded:: 1.4\n |  \n |  rollup(self, *cols)\n |      Create a multi-dimensional rollup for the current :class:&#96;DataFrame&#96; using\n |      the specified columns, so we can run aggregation on them.\n |      \n |      &gt;&gt;&gt; df.rollup(&apos;name&apos;, df.age).count().show()\n |      +-----+----+-----+\n |      | name| age|count|\n |      +-----+----+-----+\n |      |Alice|null|    1|\n |      |  Bob|   5|    1|\n |      |  Bob|null|    1|\n |      | null|null|    2|\n |      |Alice|   2|    1|\n |      +-----+----+-----+\n |      \n |      .. versionadded:: 1.4\n |  \n |  sample(self, withReplacement, fraction, seed=None)\n |      Returns a sampled subset of this :class:&#96;DataFrame&#96;.\n |      \n |      &gt;&gt;&gt; df.sample(False, 0.5, 42).count()\n |      2\n |      \n |      .. versionadded:: 1.3\n |  \n |  sampleBy(self, col, fractions, seed=None)\n |      Returns a stratified sample without replacement based on the\n |      fraction given on each stratum.\n |      \n |      :param col: column that defines strata\n |      :param fractions:\n |          sampling fraction for each stratum. If a stratum is not\n |          specified, we treat its fraction as zero.\n |      :param seed: random seed\n |      :return: a new DataFrame that represents the stratified sample\n |      \n |      &gt;&gt;&gt; from pyspark.sql.functions import col\n |      &gt;&gt;&gt; dataset = sqlContext.range(0, 100).select((col(&quot;id&quot;) % 3).alias(&quot;key&quot;))\n |      &gt;&gt;&gt; sampled = dataset.sampleBy(&quot;key&quot;, fractions={0: 0.1, 1: 0.2}, seed=0)\n |      &gt;&gt;&gt; sampled.groupBy(&quot;key&quot;).count().orderBy(&quot;key&quot;).show()\n |      +---+-----+\n |      |key|count|\n |      +---+-----+\n |      |  0|    5|\n |      |  1|    9|\n |      +---+-----+\n |      \n |      .. versionadded:: 1.5\n |  \n |  save(self, path=None, source=None, mode=&apos;error&apos;, **options)\n |      Saves the contents of the :class:&#96;DataFrame&#96; to a data source.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameWriter.save&#96; instead.\n |      \n |      .. versionadded:: 1.3\n |  \n |  saveAsParquetFile(self, path)\n |      Saves the contents as a Parquet file, preserving the schema.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameWriter.parquet&#96; instead.\n |  \n |  saveAsTable(self, tableName, source=None, mode=&apos;error&apos;, **options)\n |      Saves the contents of this :class:&#96;DataFrame&#96; to a data source as a table.\n |      \n |      .. note:: Deprecated in 1.4, use :func:&#96;DataFrameWriter.saveAsTable&#96; instead.\n |  \n |  select(self, *cols)\n |      Projects a set of expressions and returns a new :class:&#96;DataFrame&#96;.\n |      \n |      :param cols: list of column names (string) or expressions (:class:&#96;Column&#96;).\n |          If one of the column names is &apos;*&apos;, that column is expanded to include all columns\n |          in the current DataFrame.\n |      \n |      &gt;&gt;&gt; df.select(&apos;*&apos;).collect()\n |      [Row(age=2, name=u&apos;Alice&apos;), Row(age=5, name=u&apos;Bob&apos;)]\n |      &gt;&gt;&gt; df.select(&apos;name&apos;, &apos;age&apos;).collect()\n |      [Row(name=u&apos;Alice&apos;, age=2), Row(name=u&apos;Bob&apos;, age=5)]\n |      &gt;&gt;&gt; df.select(df.name, (df.age + 10).alias(&apos;age&apos;)).collect()\n |      [Row(name=u&apos;Alice&apos;, age=12), Row(name=u&apos;Bob&apos;, age=15)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  selectExpr(self, *expr)\n |      Projects a set of SQL expressions and returns a new :class:&#96;DataFrame&#96;.\n |      \n |      This is a variant of :func:&#96;select&#96; that accepts SQL expressions.\n |      \n |      &gt;&gt;&gt; df.selectExpr(&quot;age * 2&quot;, &quot;abs(age)&quot;).collect()\n |      [Row((age * 2)=4, abs(age)=2), Row((age * 2)=10, abs(age)=5)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  show(self, n=20, truncate=True)\n |      Prints the first &#96;&#96;n&#96;&#96; rows to the console.\n |      \n |      :param n: Number of rows to show.\n |      :param truncate: Whether truncate long strings and align cells right.\n |      \n |      &gt;&gt;&gt; df\n |      DataFrame[age: int, name: string]\n |      &gt;&gt;&gt; df.show()\n |      +---+-----+\n |      |age| name|\n |      +---+-----+\n |      |  2|Alice|\n |      |  5|  Bob|\n |      +---+-----+\n |      \n |      .. versionadded:: 1.3\n |  \n |  sort(self, *cols, **kwargs)\n |      Returns a new :class:&#96;DataFrame&#96; sorted by the specified column(s).\n |      \n |      :param cols: list of :class:&#96;Column&#96; or column names to sort by.\n |      :param ascending: boolean or list of boolean (default True).\n |          Sort ascending vs. descending. Specify list for multiple sort orders.\n |          If a list is specified, length of the list must equal length of the &#96;cols&#96;.\n |      \n |      &gt;&gt;&gt; df.sort(df.age.desc()).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;), Row(age=2, name=u&apos;Alice&apos;)]\n |      &gt;&gt;&gt; df.sort(&quot;age&quot;, ascending=False).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;), Row(age=2, name=u&apos;Alice&apos;)]\n |      &gt;&gt;&gt; df.orderBy(df.age.desc()).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;), Row(age=2, name=u&apos;Alice&apos;)]\n |      &gt;&gt;&gt; from pyspark.sql.functions import *\n |      &gt;&gt;&gt; df.sort(asc(&quot;age&quot;)).collect()\n |      [Row(age=2, name=u&apos;Alice&apos;), Row(age=5, name=u&apos;Bob&apos;)]\n |      &gt;&gt;&gt; df.orderBy(desc(&quot;age&quot;), &quot;name&quot;).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;), Row(age=2, name=u&apos;Alice&apos;)]\n |      &gt;&gt;&gt; df.orderBy([&quot;age&quot;, &quot;name&quot;], ascending=[0, 1]).collect()\n |      [Row(age=5, name=u&apos;Bob&apos;), Row(age=2, name=u&apos;Alice&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  sortWithinPartitions(self, *cols, **kwargs)\n |      Returns a new :class:&#96;DataFrame&#96; with each partition sorted by the specified column(s).\n |      \n |      :param cols: list of :class:&#96;Column&#96; or column names to sort by.\n |      :param ascending: boolean or list of boolean (default True).\n |          Sort ascending vs. descending. Specify list for multiple sort orders.\n |          If a list is specified, length of the list must equal length of the &#96;cols&#96;.\n |      \n |      &gt;&gt;&gt; df.sortWithinPartitions(&quot;age&quot;, ascending=False).show()\n |      +---+-----+\n |      |age| name|\n |      +---+-----+\n |      |  2|Alice|\n |      |  5|  Bob|\n |      +---+-----+\n |      \n |      .. versionadded:: 1.6\n |  \n |  subtract(self, other)\n |      Return a new :class:&#96;DataFrame&#96; containing rows in this frame\n |      but not in another frame.\n |      \n |      This is equivalent to &#96;EXCEPT&#96; in SQL.\n |      \n |      .. versionadded:: 1.3\n |  \n |  take(self, num)\n |      Returns the first &#96;&#96;num&#96;&#96; rows as a :class:&#96;list&#96; of :class:&#96;Row&#96;.\n |      \n |      &gt;&gt;&gt; df.take(2)\n |      [Row(age=2, name=u&apos;Alice&apos;), Row(age=5, name=u&apos;Bob&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  toDF(self, *cols)\n |      Returns a new class:&#96;DataFrame&#96; that with new specified column names\n |      \n |      :param cols: list of new column names (string)\n |      \n |      &gt;&gt;&gt; df.toDF(&apos;f1&apos;, &apos;f2&apos;).collect()\n |      [Row(f1=2, f2=u&apos;Alice&apos;), Row(f1=5, f2=u&apos;Bob&apos;)]\n |  \n |  toJSON(self, use_unicode=True)\n |      Converts a :class:&#96;DataFrame&#96; into a :class:&#96;RDD&#96; of string.\n |      \n |      Each row is turned into a JSON document as one element in the returned RDD.\n |      \n |      &gt;&gt;&gt; df.toJSON().first()\n |      u&apos;{&quot;age&quot;:2,&quot;name&quot;:&quot;Alice&quot;}&apos;\n |      \n |      .. versionadded:: 1.3\n |  \n |  toPandas(self)\n |      Returns the contents of this :class:&#96;DataFrame&#96; as Pandas &#96;&#96;pandas.DataFrame&#96;&#96;.\n |      \n |      This is only available if Pandas is installed and available.\n |      \n |      &gt;&gt;&gt; df.toPandas()  # doctest: +SKIP\n |         age   name\n |      0    2  Alice\n |      1    5    Bob\n |      \n |      .. versionadded:: 1.3\n |  \n |  unionAll(self, other)\n |      Return a new :class:&#96;DataFrame&#96; containing union of rows in this\n |      frame and another frame.\n |      \n |      This is equivalent to &#96;UNION ALL&#96; in SQL.\n |      \n |      .. versionadded:: 1.3\n |  \n |  unpersist(self, blocking=True)\n |      Marks the :class:&#96;DataFrame&#96; as non-persistent, and remove all blocks for it from\n |      memory and disk.\n |      \n |      .. versionadded:: 1.3\n |  \n |  where = filter(self, condition)\n |  \n |  withColumn(self, colName, col)\n |      Returns a new :class:&#96;DataFrame&#96; by adding a column or replacing the\n |      existing column that has the same name.\n |      \n |      :param colName: string, name of the new column.\n |      :param col: a :class:&#96;Column&#96; expression for the new column.\n |      \n |      &gt;&gt;&gt; df.withColumn(&apos;age2&apos;, df.age + 2).collect()\n |      [Row(age=2, name=u&apos;Alice&apos;, age2=4), Row(age=5, name=u&apos;Bob&apos;, age2=7)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  withColumnRenamed(self, existing, new)\n |      Returns a new :class:&#96;DataFrame&#96; by renaming an existing column.\n |      \n |      :param existing: string, name of the existing column to rename.\n |      :param col: string, new name of the column.\n |      \n |      &gt;&gt;&gt; df.withColumnRenamed(&apos;age&apos;, &apos;age2&apos;).collect()\n |      [Row(age2=2, name=u&apos;Alice&apos;), Row(age2=5, name=u&apos;Bob&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  columns\n |      Returns all column names as a list.\n |      \n |      &gt;&gt;&gt; df.columns\n |      [&apos;age&apos;, &apos;name&apos;]\n |      \n |      .. versionadded:: 1.3\n |  \n |  dtypes\n |      Returns all column names and their data types as a list.\n |      \n |      &gt;&gt;&gt; df.dtypes\n |      [(&apos;age&apos;, &apos;int&apos;), (&apos;name&apos;, &apos;string&apos;)]\n |      \n |      .. versionadded:: 1.3\n |  \n |  na\n |      Returns a :class:&#96;DataFrameNaFunctions&#96; for handling missing values.\n |      \n |      .. versionadded:: 1.3.1\n |  \n |  rdd\n |      Returns the content as an :class:&#96;pyspark.RDD&#96; of :class:&#96;Row&#96;.\n |      \n |      .. versionadded:: 1.3\n |  \n |  schema\n |      Returns the schema of this :class:&#96;DataFrame&#96; as a :class:&#96;types.StructType&#96;.\n |      \n |      &gt;&gt;&gt; df.schema\n |      StructType(List(StructField(age,IntegerType,true),StructField(name,StringType,true)))\n |      \n |      .. versionadded:: 1.3\n |  \n |  stat\n |      Returns a :class:&#96;DataFrameStatFunctions&#96; for statistic functions.\n |      \n |      .. versionadded:: 1.4\n |  \n |  write\n |      Interface for saving the content of the :class:&#96;DataFrame&#96; out into external storage.\n |      \n |      :return: :class:&#96;DataFrameWriter&#96;\n |      \n |      .. versionadded:: 1.4\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674404748E12,"submitTime":1.476674410223E12,"finishTime":1.476674404789E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"14b36648-6498-44eb-a686-6441c73ad4f9"},{"version":"CommandV1","origId":1305471881462035,"guid":"1657e4a1-0d14-44d8-b19c-009d2363f25c","subtype":"command","commandType":"auto","position":48.0,"command":"%md\nHow many partitions will the DataFrame be split into?","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490814E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c6b1ff1c-08f6-49b3-901d-805a3f62fc35"},{"version":"CommandV1","origId":1305471881462036,"guid":"ac2d2704-1a18-43d4-a6a1-31c8dfa0379d","subtype":"command","commandType":"auto","position":49.0,"command":"dataDF.rdd.getNumPartitions()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">36</span><span class=\"ansired\">]: </span>8\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674408078E12,"submitTime":1.476674413542E12,"finishTime":1.476674408118E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7e4351e7-8f79-43f2-bf29-07e513cdac92"},{"version":"CommandV1","origId":1305471881462037,"guid":"202cedf5-b43a-4ea2-a3b6-193c157f772f","subtype":"command","commandType":"auto","position":50.0,"command":"%md\n###### A note about DataFrames and queries\n\nWhen you use DataFrames or Spark SQL, you are building up a _query plan_. Each transformation you apply to a DataFrame adds some information to the query plan. When you finally call an action, which triggers execution of your Spark job, several things happen:\n\n1. Spark's Catalyst optimizer analyzes the query plan (called an _unoptimized logical query plan_) and attempts to optimize it. Optimizations include (but aren't limited to) rearranging and combining `filter()` operations for efficiency, converting `Decimal` operations to more efficient long integer operations, and pushing some operations down into the data source (e.g., a `filter()` operation might be translated to a SQL `WHERE` clause, if the data source is a traditional SQL RDBMS). The result of this optimization phase is an _optimized logical plan_.\n2. Once Catalyst has an optimized logical plan, it then constructs multiple _physical_ plans from it. Specifically, it implements the query in terms of lower level Spark RDD operations.\n3. Catalyst chooses which physical plan to use via _cost optimization_. That is, it determines which physical plan is the most efficient (or least expensive), and uses that one.\n4. Finally, once the physical RDD execution plan is established, Spark actually executes the job.\n\nYou can examine the query plan using the `explain()` function on a DataFrame. By default, `explain()` only shows you the final physical plan; however, if you pass it an argument of `True`, it will show you all phases.\n\n(If you want to take a deeper dive into how Catalyst optimizes DataFrame queries, this blog post, while a little old, is an excellent overview: [Deep Dive into Spark SQL's Catalyst Optimizer](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html).)\n\nLet's add a couple transformations to our DataFrame and look at the query plan on the resulting transformed DataFrame. Don't be too concerned if it looks like gibberish. As you gain more experience with Apache Spark, you'll begin to be able to use `explain()` to help you understand more about your DataFrame operations.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490856E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1f959a10-6196-4743-b9fc-a210da613a23"},{"version":"CommandV1","origId":1305471881462038,"guid":"0c85afe9-4fa1-4a71-9689-9f6acc5cdbef","subtype":"command","commandType":"auto","position":51.0,"command":"newDF = dataDF.distinct().select('*')\nnewDF.explain(True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&apos;Project [*]\n+- Aggregate [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], [last_name#358,first_name#359,ssn#360,occupation#361,age#362L]\n   +- LogicalRDD [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], MapPartitionsRDD[190] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:-2\n\n== Analyzed Logical Plan ==\nlast_name: string, first_name: string, ssn: string, occupation: string, age: bigint\nProject [last_name#358,first_name#359,ssn#360,occupation#361,age#362L]\n+- Aggregate [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], [last_name#358,first_name#359,ssn#360,occupation#361,age#362L]\n   +- LogicalRDD [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], MapPartitionsRDD[190] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:-2\n\n== Optimized Logical Plan ==\nAggregate [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], [last_name#358,first_name#359,ssn#360,occupation#361,age#362L]\n+- LogicalRDD [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], MapPartitionsRDD[190] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:-2\n\n== Physical Plan ==\nTungstenAggregate(key=[last_name#358,first_name#359,ssn#360,occupation#361,age#362L], functions=[], output=[last_name#358,first_name#359,ssn#360,occupation#361,age#362L])\n+- TungstenExchange hashpartitioning(last_name#358,first_name#359,ssn#360,occupation#361,age#362L,200), None\n   +- TungstenAggregate(key=[last_name#358,first_name#359,ssn#360,occupation#361,age#362L], functions=[], output=[last_name#358,first_name#359,ssn#360,occupation#361,age#362L])\n      +- Scan ExistingRDD[last_name#358,first_name#359,ssn#360,occupation#361,age#362L]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.47667441053E12,"submitTime":1.476674416011E12,"finishTime":1.476674410652E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"37224bc7-87aa-47be-a6ff-8c5bd0525d0b"},{"version":"CommandV1","origId":1305471881462039,"guid":"5a7128a5-4336-4366-b324-fc09a71547d7","subtype":"command","commandType":"auto","position":52.0,"command":"%md\n### (3c): Subtract one from each value using _select_\n\nSo far, we've created a distributed DataFrame that is split into many partitions, where each partition is stored on a single machine in our cluster.  Let's look at what happens when we do a basic operation on the dataset.  Many useful data analysis operations can be specified as \"do something to each item in the dataset\".  These data-parallel operations are convenient because each item in the dataset can be processed individually: the operation on one entry doesn't effect the operations on any of the other entries.  Therefore, Spark can parallelize the operation.\n\nOne of the most common DataFrame operations is `select()`, and it works more or less like a SQL `SELECT` statement: You can select specific columns from the DataFrame, and you can even use `select()` to create _new_ columns with values that are derived from existing column values. We can use `select()` to create a new column that decrements the value of the existing `age` column.\n\n`select()` is a _transformation_. It returns a new DataFrame that captures both the previous DataFrame and the operation to add to the query (`select`, in this case). But it does *not* actually execute anything on the cluster. When transforming DataFrames, we are building up a _query plan_. That query plan will be optimized, implemented (in terms of RDDs), and executed by Spark _only_ when we call an action.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490899E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a42caf8b-edb0-4838-9edb-ed13ee64926b"},{"version":"CommandV1","origId":1305471881462040,"guid":"371c0a56-85a0-492e-8e3a-b23538630084","subtype":"command","commandType":"auto","position":53.0,"command":"# Transform dataDF through a select transformation and rename the newly created '(age -1)' column to 'age'\n# Because select is a transformation and Spark uses lazy evaluation, no jobs, stages,\n# or tasks will be launched when we run this code.\nsubDF = dataDF.select('last_name', 'first_name', 'ssn', 'occupation', (dataDF.age - 1).alias('age'))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674412317E12,"submitTime":1.476674417782E12,"finishTime":1.47667441244E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2c02d040-0537-4b2f-9054-adaa4f761e0c"},{"version":"CommandV1","origId":1305471881462041,"guid":"5614d861-867b-48a9-82ce-1fe3eb59d465","subtype":"command","commandType":"auto","position":54.0,"command":"%md\nLet's take a look at the query plan.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490938E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ed4a9e24-2cc3-48b6-b2e9-578513645940"},{"version":"CommandV1","origId":1305471881462042,"guid":"8177297a-f235-464c-b593-a73f771ee0b5","subtype":"command","commandType":"auto","position":55.0,"command":"subDF.explain(True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&apos;Project [unresolvedalias(&apos;last_name),unresolvedalias(&apos;first_name),unresolvedalias(&apos;ssn),unresolvedalias(&apos;occupation),(age#362L - 1) AS age#369]\n+- LogicalRDD [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], MapPartitionsRDD[190] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:-2\n\n== Analyzed Logical Plan ==\nlast_name: string, first_name: string, ssn: string, occupation: string, age: bigint\nProject [last_name#358,first_name#359,ssn#360,occupation#361,(age#362L - cast(1 as bigint)) AS age#369L]\n+- LogicalRDD [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], MapPartitionsRDD[190] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:-2\n\n== Optimized Logical Plan ==\nProject [last_name#358,first_name#359,ssn#360,occupation#361,(age#362L - 1) AS age#369L]\n+- LogicalRDD [last_name#358,first_name#359,ssn#360,occupation#361,age#362L], MapPartitionsRDD[190] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:-2\n\n== Physical Plan ==\nProject [last_name#358,first_name#359,ssn#360,occupation#361,(age#362L - 1) AS age#369L]\n+- Scan ExistingRDD[last_name#358,first_name#359,ssn#360,occupation#361,age#362L]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674414691E12,"submitTime":1.476674420173E12,"finishTime":1.476674414731E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f6167eac-3483-4c09-a794-f42ea3855e00"},{"version":"CommandV1","origId":1305471881462043,"guid":"847c6092-626c-41f3-a51f-9cfd64d6691e","subtype":"command","commandType":"auto","position":56.0,"command":"%md\n### (3d) Use _collect_ to view results\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/cs105x/diagram-3d.png\" style=\"height:700px;float:right\"/>\n\nTo see a list of elements decremented by one, we need to create a new list on the driver from the the data distributed in the executor nodes.  To do this we can call the `collect()` method on our DataFrame.  `collect()` is often used after transformations to ensure that we are only returning a *small* amount of data to the driver.  This is done because the data returned to the driver must fit into the driver's available memory.  If not, the driver will crash.\n\nThe `collect()` method is the first action operation that we have encountered.  Action operations cause Spark to perform the (lazy) transformation operations that are required to compute the values returned by the action.  In our example, this means that tasks will now be launched to perform the `createDataFrame`, `select`, and `collect` operations.\n\nIn the diagram, the dataset is broken into four partitions, so four `collect()` tasks are launched. Each task collects the entries in its partition and sends the result to the driver, which creates a list of the values, as shown in the figure below.\n\nNow let's run `collect()` on `subDF`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137490983E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d4a320f1-c52d-4c0e-aec3-34f539b0fa32"},{"version":"CommandV1","origId":1305471881462044,"guid":"f60b3adf-2441-4d78-aad7-8feb1417e24f","subtype":"command","commandType":"auto","position":57.0,"command":"# Let's collect the data\nresults = subDF.collect()\nprint results","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">[Row(last_name=u&apos;Curtis&apos;, first_name=u&apos;Kristen&apos;, ssn=u&apos;688-09-1018&apos;, occupation=u&apos;Administrator, charities/voluntary organisations&apos;, age=7), Row(last_name=u&apos;Richards&apos;, first_name=u&apos;David&apos;, ssn=u&apos;201-66-6752&apos;, occupation=u&apos;Building surveyor&apos;, age=23), Row(last_name=u&apos;Parker&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;784-44-1690&apos;, occupation=u&apos;Proofreader&apos;, age=11), Row(last_name=u&apos;Wood&apos;, first_name=u&apos;Jeremiah&apos;, ssn=u&apos;645-25-9468&apos;, occupation=u&apos;Librarian, academic&apos;, age=5), Row(last_name=u&apos;Arias&apos;, first_name=u&apos;Sandra&apos;, ssn=u&apos;460-22-4420&apos;, occupation=u&apos;Engineer, electrical&apos;, age=43), Row(last_name=u&apos;Green&apos;, first_name=u&apos;David&apos;, ssn=u&apos;588-46-6358&apos;, occupation=u&apos;Scientist, biomedical&apos;, age=0), Row(last_name=u&apos;Glenn&apos;, first_name=u&apos;Derrick&apos;, ssn=u&apos;337-51-5287&apos;, occupation=u&apos;Patent attorney&apos;, age=6), Row(last_name=u&apos;Evans&apos;, first_name=u&apos;Leah&apos;, ssn=u&apos;163-56-3569&apos;, occupation=u&apos;Pharmacist, hospital&apos;, age=36), Row(last_name=u&apos;Snyder&apos;, first_name=u&apos;Tara&apos;, ssn=u&apos;842-77-4305&apos;, occupation=u&apos;Administrator, education&apos;, age=26), Row(last_name=u&apos;Miller&apos;, first_name=u&apos;Tiffany&apos;, ssn=u&apos;527-33-8046&apos;, occupation=u&apos;Lighting technician, broadcasting/film/video&apos;, age=3), Row(last_name=u&apos;Boyer&apos;, first_name=u&apos;Tiffany&apos;, ssn=u&apos;855-14-4693&apos;, occupation=u&apos;Graphic designer&apos;, age=4), Row(last_name=u&apos;Mills&apos;, first_name=u&apos;Kevin&apos;, ssn=u&apos;701-33-5126&apos;, occupation=u&apos;Engineer, water&apos;, age=23), Row(last_name=u&apos;Glenn&apos;, first_name=u&apos;Karen&apos;, ssn=u&apos;894-73-1777&apos;, occupation=u&apos;Investment banker, corporate&apos;, age=30), Row(last_name=u&apos;Brady&apos;, first_name=u&apos;Patricia&apos;, ssn=u&apos;175-38-4379&apos;, occupation=u&apos;Mudlogger&apos;, age=21), Row(last_name=u&apos;Juarez&apos;, first_name=u&apos;Kyle&apos;, ssn=u&apos;612-98-0866&apos;, occupation=u&apos;Market researcher&apos;, age=44), Row(last_name=u&apos;Cooper&apos;, first_name=u&apos;Catherine&apos;, ssn=u&apos;245-56-5385&apos;, occupation=u&apos;Medical technical officer&apos;, age=19), Row(last_name=u&apos;Nelson&apos;, first_name=u&apos;John&apos;, ssn=u&apos;732-19-3869&apos;, occupation=u&apos;Commercial horticulturist&apos;, age=3), Row(last_name=u&apos;Taylor&apos;, first_name=u&apos;Jamie&apos;, ssn=u&apos;189-24-2509&apos;, occupation=u&apos;Tourist information centre manager&apos;, age=27), Row(last_name=u&apos;Reed&apos;, first_name=u&apos;James&apos;, ssn=u&apos;508-63-4298&apos;, occupation=u&apos;Physiological scientist&apos;, age=16), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Richard&apos;, ssn=u&apos;430-04-3230&apos;, occupation=u&apos;Ophthalmologist&apos;, age=8), Row(last_name=u&apos;Hudson&apos;, first_name=u&apos;Jeff&apos;, ssn=u&apos;361-38-1225&apos;, occupation=u&apos;Fitness centre manager&apos;, age=11), Row(last_name=u&apos;Kathryn&apos;, first_name=u&apos;Mrs.&apos;, ssn=u&apos;029-47-4555&apos;, occupation=u&apos;Scientific laboratory technician&apos;, age=44), Row(last_name=u&apos;Stephens&apos;, first_name=u&apos;Scott&apos;, ssn=u&apos;287-59-2532&apos;, occupation=u&apos;Patent attorney&apos;, age=29), Row(last_name=u&apos;Johnson&apos;, first_name=u&apos;Norma&apos;, ssn=u&apos;473-06-8214&apos;, occupation=u&apos;Horticultural therapist&apos;, age=26), Row(last_name=u&apos;Campbell&apos;, first_name=u&apos;Matthew&apos;, ssn=u&apos;755-53-2711&apos;, occupation=u&apos;Tree surgeon&apos;, age=4), Row(last_name=u&apos;William&apos;, first_name=u&apos;Dr.&apos;, ssn=u&apos;603-84-8464&apos;, occupation=u&apos;Call centre manager&apos;, age=33), Row(last_name=u&apos;Morgan&apos;, first_name=u&apos;Lorraine&apos;, ssn=u&apos;304-86-9496&apos;, occupation=u&apos;Engineer, maintenance (IT)&apos;, age=13), Row(last_name=u&apos;Lee&apos;, first_name=u&apos;Lisa&apos;, ssn=u&apos;138-97-9782&apos;, occupation=u&apos;Clinical embryologist&apos;, age=22), Row(last_name=u&apos;Lopez&apos;, first_name=u&apos;Heather&apos;, ssn=u&apos;519-48-8761&apos;, occupation=u&quot;Nurse, children&apos;s&quot;, age=14), Row(last_name=u&apos;Patrick&apos;, first_name=u&apos;Doris&apos;, ssn=u&apos;781-48-3096&apos;, occupation=u&apos;Music tutor&apos;, age=46), Row(last_name=u&apos;Howard&apos;, first_name=u&apos;Erika&apos;, ssn=u&apos;199-19-3835&apos;, occupation=u&apos;Rural practice surveyor&apos;, age=14), Row(last_name=u&apos;Lopez&apos;, first_name=u&apos;Collin&apos;, ssn=u&apos;484-43-0522&apos;, occupation=u&apos;Health and safety adviser&apos;, age=6), Row(last_name=u&apos;Hanson&apos;, first_name=u&apos;Tina&apos;, ssn=u&apos;577-26-2113&apos;, occupation=u&apos;Petroleum engineer&apos;, age=23), Row(last_name=u&apos;Moreno&apos;, first_name=u&apos;Glenn&apos;, ssn=u&apos;227-97-4319&apos;, occupation=u&apos;IT technical support officer&apos;, age=19), Row(last_name=u&apos;Lopez&apos;, first_name=u&apos;Cynthia&apos;, ssn=u&apos;678-06-1255&apos;, occupation=u&apos;Engineer, structural&apos;, age=43), Row(last_name=u&apos;Vargas&apos;, first_name=u&apos;Mary&apos;, ssn=u&apos;198-76-2470&apos;, occupation=u&apos;Research scientist (life sciences)&apos;, age=23), Row(last_name=u&apos;Barnes&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;751-08-1097&apos;, occupation=u&apos;Broadcast engineer&apos;, age=15), Row(last_name=u&apos;Hines&apos;, first_name=u&apos;Brandon&apos;, ssn=u&apos;073-36-3206&apos;, occupation=u&apos;Landscape architect&apos;, age=34), Row(last_name=u&apos;Ramos&apos;, first_name=u&apos;Tracy&apos;, ssn=u&apos;297-94-7225&apos;, occupation=u&apos;Photographer&apos;, age=5), Row(last_name=u&apos;Lang&apos;, first_name=u&apos;Jessica&apos;, ssn=u&apos;521-20-2148&apos;, occupation=u&apos;Scientist, audiological&apos;, age=4), Row(last_name=u&apos;Lawrence&apos;, first_name=u&apos;Cesar&apos;, ssn=u&apos;054-75-3019&apos;, occupation=u&apos;Educational psychologist&apos;, age=45), Row(last_name=u&apos;Monroe&apos;, first_name=u&apos;Dwayne&apos;, ssn=u&apos;202-52-0122&apos;, occupation=u&apos;Tree surgeon&apos;, age=12), Row(last_name=u&apos;Lee&apos;, first_name=u&apos;Rodney&apos;, ssn=u&apos;302-24-1795&apos;, occupation=u&apos;Veterinary surgeon&apos;, age=29), Row(last_name=u&apos;Jackson&apos;, first_name=u&apos;Laura&apos;, ssn=u&apos;411-60-4473&apos;, occupation=u&apos;Waste management officer&apos;, age=15), Row(last_name=u&apos;Kennedy&apos;, first_name=u&apos;Caitlin&apos;, ssn=u&apos;431-98-3022&apos;, occupation=u&apos;Geologist, engineering&apos;, age=39), Row(last_name=u&apos;Ward&apos;, first_name=u&apos;Brett&apos;, ssn=u&apos;181-70-5815&apos;, occupation=u&quot;Barrister&apos;s clerk&quot;, age=39), Row(last_name=u&apos;Huffman&apos;, first_name=u&apos;Timothy&apos;, ssn=u&apos;614-07-0799&apos;, occupation=u&apos;Fish farm manager&apos;, age=17), Row(last_name=u&apos;Cruz&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;767-70-5269&apos;, occupation=u&apos;Licensed conveyancer&apos;, age=3), Row(last_name=u&apos;Key&apos;, first_name=u&apos;Jeremy&apos;, ssn=u&apos;449-64-2814&apos;, occupation=u&apos;Newspaper journalist&apos;, age=16), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Frances&apos;, ssn=u&apos;337-33-6058&apos;, occupation=u&apos;Tourist information centre manager&apos;, age=23), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Mark&apos;, ssn=u&apos;196-76-2218&apos;, occupation=u&apos;Primary school teacher&apos;, age=33), Row(last_name=u&apos;Wright&apos;, first_name=u&apos;Terri&apos;, ssn=u&apos;558-81-0423&apos;, occupation=u&apos;Hospital doctor&apos;, age=16), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Sarah&apos;, ssn=u&apos;725-06-9596&apos;, occupation=u&apos;Telecommunications researcher&apos;, age=12), Row(last_name=u&apos;Webb&apos;, first_name=u&apos;Julian&apos;, ssn=u&apos;757-82-5438&apos;, occupation=u&apos;Administrator&apos;, age=15), Row(last_name=u&apos;Michelle&apos;, first_name=u&apos;Miss&apos;, ssn=u&apos;318-47-6860&apos;, occupation=u&apos;Writer&apos;, age=37), Row(last_name=u&apos;Bailey&apos;, first_name=u&apos;David&apos;, ssn=u&apos;230-38-2189&apos;, occupation=u&apos;Merchandiser, retail&apos;, age=35), Row(last_name=u&apos;Spears&apos;, first_name=u&apos;Sandra&apos;, ssn=u&apos;661-42-2121&apos;, occupation=u&apos;Surveyor, land/geomatics&apos;, age=44), Row(last_name=u&apos;Murray&apos;, first_name=u&apos;Scott&apos;, ssn=u&apos;061-87-6153&apos;, occupation=u&apos;Financial manager&apos;, age=19), Row(last_name=u&apos;Thompson&apos;, first_name=u&apos;Carrie&apos;, ssn=u&apos;465-02-5429&apos;, occupation=u&apos;Teacher, music&apos;, age=2), Row(last_name=u&apos;Byrd&apos;, first_name=u&apos;Jerome&apos;, ssn=u&apos;047-57-3233&apos;, occupation=u&apos;Occupational psychologist&apos;, age=21), Row(last_name=u&apos;Farmer&apos;, first_name=u&apos;Martin&apos;, ssn=u&apos;435-04-0320&apos;, occupation=u&apos;TEFL teacher&apos;, age=18), Row(last_name=u&apos;Martin&apos;, first_name=u&apos;Denise&apos;, ssn=u&apos;232-33-6223&apos;, occupation=u&apos;Primary school teacher&apos;, age=30), Row(last_name=u&apos;Gross&apos;, first_name=u&apos;Madison&apos;, ssn=u&apos;158-08-6750&apos;, occupation=u&apos;Mental health nurse&apos;, age=2), Row(last_name=u&apos;Frederick&apos;, first_name=u&apos;Daniel&apos;, ssn=u&apos;505-21-9276&apos;, occupation=u&apos;Production engineer&apos;, age=5), Row(last_name=u&apos;Clark&apos;, first_name=u&apos;Amy&apos;, ssn=u&apos;183-30-3218&apos;, occupation=u&apos;Education officer, museum&apos;, age=36), Row(last_name=u&apos;Garner&apos;, first_name=u&apos;Laura&apos;, ssn=u&apos;861-38-0228&apos;, occupation=u&apos;Museum/gallery conservator&apos;, age=25), Row(last_name=u&apos;Ramirez&apos;, first_name=u&apos;Gerald&apos;, ssn=u&apos;186-92-1482&apos;, occupation=u&apos;Producer, radio&apos;, age=35), Row(last_name=u&apos;Miles&apos;, first_name=u&apos;James&apos;, ssn=u&apos;891-37-2762&apos;, occupation=u&apos;Health visitor&apos;, age=7), Row(last_name=u&apos;Carey&apos;, first_name=u&apos;Michelle&apos;, ssn=u&apos;803-55-7506&apos;, occupation=u&apos;Scientist, research (maths)&apos;, age=41), Row(last_name=u&apos;Harris&apos;, first_name=u&apos;Joshua&apos;, ssn=u&apos;152-55-8567&apos;, occupation=u&apos;Nutritional therapist&apos;, age=42), Row(last_name=u&apos;Flores&apos;, first_name=u&apos;Debra&apos;, ssn=u&apos;848-01-8689&apos;, occupation=u&apos;Architect&apos;, age=41), Row(last_name=u&apos;Brown&apos;, first_name=u&apos;Tina&apos;, ssn=u&apos;690-20-9271&apos;, occupation=u&apos;Furniture conservator/restorer&apos;, age=35), Row(last_name=u&apos;Davis&apos;, first_name=u&apos;Destiny&apos;, ssn=u&apos;361-58-2113&apos;, occupation=u&apos;Designer, ceramics/pottery&apos;, age=39), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Laurie&apos;, ssn=u&apos;714-17-6911&apos;, occupation=u&apos;Financial manager&apos;, age=13), Row(last_name=u&apos;Carpenter&apos;, first_name=u&apos;Sarah&apos;, ssn=u&apos;250-25-5903&apos;, occupation=u&apos;Actuary&apos;, age=21), Row(last_name=u&apos;Ward&apos;, first_name=u&apos;Terri&apos;, ssn=u&apos;151-76-1895&apos;, occupation=u&apos;Plant breeder/geneticist&apos;, age=23), Row(last_name=u&apos;Miller&apos;, first_name=u&apos;Mariah&apos;, ssn=u&apos;179-55-6664&apos;, occupation=u&apos;Advertising art director&apos;, age=13), Row(last_name=u&apos;Martin&apos;, first_name=u&apos;Curtis&apos;, ssn=u&apos;703-58-0090&apos;, occupation=u&apos;Medical physicist&apos;, age=14), Row(last_name=u&apos;Clements&apos;, first_name=u&apos;Jesse&apos;, ssn=u&apos;670-40-5655&apos;, occupation=u&apos;Teacher, adult education&apos;, age=41), Row(last_name=u&apos;Ortiz&apos;, first_name=u&apos;Kristen&apos;, ssn=u&apos;865-07-2179&apos;, occupation=u&apos;Control and instrumentation engineer&apos;, age=34), Row(last_name=u&apos;Myers&apos;, first_name=u&apos;Paula&apos;, ssn=u&apos;025-56-5469&apos;, occupation=u&apos;Research scientist (maths)&apos;, age=24), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Lisa&apos;, ssn=u&apos;123-02-6786&apos;, occupation=u&apos;Psychotherapist, child&apos;, age=9), Row(last_name=u&apos;Bates&apos;, first_name=u&apos;Kristina&apos;, ssn=u&apos;008-38-0836&apos;, occupation=u&apos;Probation officer&apos;, age=10), Row(last_name=u&apos;Solis&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;011-79-8500&apos;, occupation=u&apos;Production assistant, radio&apos;, age=5), Row(last_name=u&apos;Cowan&apos;, first_name=u&apos;Randall&apos;, ssn=u&apos;230-07-6182&apos;, occupation=u&apos;English as a second language teacher&apos;, age=26), Row(last_name=u&apos;Hudson&apos;, first_name=u&apos;Maria&apos;, ssn=u&apos;071-69-8159&apos;, occupation=u&apos;Sub&apos;, age=7), Row(last_name=u&apos;Kramer&apos;, first_name=u&apos;Shannon&apos;, ssn=u&apos;291-73-3440&apos;, occupation=u&apos;Surgeon&apos;, age=5), Row(last_name=u&apos;Frederick&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;629-98-7923&apos;, occupation=u&apos;Medical sales representative&apos;, age=3), Row(last_name=u&apos;Young&apos;, first_name=u&apos;John&apos;, ssn=u&apos;308-70-4051&apos;, occupation=u&apos;Further education lecturer&apos;, age=13), Row(last_name=u&apos;Burgess&apos;, first_name=u&apos;Aaron&apos;, ssn=u&apos;804-83-3583&apos;, occupation=u&apos;Chartered public finance accountant&apos;, age=14), Row(last_name=u&apos;Foster&apos;, first_name=u&apos;Kristi&apos;, ssn=u&apos;657-12-3077&apos;, occupation=u&apos;Paediatric nurse&apos;, age=29), Row(last_name=u&apos;Estrada&apos;, first_name=u&apos;Jonathon&apos;, ssn=u&apos;614-72-0253&apos;, occupation=u&apos;Engineer, chemical&apos;, age=46), Row(last_name=u&apos;Hensley&apos;, first_name=u&apos;Erica&apos;, ssn=u&apos;881-90-4738&apos;, occupation=u&apos;Garment/textile technologist&apos;, age=7), Row(last_name=u&apos;Elliott&apos;, first_name=u&apos;Duane&apos;, ssn=u&apos;359-64-0476&apos;, occupation=u&apos;Restaurant manager&apos;, age=32), Row(last_name=u&apos;Hunter&apos;, first_name=u&apos;Brian&apos;, ssn=u&apos;392-83-0709&apos;, occupation=u&apos;Nature conservation officer&apos;, age=42), Row(last_name=u&apos;Bailey&apos;, first_name=u&apos;Sydney&apos;, ssn=u&apos;276-05-6482&apos;, occupation=u&apos;Insurance claims handler&apos;, age=18), Row(last_name=u&apos;Nguyen&apos;, first_name=u&apos;Erika&apos;, ssn=u&apos;276-57-8816&apos;, occupation=u&apos;Field seismologist&apos;, age=39), Row(last_name=u&apos;Bryant&apos;, first_name=u&apos;Charles&apos;, ssn=u&apos;360-58-9234&apos;, occupation=u&apos;Clinical cytogeneticist&apos;, age=8), Row(last_name=u&apos;Lopez&apos;, first_name=u&apos;Chelsea&apos;, ssn=u&apos;185-33-2334&apos;, occupation=u&apos;Chartered certified accountant&apos;, age=37), Row(last_name=u&apos;Durham&apos;, first_name=u&apos;Sarah&apos;, ssn=u&apos;682-48-9485&apos;, occupation=u&apos;Environmental education officer&apos;, age=37), Row(last_name=u&apos;White&apos;, first_name=u&apos;Christina&apos;, ssn=u&apos;431-03-2203&apos;, occupation=u&apos;Accounting technician&apos;, age=5), Row(last_name=u&apos;Perry&apos;, first_name=u&apos;Chad&apos;, ssn=u&apos;799-31-2527&apos;, occupation=u&apos;Operational investment banker&apos;, age=10), Row(last_name=u&apos;Rhodes&apos;, first_name=u&apos;William&apos;, ssn=u&apos;703-34-5967&apos;, occupation=u&apos;Advertising account planner&apos;, age=22), Row(last_name=u&apos;Bartlett&apos;, first_name=u&apos;James&apos;, ssn=u&apos;394-67-0604&apos;, occupation=u&apos;Designer, blown glass/stained glass&apos;, age=36), Row(last_name=u&apos;Myers&apos;, first_name=u&apos;Kelsey&apos;, ssn=u&apos;073-13-7973&apos;, occupation=u&apos;Special effects artist&apos;, age=26), Row(last_name=u&apos;Nixon&apos;, first_name=u&apos;Derrick&apos;, ssn=u&apos;742-70-0051&apos;, occupation=u&apos;Food technologist&apos;, age=6), Row(last_name=u&apos;Valentine&apos;, first_name=u&apos;Melissa&apos;, ssn=u&apos;062-75-8765&apos;, occupation=u&apos;Designer, television/film set&apos;, age=3), Row(last_name=u&apos;Jones&apos;, first_name=u&apos;Natalie&apos;, ssn=u&apos;889-40-2800&apos;, occupation=u&apos;Museum/gallery conservator&apos;, age=4), Row(last_name=u&apos;Murphy&apos;, first_name=u&apos;Thomas&apos;, ssn=u&apos;573-45-1181&apos;, occupation=u&apos;Seismic interpreter&apos;, age=24), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Tracy&apos;, ssn=u&apos;387-28-8771&apos;, occupation=u&apos;Private music teacher&apos;, age=8), Row(last_name=u&apos;Rodriguez&apos;, first_name=u&apos;Bryan&apos;, ssn=u&apos;742-94-9047&apos;, occupation=u&apos;Occupational psychologist&apos;, age=18), Row(last_name=u&apos;Davis&apos;, first_name=u&apos;David&apos;, ssn=u&apos;358-29-8499&apos;, occupation=u&apos;Publishing rights manager&apos;, age=6), Row(last_name=u&apos;Marshall&apos;, first_name=u&apos;Matthew&apos;, ssn=u&apos;794-36-6085&apos;, occupation=u&apos;Counsellor&apos;, age=5), Row(last_name=u&apos;Riley&apos;, first_name=u&apos;Jessica&apos;, ssn=u&apos;171-92-9984&apos;, occupation=u&apos;Artist&apos;, age=25), Row(last_name=u&apos;Cooper&apos;, first_name=u&apos;Daniel&apos;, ssn=u&apos;485-36-0896&apos;, occupation=u&apos;Recycling officer&apos;, age=20), Row(last_name=u&apos;Perry&apos;, first_name=u&apos;Jessica&apos;, ssn=u&apos;517-53-3991&apos;, occupation=u&apos;Horticulturist, commercial&apos;, age=37), Row(last_name=u&apos;Herrera&apos;, first_name=u&apos;John&apos;, ssn=u&apos;248-29-5580&apos;, occupation=u&apos;Therapist, horticultural&apos;, age=11), Row(last_name=u&apos;Francis&apos;, first_name=u&apos;Joel&apos;, ssn=u&apos;559-19-9896&apos;, occupation=u&apos;Recycling officer&apos;, age=10), Row(last_name=u&apos;Sutton&apos;, first_name=u&apos;Joseph&apos;, ssn=u&apos;163-97-7959&apos;, occupation=u&apos;Investment banker, operational&apos;, age=43), Row(last_name=u&apos;Barry&apos;, first_name=u&apos;Jesus&apos;, ssn=u&apos;652-82-6121&apos;, occupation=u&apos;Product designer&apos;, age=26), Row(last_name=u&apos;Mckinney&apos;, first_name=u&apos;Brett&apos;, ssn=u&apos;852-77-2607&apos;, occupation=u&apos;Graphic designer&apos;, age=11), Row(last_name=u&apos;Moore&apos;, first_name=u&apos;Amy&apos;, ssn=u&apos;209-33-3136&apos;, occupation=u&apos;Technical brewer&apos;, age=38), Row(last_name=u&apos;Leonard&apos;, first_name=u&apos;Brooke&apos;, ssn=u&apos;810-99-6228&apos;, occupation=u&apos;Geographical information systems officer&apos;, age=10), Row(last_name=u&apos;Hopkins&apos;, first_name=u&apos;Andrea&apos;, ssn=u&apos;130-82-3102&apos;, occupation=u&apos;Immunologist&apos;, age=33), Row(last_name=u&apos;Hernandez&apos;, first_name=u&apos;Omar&apos;, ssn=u&apos;289-24-7458&apos;, occupation=u&apos;IT consultant&apos;, age=13), Row(last_name=u&apos;Matthews&apos;, first_name=u&apos;Carrie&apos;, ssn=u&apos;537-11-4295&apos;, occupation=u&apos;Community education officer&apos;, age=22), Row(last_name=u&apos;Mayo&apos;, first_name=u&apos;Lucas&apos;, ssn=u&apos;809-18-4668&apos;, occupation=u&apos;Surveyor, building&apos;, age=24), Row(last_name=u&apos;Bailey&apos;, first_name=u&apos;Heidi&apos;, ssn=u&apos;022-86-7761&apos;, occupation=u&apos;Actor&apos;, age=41), Row(last_name=u&apos;Horn&apos;, first_name=u&apos;Brent&apos;, ssn=u&apos;481-86-9803&apos;, occupation=u&apos;Photographer&apos;, age=40), Row(last_name=u&apos;Johnson&apos;, first_name=u&apos;Ashley&apos;, ssn=u&apos;707-27-2864&apos;, occupation=u&apos;Industrial buyer&apos;, age=42), Row(last_name=u&apos;Higgins&apos;, first_name=u&apos;Antonio&apos;, ssn=u&apos;217-47-2995&apos;, occupation=u&apos;Geoscientist&apos;, age=12), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;Sarah&apos;, ssn=u&apos;885-76-7474&apos;, occupation=u&apos;Trade mark attorney&apos;, age=22), Row(last_name=u&apos;Hampton&apos;, first_name=u&apos;Nicholas&apos;, ssn=u&apos;344-07-0218&apos;, occupation=u&apos;Clinical cytogeneticist&apos;, age=34), Row(last_name=u&apos;Orr&apos;, first_name=u&apos;Victoria&apos;, ssn=u&apos;738-07-2960&apos;, occupation=u&apos;Therapist, nutritional&apos;, age=25), Row(last_name=u&apos;Lynch&apos;, first_name=u&apos;Eileen&apos;, ssn=u&apos;389-63-8648&apos;, occupation=u&apos;Electronics engineer&apos;, age=10), Row(last_name=u&apos;Willis&apos;, first_name=u&apos;Justin&apos;, ssn=u&apos;646-87-5378&apos;, occupation=u&apos;Tree surgeon&apos;, age=13), Row(last_name=u&apos;Riley&apos;, first_name=u&apos;Shane&apos;, ssn=u&apos;449-77-3538&apos;, occupation=u&apos;Music therapist&apos;, age=3), Row(last_name=u&apos;Carter&apos;, first_name=u&apos;Angel&apos;, ssn=u&apos;255-41-3386&apos;, occupation=u&apos;Sales promotion account executive&apos;, age=9), Row(last_name=u&apos;Melissa&apos;, first_name=u&apos;Mrs.&apos;, ssn=u&apos;043-99-8032&apos;, occupation=u&apos;Lawyer&apos;, age=24), Row(last_name=u&apos;Reyes&apos;, first_name=u&apos;Misty&apos;, ssn=u&apos;035-93-2365&apos;, occupation=u&apos;Energy manager&apos;, age=34), Row(last_name=u&apos;Ramirez&apos;, first_name=u&apos;Dustin&apos;, ssn=u&apos;723-48-4040&apos;, occupation=u&apos;Print production planner&apos;, age=33), Row(last_name=u&apos;Simmons&apos;, first_name=u&apos;Timothy&apos;, ssn=u&apos;154-10-8220&apos;, occupation=u&apos;Programmer, applications&apos;, age=17), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Tiffany&apos;, ssn=u&apos;446-74-9493&apos;, occupation=u&apos;Electronics engineer&apos;, age=30), Row(last_name=u&apos;Kelley&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;861-78-9237&apos;, occupation=u&apos;Records manager&apos;, age=4), Row(last_name=u&apos;Taylor&apos;, first_name=u&apos;Melissa&apos;, ssn=u&apos;057-86-1542&apos;, occupation=u&apos;Scientist, marine&apos;, age=16), Row(last_name=u&apos;Wilkinson&apos;, first_name=u&apos;Joshua&apos;, ssn=u&apos;508-96-5519&apos;, occupation=u&apos;Corporate treasurer&apos;, age=31), Row(last_name=u&apos;Le&apos;, first_name=u&apos;Chase&apos;, ssn=u&apos;310-32-0801&apos;, occupation=u&apos;Horticultural therapist&apos;, age=13), Row(last_name=u&apos;Barker&apos;, first_name=u&apos;Sarah&apos;, ssn=u&apos;426-44-8612&apos;, occupation=u&apos;Records manager&apos;, age=3), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;William&apos;, ssn=u&apos;250-14-6199&apos;, occupation=u&apos;Production assistant, radio&apos;, age=36), Row(last_name=u&apos;Perkins&apos;, first_name=u&apos;Lawrence&apos;, ssn=u&apos;421-42-7657&apos;, occupation=u&apos;Designer, interior/spatial&apos;, age=21), Row(last_name=u&apos;Gallegos&apos;, first_name=u&apos;Joseph&apos;, ssn=u&apos;260-65-5995&apos;, occupation=u&apos;Investment banker, operational&apos;, age=2), Row(last_name=u&apos;Thompson&apos;, first_name=u&apos;Amy&apos;, ssn=u&apos;311-31-7843&apos;, occupation=u&apos;Cartographer&apos;, age=2), Row(last_name=u&apos;Thomas&apos;, first_name=u&apos;Daryl&apos;, ssn=u&apos;823-26-0650&apos;, occupation=u&apos;Engineer, water&apos;, age=41), Row(last_name=u&apos;Lewis&apos;, first_name=u&apos;Robert&apos;, ssn=u&apos;453-07-1148&apos;, occupation=u&apos;Social worker&apos;, age=13), Row(last_name=u&apos;Reeves&apos;, first_name=u&apos;Jennifer&apos;, ssn=u&apos;545-98-2229&apos;, occupation=u&quot;Politician&apos;s assistant&quot;, age=42), Row(last_name=u&apos;Barrett&apos;, first_name=u&apos;Mary&apos;, ssn=u&apos;442-43-1113&apos;, occupation=u&apos;Acupuncturist&apos;, age=31), Row(last_name=u&apos;Hernandez&apos;, first_name=u&apos;Jacqueline&apos;, ssn=u&apos;712-58-1239&apos;, occupation=u&apos;Production engineer&apos;, age=8), Row(last_name=u&apos;Lewis&apos;, first_name=u&apos;Joseph&apos;, ssn=u&apos;453-91-2434&apos;, occupation=u&apos;Forensic scientist&apos;, age=14), Row(last_name=u&apos;Parker&apos;, first_name=u&apos;Kristi&apos;, ssn=u&apos;790-19-7296&apos;, occupation=u&apos;Electrical engineer&apos;, age=25), Row(last_name=u&apos;Young&apos;, first_name=u&apos;Craig&apos;, ssn=u&apos;068-45-9639&apos;, occupation=u&apos;Psychologist, clinical&apos;, age=3), Row(last_name=u&apos;Horton&apos;, first_name=u&apos;Traci&apos;, ssn=u&apos;516-86-7759&apos;, occupation=u&apos;Social worker&apos;, age=40), Row(last_name=u&apos;Berg&apos;, first_name=u&apos;Walter&apos;, ssn=u&apos;175-01-6307&apos;, occupation=u&apos;Engineer, manufacturing&apos;, age=27), Row(last_name=u&apos;Welch&apos;, first_name=u&apos;Elizabeth&apos;, ssn=u&apos;668-76-9591&apos;, occupation=u&apos;Engineer, biomedical&apos;, age=25), Row(last_name=u&apos;Mann&apos;, first_name=u&apos;Mark&apos;, ssn=u&apos;558-40-9113&apos;, occupation=u&apos;Education officer, community&apos;, age=26), Row(last_name=u&apos;Adams&apos;, first_name=u&apos;Anne&apos;, ssn=u&apos;600-21-6179&apos;, occupation=u&apos;Scientist, research (life sciences)&apos;, age=46), Row(last_name=u&apos;Ortega&apos;, first_name=u&apos;Jennifer&apos;, ssn=u&apos;785-14-6169&apos;, occupation=u&apos;Drilling engineer&apos;, age=23), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;David&apos;, ssn=u&apos;013-52-1674&apos;, occupation=u&apos;Systems analyst&apos;, age=42), Row(last_name=u&apos;Butler&apos;, first_name=u&apos;Terry&apos;, ssn=u&apos;689-27-1416&apos;, occupation=u&apos;Leisure centre manager&apos;, age=43), Row(last_name=u&apos;Torres&apos;, first_name=u&apos;Brittany&apos;, ssn=u&apos;632-88-8876&apos;, occupation=u&apos;Mining engineer&apos;, age=32), Row(last_name=u&apos;Martin&apos;, first_name=u&apos;Renee&apos;, ssn=u&apos;222-51-5019&apos;, occupation=u&apos;Conservation officer, historic buildings&apos;, age=13), Row(last_name=u&apos;Logan&apos;, first_name=u&apos;Nicholas&apos;, ssn=u&apos;275-17-8229&apos;, occupation=u&apos;Psychiatrist&apos;, age=11), Row(last_name=u&apos;Myers&apos;, first_name=u&apos;Sharon&apos;, ssn=u&apos;471-91-8967&apos;, occupation=u&apos;Clinical biochemist&apos;, age=14), Row(last_name=u&apos;Hardin&apos;, first_name=u&apos;Natalie&apos;, ssn=u&apos;201-91-0679&apos;, occupation=u&apos;Engineer, chemical&apos;, age=37), Row(last_name=u&apos;Perry&apos;, first_name=u&apos;Jodi&apos;, ssn=u&apos;736-34-8801&apos;, occupation=u&apos;Geologist, engineering&apos;, age=24), Row(last_name=u&apos;John&apos;, first_name=u&apos;Dr.&apos;, ssn=u&apos;548-64-9480&apos;, occupation=u&apos;Production manager&apos;, age=3), Row(last_name=u&apos;Ramirez&apos;, first_name=u&apos;William&apos;, ssn=u&apos;250-77-9423&apos;, occupation=u&apos;Administrator&apos;, age=16), Row(last_name=u&apos;Stewart&apos;, first_name=u&apos;Jason&apos;, ssn=u&apos;722-83-8739&apos;, occupation=u&apos;Exhibitions officer, museum/gallery&apos;, age=20), Row(last_name=u&apos;Hawkins&apos;, first_name=u&apos;Anna&apos;, ssn=u&apos;331-24-5030&apos;, occupation=u&apos;Colour technologist&apos;, age=17), Row(last_name=u&apos;Randolph&apos;, first_name=u&apos;Joe&apos;, ssn=u&apos;680-43-7591&apos;, occupation=u&apos;Meteorologist&apos;, age=31), Row(last_name=u&apos;Clark&apos;, first_name=u&apos;Cheryl&apos;, ssn=u&apos;573-17-4360&apos;, occupation=u&apos;Systems analyst&apos;, age=8), Row(last_name=u&apos;Reyes&apos;, first_name=u&apos;Jill&apos;, ssn=u&apos;294-05-3175&apos;, occupation=u&apos;Electrical engineer&apos;, age=21), Row(last_name=u&apos;Taylor&apos;, first_name=u&apos;Ashlee&apos;, ssn=u&apos;775-86-2123&apos;, occupation=u&apos;Higher education careers adviser&apos;, age=44), Row(last_name=u&apos;Hunt&apos;, first_name=u&apos;Patrick&apos;, ssn=u&apos;101-72-0975&apos;, occupation=u&apos;Therapist, art&apos;, age=43), Row(last_name=u&apos;Ortiz&apos;, first_name=u&apos;Dillon&apos;, ssn=u&apos;196-21-2698&apos;, occupation=u&apos;Clinical cytogeneticist&apos;, age=41), Row(last_name=u&apos;Young&apos;, first_name=u&apos;Jamie&apos;, ssn=u&apos;234-05-7032&apos;, occupation=u&apos;Colour technologist&apos;, age=16), Row(last_name=u&apos;Hampton&apos;, first_name=u&apos;Derrick&apos;, ssn=u&apos;512-16-9100&apos;, occupation=u&apos;Clinical embryologist&apos;, age=40), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;Sherri&apos;, ssn=u&apos;509-83-6533&apos;, occupation=u&apos;Control and instrumentation engineer&apos;, age=18), Row(last_name=u&apos;Kennedy&apos;, first_name=u&apos;Allison&apos;, ssn=u&apos;885-07-2518&apos;, occupation=u&apos;Market researcher&apos;, age=5), Row(last_name=u&apos;Rice&apos;, first_name=u&apos;Christina&apos;, ssn=u&apos;496-94-2666&apos;, occupation=u&apos;Public relations account executive&apos;, age=10), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Erin&apos;, ssn=u&apos;705-79-6682&apos;, occupation=u&apos;Cabin crew&apos;, age=9), Row(last_name=u&apos;Summers&apos;, first_name=u&apos;Carrie&apos;, ssn=u&apos;546-39-8666&apos;, occupation=u&apos;Producer, television/film/video&apos;, age=7), Row(last_name=u&apos;Elliott&apos;, first_name=u&apos;Jamie&apos;, ssn=u&apos;414-29-5329&apos;, occupation=u&apos;Local government officer&apos;, age=1), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Erin&apos;, ssn=u&apos;893-27-4992&apos;, occupation=u&apos;Radiation protection practitioner&apos;, age=27), Row(last_name=u&apos;Perkins&apos;, first_name=u&apos;James&apos;, ssn=u&apos;508-17-4643&apos;, occupation=u&apos;Graphic designer&apos;, age=1), Row(last_name=u&apos;Schultz&apos;, first_name=u&apos;Whitney&apos;, ssn=u&apos;227-48-8117&apos;, occupation=u&apos;Engineer, maintenance&apos;, age=17), Row(last_name=u&apos;Arnold&apos;, first_name=u&apos;Yvonne&apos;, ssn=u&apos;007-87-0678&apos;, occupation=u&apos;Gaffer&apos;, age=24), Row(last_name=u&apos;Johnson&apos;, first_name=u&apos;Ryan&apos;, ssn=u&apos;831-42-6981&apos;, occupation=u&apos;Chemist, analytical&apos;, age=13), Row(last_name=u&apos;Vaughn&apos;, first_name=u&apos;Jessica&apos;, ssn=u&apos;729-94-2091&apos;, occupation=u&apos;Product designer&apos;, age=25), Row(last_name=u&apos;Barajas&apos;, first_name=u&apos;Sharon&apos;, ssn=u&apos;828-48-0650&apos;, occupation=u&apos;Video editor&apos;, age=41), Row(last_name=u&apos;Martinez&apos;, first_name=u&apos;Dale&apos;, ssn=u&apos;321-88-4917&apos;, occupation=u&apos;Scientist, research (maths)&apos;, age=16), Row(last_name=u&apos;Miller&apos;, first_name=u&apos;Michelle&apos;, ssn=u&apos;844-46-8482&apos;, occupation=u&apos;Designer, interior/spatial&apos;, age=3), Row(last_name=u&apos;Lee&apos;, first_name=u&apos;Antonio&apos;, ssn=u&apos;053-17-0216&apos;, occupation=u&apos;Volunteer coordinator&apos;, age=31), Row(last_name=u&apos;Allen&apos;, first_name=u&apos;Troy&apos;, ssn=u&apos;155-92-1405&apos;, occupation=u&apos;Engineer, production&apos;, age=40), Row(last_name=u&apos;Patel&apos;, first_name=u&apos;Keith&apos;, ssn=u&apos;207-79-4285&apos;, occupation=u&apos;Probation officer&apos;, age=21), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Meagan&apos;, ssn=u&apos;332-98-2465&apos;, occupation=u&apos;Web designer&apos;, age=14), Row(last_name=u&apos;Mercado&apos;, first_name=u&apos;Denise&apos;, ssn=u&apos;283-03-4911&apos;, occupation=u&apos;Glass blower/designer&apos;, age=30), Row(last_name=u&apos;Wood&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;537-02-6134&apos;, occupation=u&apos;Midwife&apos;, age=7), Row(last_name=u&apos;Nichols&apos;, first_name=u&apos;Steven&apos;, ssn=u&apos;733-58-3920&apos;, occupation=u&apos;Scientist, biomedical&apos;, age=18), Row(last_name=u&apos;Howard&apos;, first_name=u&apos;Kathy&apos;, ssn=u&apos;716-74-0340&apos;, occupation=u&apos;Legal secretary&apos;, age=32), Row(last_name=u&apos;Fox&apos;, first_name=u&apos;Jacqueline&apos;, ssn=u&apos;774-97-6217&apos;, occupation=u&apos;Naval architect&apos;, age=32), Row(last_name=u&apos;Schultz&apos;, first_name=u&apos;Victoria&apos;, ssn=u&apos;711-54-8521&apos;, occupation=u&apos;Network engineer&apos;, age=20), Row(last_name=u&apos;Shaw&apos;, first_name=u&apos;Audrey&apos;, ssn=u&apos;195-89-6409&apos;, occupation=u&apos;Health and safety inspector&apos;, age=9), Row(last_name=u&apos;King&apos;, first_name=u&apos;Nicholas&apos;, ssn=u&apos;319-80-5824&apos;, occupation=u&apos;Optometrist&apos;, age=14), Row(last_name=u&apos;Roberts&apos;, first_name=u&apos;Adam&apos;, ssn=u&apos;696-69-7269&apos;, occupation=u&apos;Diagnostic radiographer&apos;, age=1), Row(last_name=u&apos;Nelson&apos;, first_name=u&apos;Erika&apos;, ssn=u&apos;222-91-9492&apos;, occupation=u&apos;Designer, blown glass/stained glass&apos;, age=25), Row(last_name=u&apos;Rowland&apos;, first_name=u&apos;Jason&apos;, ssn=u&apos;696-93-1973&apos;, occupation=u&apos;Financial controller&apos;, age=29), Row(last_name=u&apos;Davis&apos;, first_name=u&apos;Leah&apos;, ssn=u&apos;895-59-6262&apos;, occupation=u&apos;Environmental consultant&apos;, age=37), Row(last_name=u&apos;Johnson&apos;, first_name=u&apos;Lindsey&apos;, ssn=u&apos;426-26-2328&apos;, occupation=u&apos;Product designer&apos;, age=21), Row(last_name=u&apos;House&apos;, first_name=u&apos;Paul&apos;, ssn=u&apos;667-09-0898&apos;, occupation=u&apos;Fast food restaurant manager&apos;, age=31), Row(last_name=u&apos;Freeman&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;627-65-3521&apos;, occupation=u&apos;Engineer, manufacturing&apos;, age=0), Row(last_name=u&apos;Rangel&apos;, first_name=u&apos;Howard&apos;, ssn=u&apos;474-85-9840&apos;, occupation=u&apos;Volunteer coordinator&apos;, age=20), Row(last_name=u&apos;Price&apos;, first_name=u&apos;Benjamin&apos;, ssn=u&apos;854-58-3882&apos;, occupation=u&apos;Medical physicist&apos;, age=34), Row(last_name=u&apos;Solomon&apos;, first_name=u&apos;Angela&apos;, ssn=u&apos;357-64-9278&apos;, occupation=u&apos;Purchasing manager&apos;, age=45), Row(last_name=u&apos;Murphy&apos;, first_name=u&apos;James&apos;, ssn=u&apos;683-53-8426&apos;, occupation=u&apos;Psychologist, counselling&apos;, age=27), Row(last_name=u&apos;Wise&apos;, first_name=u&apos;Ariel&apos;, ssn=u&apos;417-19-2373&apos;, occupation=u&apos;Scientific laboratory technician&apos;, age=31), Row(last_name=u&apos;Hamilton&apos;, first_name=u&apos;Craig&apos;, ssn=u&apos;105-15-4161&apos;, occupation=u&apos;Holiday representative&apos;, age=22), Row(last_name=u&apos;Prince&apos;, first_name=u&apos;Walter&apos;, ssn=u&apos;805-69-6874&apos;, occupation=u&apos;Quarry manager&apos;, age=15), Row(last_name=u&apos;Ellison&apos;, first_name=u&apos;Donald&apos;, ssn=u&apos;504-79-8513&apos;, occupation=u&apos;Sales promotion account executive&apos;, age=44), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Ricky&apos;, ssn=u&apos;665-44-3213&apos;, occupation=u&apos;Production manager&apos;, age=8), Row(last_name=u&apos;Taylor&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;520-92-1427&apos;, occupation=u&apos;Editor, commissioning&apos;, age=37), Row(last_name=u&apos;Coleman&apos;, first_name=u&apos;Debbie&apos;, ssn=u&apos;165-10-1998&apos;, occupation=u&apos;Research scientist (life sciences)&apos;, age=23), Row(last_name=u&apos;Heath&apos;, first_name=u&apos;Jesse&apos;, ssn=u&apos;517-56-4629&apos;, occupation=u&apos;Building services engineer&apos;, age=14), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Nicole&apos;, ssn=u&apos;847-49-2168&apos;, occupation=u&apos;Private music teacher&apos;, age=44), Row(last_name=u&apos;Morales&apos;, first_name=u&apos;Brian&apos;, ssn=u&apos;805-26-1774&apos;, occupation=u&apos;Conservation officer, historic buildings&apos;, age=43), Row(last_name=u&apos;Zuniga&apos;, first_name=u&apos;Carrie&apos;, ssn=u&apos;173-87-2245&apos;, occupation=u&apos;Arboriculturist&apos;, age=36), Row(last_name=u&apos;Ross&apos;, first_name=u&apos;Tabitha&apos;, ssn=u&apos;415-32-9374&apos;, occupation=u&apos;Trade union research officer&apos;, age=37), Row(last_name=u&apos;Willie&apos;, first_name=u&apos;Mr.&apos;, ssn=u&apos;736-18-2420&apos;, occupation=u&apos;Accountant, chartered public finance&apos;, age=19), Row(last_name=u&apos;Drake&apos;, first_name=u&apos;April&apos;, ssn=u&apos;166-25-0395&apos;, occupation=u&apos;Dance movement psychotherapist&apos;, age=28), Row(last_name=u&apos;Lopez&apos;, first_name=u&apos;Janet&apos;, ssn=u&apos;459-70-7429&apos;, occupation=u&apos;Phytotherapist&apos;, age=13), Row(last_name=u&apos;Taylor&apos;, first_name=u&apos;William&apos;, ssn=u&apos;159-45-9638&apos;, occupation=u&apos;Magazine journalist&apos;, age=21), Row(last_name=u&apos;Caldwell&apos;, first_name=u&apos;John&apos;, ssn=u&apos;152-49-8466&apos;, occupation=u&apos;Administrator, Civil Service&apos;, age=3), Row(last_name=u&apos;Stewart&apos;, first_name=u&apos;Gregory&apos;, ssn=u&apos;639-29-8863&apos;, occupation=u&apos;Microbiologist&apos;, age=46), Row(last_name=u&apos;Ibarra&apos;, first_name=u&apos;Catherine&apos;, ssn=u&apos;203-66-8715&apos;, occupation=u&apos;Aid worker&apos;, age=45), Row(last_name=u&apos;Vargas&apos;, first_name=u&apos;Bradley&apos;, ssn=u&apos;059-24-3625&apos;, occupation=u&apos;Geophysicist/field seismologist&apos;, age=20), Row(last_name=u&apos;Decker&apos;, first_name=u&apos;Timothy&apos;, ssn=u&apos;475-58-6500&apos;, occupation=u&apos;Paramedic&apos;, age=26), Row(last_name=u&apos;Villarreal&apos;, first_name=u&apos;Ashley&apos;, ssn=u&apos;016-70-5168&apos;, occupation=u&apos;Public house manager&apos;, age=17), Row(last_name=u&apos;Burton&apos;, first_name=u&apos;Kevin&apos;, ssn=u&apos;882-83-3824&apos;, occupation=u&apos;Engineer, maintenance (IT)&apos;, age=15), Row(last_name=u&apos;Rodriguez&apos;, first_name=u&apos;Matthew&apos;, ssn=u&apos;098-77-3826&apos;, occupation=u&apos;Designer, multimedia&apos;, age=12), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;Brenda&apos;, ssn=u&apos;327-73-4507&apos;, occupation=u&apos;Bonds trader&apos;, age=4), Row(last_name=u&apos;Mcgee&apos;, first_name=u&apos;Brian&apos;, ssn=u&apos;613-36-4485&apos;, occupation=u&apos;Engineer, control and instrumentation&apos;, age=45), Row(last_name=u&apos;Bowman&apos;, first_name=u&apos;Robert&apos;, ssn=u&apos;071-70-4229&apos;, occupation=u&apos;Occupational hygienist&apos;, age=33), Row(last_name=u&apos;Rose&apos;, first_name=u&apos;Jerry&apos;, ssn=u&apos;031-18-6271&apos;, occupation=u&apos;Educational psychologist&apos;, age=34), Row(last_name=u&apos;Adams&apos;, first_name=u&apos;Steven&apos;, ssn=u&apos;056-05-6165&apos;, occupation=u&apos;Physiological scientist&apos;, age=39), Row(last_name=u&apos;Bennett&apos;, first_name=u&apos;Johnathan&apos;, ssn=u&apos;389-02-5406&apos;, occupation=u&apos;Quality manager&apos;, age=36), Row(last_name=u&apos;Ramirez&apos;, first_name=u&apos;Lauren&apos;, ssn=u&apos;836-11-8095&apos;, occupation=u&apos;Television/film/video producer&apos;, age=35), Row(last_name=u&apos;Russell&apos;, first_name=u&apos;Miguel&apos;, ssn=u&apos;882-39-9841&apos;, occupation=u&apos;Engineer, materials&apos;, age=46), Row(last_name=u&apos;Mata&apos;, first_name=u&apos;Matthew&apos;, ssn=u&apos;705-65-8373&apos;, occupation=u&apos;Accountant, chartered management&apos;, age=34), Row(last_name=u&apos;Davidson&apos;, first_name=u&apos;Kendra&apos;, ssn=u&apos;684-63-6241&apos;, occupation=u&apos;Medical illustrator&apos;, age=10), Row(last_name=u&apos;Flores&apos;, first_name=u&apos;Paul&apos;, ssn=u&apos;360-73-9441&apos;, occupation=u&apos;Pharmacologist&apos;, age=43), Row(last_name=u&apos;Clark&apos;, first_name=u&apos;Crystal&apos;, ssn=u&apos;509-53-8700&apos;, occupation=u&apos;Sound technician, broadcasting/film/video&apos;, age=41), Row(last_name=u&apos;James&apos;, first_name=u&apos;Dr.&apos;, ssn=u&apos;687-94-5466&apos;, occupation=u&apos;Oncologist&apos;, age=9), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Jeffrey&apos;, ssn=u&apos;871-32-3550&apos;, occupation=u&apos;Engineer, petroleum&apos;, age=10), Row(last_name=u&apos;Jordan&apos;, first_name=u&apos;William&apos;, ssn=u&apos;457-37-9828&apos;, occupation=u&apos;Artist&apos;, age=22), Row(last_name=u&apos;Rodriguez&apos;, first_name=u&apos;Jack&apos;, ssn=u&apos;873-30-7193&apos;, occupation=u&apos;Statistician&apos;, age=1), Row(last_name=u&apos;Osborne&apos;, first_name=u&apos;Allison&apos;, ssn=u&apos;680-55-9136&apos;, occupation=u&apos;Librarian, academic&apos;, age=31), Row(last_name=u&apos;Rodgers&apos;, first_name=u&apos;Ronald&apos;, ssn=u&apos;179-02-8263&apos;, occupation=u&apos;Surveyor, hydrographic&apos;, age=29), Row(last_name=u&apos;King&apos;, first_name=u&apos;Charles&apos;, ssn=u&apos;849-82-4978&apos;, occupation=u&apos;Financial trader&apos;, age=31), Row(last_name=u&apos;Wilson&apos;, first_name=u&apos;Robert&apos;, ssn=u&apos;657-46-9119&apos;, occupation=u&apos;Broadcast journalist&apos;, age=35), Row(last_name=u&apos;Holmes&apos;, first_name=u&apos;Randy&apos;, ssn=u&apos;433-14-9255&apos;, occupation=u&apos;Research scientist (maths)&apos;, age=28), Row(last_name=u&apos;Le&apos;, first_name=u&apos;Laura&apos;, ssn=u&apos;467-14-0692&apos;, occupation=u&apos;Government social research officer&apos;, age=43), Row(last_name=u&apos;Heather&apos;, first_name=u&apos;Dr.&apos;, ssn=u&apos;349-90-5947&apos;, occupation=u&apos;Administrator, Civil Service&apos;, age=11), Row(last_name=u&apos;Sims&apos;, first_name=u&apos;Stephen&apos;, ssn=u&apos;305-66-2112&apos;, occupation=u&apos;Software engineer&apos;, age=16), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;Sarah&apos;, ssn=u&apos;231-08-7297&apos;, occupation=u&apos;Administrator, local government&apos;, age=3), Row(last_name=u&apos;Downs&apos;, first_name=u&apos;Alyssa&apos;, ssn=u&apos;172-09-8917&apos;, occupation=u&apos;Dispensing optician&apos;, age=19), Row(last_name=u&apos;Collins&apos;, first_name=u&apos;David&apos;, ssn=u&apos;100-90-0643&apos;, occupation=u&apos;Public relations officer&apos;, age=3), Row(last_name=u&apos;Washington&apos;, first_name=u&apos;Jean&apos;, ssn=u&apos;073-82-5103&apos;, occupation=u&apos;Dietitian&apos;, age=8), Row(last_name=u&apos;Jordan&apos;, first_name=u&apos;Gerald&apos;, ssn=u&apos;526-79-3061&apos;, occupation=u&apos;Counselling psychologist&apos;, age=37), Row(last_name=u&apos;Hernandez&apos;, first_name=u&apos;Lindsay&apos;, ssn=u&apos;033-35-8210&apos;, occupation=u&apos;Electronics engineer&apos;, age=15), Row(last_name=u&apos;Johnson&apos;, first_name=u&apos;Kelly&apos;, ssn=u&apos;661-70-8200&apos;, occupation=u&apos;Therapist, occupational&apos;, age=19), Row(last_name=u&apos;Jackson&apos;, first_name=u&apos;William&apos;, ssn=u&apos;374-02-3134&apos;, occupation=u&apos;Chemical engineer&apos;, age=34), Row(last_name=u&apos;Foley&apos;, first_name=u&apos;Danny&apos;, ssn=u&apos;257-05-0070&apos;, occupation=u&apos;Pathologist&apos;, age=15), Row(last_name=u&apos;Jones&apos;, first_name=u&apos;Amanda&apos;, ssn=u&apos;806-82-3781&apos;, occupation=u&apos;Investment banker, corporate&apos;, age=41), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Tracy&apos;, ssn=u&apos;594-74-5478&apos;, occupation=u&apos;Environmental education officer&apos;, age=14), Row(last_name=u&apos;Chaney&apos;, first_name=u&apos;Elizabeth&apos;, ssn=u&apos;884-45-7908&apos;, occupation=u&apos;Engineer, aeronautical&apos;, age=20), Row(last_name=u&apos;Figueroa&apos;, first_name=u&apos;Lisa&apos;, ssn=u&apos;760-08-9332&apos;, occupation=u&apos;Fitness centre manager&apos;, age=21), Row(last_name=u&apos;Hanson&apos;, first_name=u&apos;Jessica&apos;, ssn=u&apos;330-25-0904&apos;, occupation=u&apos;Health and safety inspector&apos;, age=14), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Phyllis&apos;, ssn=u&apos;122-31-9779&apos;, occupation=u&apos;Mudlogger&apos;, age=1), Row(last_name=u&apos;Combs&apos;, first_name=u&apos;Heather&apos;, ssn=u&apos;782-94-8814&apos;, occupation=u&apos;Logistics and distribution manager&apos;, age=10), Row(last_name=u&apos;Franklin&apos;, first_name=u&apos;James&apos;, ssn=u&apos;229-52-2327&apos;, occupation=u&apos;Surveyor, insurance&apos;, age=25), Row(last_name=u&apos;Cochran&apos;, first_name=u&apos;Michele&apos;, ssn=u&apos;602-36-4532&apos;, occupation=u&apos;Veterinary surgeon&apos;, age=10), Row(last_name=u&apos;Ferrell&apos;, first_name=u&apos;Robin&apos;, ssn=u&apos;223-93-5412&apos;, occupation=u&apos;Fast food restaurant manager&apos;, age=35), Row(last_name=u&apos;Thompson&apos;, first_name=u&apos;Gary&apos;, ssn=u&apos;676-25-7220&apos;, occupation=u&apos;Mining engineer&apos;, age=11), Row(last_name=u&apos;Collins&apos;, first_name=u&apos;John&apos;, ssn=u&apos;653-92-4623&apos;, occupation=u&apos;Information systems manager&apos;, age=20), Row(last_name=u&apos;Sweeney&apos;, first_name=u&apos;James&apos;, ssn=u&apos;286-52-6505&apos;, occupation=u&apos;Engineer, communications&apos;, age=22), Row(last_name=u&apos;White&apos;, first_name=u&apos;Benjamin&apos;, ssn=u&apos;700-58-4881&apos;, occupation=u&apos;Oceanographer&apos;, age=42), Row(last_name=u&apos;Ramirez&apos;, first_name=u&apos;Jessica&apos;, ssn=u&apos;287-86-9559&apos;, occupation=u&apos;Advertising art director&apos;, age=18), Row(last_name=u&apos;Conner&apos;, first_name=u&apos;Joshua&apos;, ssn=u&apos;093-62-2648&apos;, occupation=u&apos;Press sub&apos;, age=29), Row(last_name=u&apos;Perez&apos;, first_name=u&apos;Michelle&apos;, ssn=u&apos;553-44-3525&apos;, occupation=u&apos;Engineer, materials&apos;, age=14), Row(last_name=u&apos;Powell&apos;, first_name=u&apos;Erin&apos;, ssn=u&apos;512-57-9489&apos;, occupation=u&apos;Special educational needs teacher&apos;, age=34), Row(last_name=u&apos;Nguyen&apos;, first_name=u&apos;Robert&apos;, ssn=u&apos;471-50-0214&apos;, occupation=u&apos;Engineer, civil (consulting)&apos;, age=39), Row(last_name=u&apos;Hanson&apos;, first_name=u&apos;Tiffany&apos;, ssn=u&apos;237-20-2813&apos;, occupation=u&apos;Administrator, arts&apos;, age=2), Row(last_name=u&apos;Cannon&apos;, first_name=u&apos;Mark&apos;, ssn=u&apos;520-83-7981&apos;, occupation=u&apos;Communications engineer&apos;, age=10), Row(last_name=u&apos;Harrison&apos;, first_name=u&apos;James&apos;, ssn=u&apos;339-65-0720&apos;, occupation=u&apos;Cytogeneticist&apos;, age=5), Row(last_name=u&apos;Thompson&apos;, first_name=u&apos;Abigail&apos;, ssn=u&apos;633-24-3685&apos;, occupation=u&apos;Trading standards officer&apos;, age=34), Row(last_name=u&apos;Cooper&apos;, first_name=u&apos;Jeremy&apos;, ssn=u&apos;566-35-7226&apos;, occupation=u&apos;Tax inspector&apos;, age=35), Row(last_name=u&apos;Cunningham&apos;, first_name=u&apos;Sean&apos;, ssn=u&apos;160-59-3705&apos;, occupation=u&apos;Production designer, theatre/television/film&apos;, age=23), Row(last_name=u&apos;Gill&apos;, first_name=u&apos;Lisa&apos;, ssn=u&apos;202-33-9222&apos;, occupation=u&apos;Health and safety adviser&apos;, age=37), Row(last_name=u&apos;Cruz&apos;, first_name=u&apos;Martin&apos;, ssn=u&apos;391-64-3452&apos;, occupation=u&apos;Industrial/product designer&apos;, age=23), Row(last_name=u&apos;Wright&apos;, first_name=u&apos;Michaela&apos;, ssn=u&apos;092-01-4448&apos;, occupation=u&apos;Charity officer&apos;, age=24), Row(last_name=u&apos;Moses&apos;, first_name=u&apos;Jeffery&apos;, ssn=u&apos;692-69-1858&apos;, occupation=u&apos;Scientist, clinical (histocompatibility and immunogenetics)&apos;, age=35), Row(last_name=u&apos;Turner&apos;, first_name=u&apos;Mary&apos;, ssn=u&apos;888-94-3982&apos;, occupation=u&apos;Fisheries officer&apos;, age=35), Row(last_name=u&apos;Simpson&apos;, first_name=u&apos;David&apos;, ssn=u&apos;133-15-6670&apos;, occupation=u&apos;Toxicologist&apos;, age=24), Row(last_name=u&apos;Hampton&apos;, first_name=u&apos;Terry&apos;, ssn=u&apos;093-28-8829&apos;, occupation=u&apos;Ranger/warden&apos;, age=2), Row(last_name=u&apos;Nelson&apos;, first_name=u&apos;Kelly&apos;, ssn=u&apos;055-64-3061&apos;, occupation=u&apos;Doctor, general practice&apos;, age=19), Row(last_name=u&apos;Martinez&apos;, first_name=u&apos;Andrew&apos;, ssn=u&apos;822-15-0277&apos;, occupation=u&apos;Radiographer, diagnostic&apos;, age=6), Row(last_name=u&apos;Hansen&apos;, first_name=u&apos;Tanner&apos;, ssn=u&apos;841-32-0448&apos;, occupation=u&apos;Museum/gallery exhibitions officer&apos;, age=32), Row(last_name=u&apos;Woods&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;680-19-8510&apos;, occupation=u&apos;Operations geologist&apos;, age=25), Row(last_name=u&apos;Ward&apos;, first_name=u&apos;Ronald&apos;, ssn=u&apos;023-33-0385&apos;, occupation=u&apos;Careers adviser&apos;, age=23), Row(last_name=u&apos;King&apos;, first_name=u&apos;Emily&apos;, ssn=u&apos;284-23-0250&apos;, occupation=u&apos;Air broker&apos;, age=8), Row(last_name=u&apos;Wagner&apos;, first_name=u&apos;Elizabeth&apos;, ssn=u&apos;728-52-9871&apos;, occupation=u&apos;Ergonomist&apos;, age=0), Row(last_name=u&apos;Jenkins&apos;, first_name=u&apos;Patricia&apos;, ssn=u&apos;534-97-5524&apos;, occupation=u&apos;Operational researcher&apos;, age=0), Row(last_name=u&apos;Salinas&apos;, first_name=u&apos;Russell&apos;, ssn=u&apos;514-89-7885&apos;, occupation=u&apos;Medical laboratory scientific officer&apos;, age=35), Row(last_name=u&apos;Reid&apos;, first_name=u&apos;Cynthia&apos;, ssn=u&apos;326-19-6213&apos;, occupation=u&apos;Farm manager&apos;, age=46), Row(last_name=u&apos;Hall&apos;, first_name=u&apos;Justin&apos;, ssn=u&apos;761-05-1148&apos;, occupation=u&apos;Legal secretary&apos;, age=41), Row(last_name=u&apos;Nelson&apos;, first_name=u&apos;Cheryl&apos;, ssn=u&apos;354-14-6437&apos;, occupation=u&apos;Music tutor&apos;, age=29), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;Rachel&apos;, ssn=u&apos;329-36-2503&apos;, occupation=u&apos;Animal technologist&apos;, age=2), Row(last_name=u&apos;Torres&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;448-33-4134&apos;, occupation=u&apos;Phytotherapist&apos;, age=41), Row(last_name=u&apos;Brown&apos;, first_name=u&apos;Angela&apos;, ssn=u&apos;016-08-8726&apos;, occupation=u&apos;Cartographer&apos;, age=28), Row(last_name=u&apos;Ward&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;086-98-3792&apos;, occupation=u&apos;Social research officer, government&apos;, age=7), Row(last_name=u&apos;Reed&apos;, first_name=u&apos;Karen&apos;, ssn=u&apos;452-59-5983&apos;, occupation=u&apos;Tourism officer&apos;, age=11), Row(last_name=u&apos;Johnson&apos;, first_name=u&apos;Sabrina&apos;, ssn=u&apos;703-80-7437&apos;, occupation=u&apos;Retail merchandiser&apos;, age=19), Row(last_name=u&apos;Butler&apos;, first_name=u&apos;Raymond&apos;, ssn=u&apos;342-14-1447&apos;, occupation=u&apos;Production designer, theatre/television/film&apos;, age=44), Row(last_name=u&apos;Sanchez&apos;, first_name=u&apos;Joseph&apos;, ssn=u&apos;526-92-4482&apos;, occupation=u&apos;Data processing manager&apos;, age=15), Row(last_name=u&apos;Brown&apos;, first_name=u&apos;Mackenzie&apos;, ssn=u&apos;333-56-4194&apos;, occupation=u&apos;Research scientist (physical sciences)&apos;, age=13), Row(last_name=u&apos;Bates&apos;, first_name=u&apos;Chad&apos;, ssn=u&apos;463-70-8041&apos;, occupation=u&apos;Engineer, electrical&apos;, age=40), Row(last_name=u&apos;Love&apos;, first_name=u&apos;Jose&apos;, ssn=u&apos;264-11-9753&apos;, occupation=u&apos;Magazine features editor&apos;, age=46), Row(last_name=u&apos;Ferguson&apos;, first_name=u&apos;Lauren&apos;, ssn=u&apos;410-49-4207&apos;, occupation=u&apos;Teacher, early years/pre&apos;, age=7), Row(last_name=u&apos;Mullen&apos;, first_name=u&apos;Arthur&apos;, ssn=u&apos;261-03-9503&apos;, occupation=u&apos;Education officer, community&apos;, age=11), Row(last_name=u&apos;Hurst&apos;, first_name=u&apos;Alexis&apos;, ssn=u&apos;811-15-1318&apos;, occupation=u&apos;Production manager&apos;, age=17), Row(last_name=u&apos;Wade&apos;, first_name=u&apos;Jeremiah&apos;, ssn=u&apos;150-87-5073&apos;, occupation=u&apos;Scientist, audiological&apos;, age=17), Row(last_name=u&apos;Ross&apos;, first_name=u&apos;Kathleen&apos;, ssn=u&apos;027-64-5393&apos;, occupation=u&apos;Restaurant manager, fast food&apos;, age=40), Row(last_name=u&apos;Guerra&apos;, first_name=u&apos;Jenna&apos;, ssn=u&apos;363-80-9072&apos;, occupation=u&apos;Nutritional therapist&apos;, age=38), Row(last_name=u&apos;Nguyen&apos;, first_name=u&apos;Joseph&apos;, ssn=u&apos;699-42-7795&apos;, occupation=u&apos;Structural engineer&apos;, age=5), Row(last_name=u&apos;Dixon&apos;, first_name=u&apos;Michelle&apos;, ssn=u&apos;770-38-3561&apos;, occupation=u&apos;Media planner&apos;, age=6), Row(last_name=u&apos;Hayden&apos;, first_name=u&apos;Mark&apos;, ssn=u&apos;434-88-7304&apos;, occupation=u&apos;Accounting technician&apos;, age=33), Row(last_name=u&apos;Kennedy&apos;, first_name=u&apos;Samantha&apos;, ssn=u&apos;728-22-5257&apos;, occupation=u&apos;Actuary&apos;, age=32), Row(last_name=u&apos;Perez&apos;, first_name=u&apos;George&apos;, ssn=u&apos;771-96-8998&apos;, occupation=u&apos;Tourism officer&apos;, age=17), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Kathryn&apos;, ssn=u&apos;642-05-3114&apos;, occupation=u&apos;Telecommunications researcher&apos;, age=27), Row(last_name=u&apos;Stanley&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;531-49-5070&apos;, occupation=u&apos;Medical secretary&apos;, age=44), Row(last_name=u&apos;Myers&apos;, first_name=u&apos;Tonya&apos;, ssn=u&apos;824-04-8860&apos;, occupation=u&apos;Leisure centre manager&apos;, age=35), Row(last_name=u&apos;Hill&apos;, first_name=u&apos;Ronald&apos;, ssn=u&apos;358-65-8691&apos;, occupation=u&apos;Printmaker&apos;, age=26), Row(last_name=u&apos;Martin&apos;, first_name=u&apos;Renee&apos;, ssn=u&apos;313-49-8921&apos;, occupation=u&apos;Copywriter, advertising&apos;, age=13), Row(last_name=u&apos;Orr&apos;, first_name=u&apos;Jenna&apos;, ssn=u&apos;441-97-5845&apos;, occupation=u&apos;Ceramics designer&apos;, age=19), Row(last_name=u&apos;Durham&apos;, first_name=u&apos;Diane&apos;, ssn=u&apos;205-17-8750&apos;, occupation=u&apos;Scientist, forensic&apos;, age=30), Row(last_name=u&apos;Graham&apos;, first_name=u&apos;Randy&apos;, ssn=u&apos;803-50-3586&apos;, occupation=u&apos;Industrial/product designer&apos;, age=9), Row(last_name=u&apos;Rodriguez&apos;, first_name=u&apos;Alan&apos;, ssn=u&apos;840-96-3667&apos;, occupation=u&apos;Product designer&apos;, age=40), Row(last_name=u&apos;Norman&apos;, first_name=u&apos;Linda&apos;, ssn=u&apos;236-11-7139&apos;, occupation=u&apos;Clinical embryologist&apos;, age=15), Row(last_name=u&apos;Rodriguez&apos;, first_name=u&apos;Lauren&apos;, ssn=u&apos;715-39-0614&apos;, occupation=u&apos;Psychiatric nurse&apos;, age=23), Row(last_name=u&apos;Peters&apos;, first_name=u&apos;Edward&apos;, ssn=u&apos;865-39-3313&apos;, occupation=u&apos;Chartered legal executive (England and Wales)&apos;, age=29), Row(last_name=u&apos;Torres&apos;, first_name=u&apos;Vincent&apos;, ssn=u&apos;442-94-5813&apos;, occupation=u&apos;Occupational therapist&apos;, age=20), Row(last_name=u&apos;Spencer&apos;, first_name=u&apos;Holly&apos;, ssn=u&apos;375-47-4203&apos;, occupation=u&apos;Radio producer&apos;, age=45), Row(last_name=u&apos;Miller&apos;, first_name=u&apos;Randy&apos;, ssn=u&apos;025-44-5431&apos;, occupation=u&apos;Hydrogeologist&apos;, age=38), Row(last_name=u&apos;Washington&apos;, first_name=u&apos;Jason&apos;, ssn=u&apos;860-02-0305&apos;, occupation=u&apos;Diplomatic Services operational officer&apos;, age=6), Row(last_name=u&apos;Gordon&apos;, first_name=u&apos;Joseph&apos;, ssn=u&apos;080-16-1239&apos;, occupation=u&apos;Restaurant manager&apos;, age=41), Row(last_name=u&apos;Caldwell&apos;, first_name=u&apos;Kevin&apos;, ssn=u&apos;422-79-3596&apos;, occupation=u&apos;Research officer, trade union&apos;, age=2), Row(last_name=u&apos;Swanson&apos;, first_name=u&apos;Billy&apos;, ssn=u&apos;634-87-9566&apos;, occupation=u&apos;Oncologist&apos;, age=8), Row(last_name=u&apos;Bass&apos;, first_name=u&apos;Thomas&apos;, ssn=u&apos;040-96-7792&apos;, occupation=u&apos;Geochemist&apos;, age=11), Row(last_name=u&apos;Nielsen&apos;, first_name=u&apos;David&apos;, ssn=u&apos;056-01-4808&apos;, occupation=u&apos;Trading standards officer&apos;, age=22), Row(last_name=u&apos;Coleman&apos;, first_name=u&apos;Anne&apos;, ssn=u&apos;321-78-6381&apos;, occupation=u&apos;Travel agency manager&apos;, age=46), Row(last_name=u&apos;Warner&apos;, first_name=u&apos;Angel&apos;, ssn=u&apos;551-19-4398&apos;, occupation=u&apos;Retail manager&apos;, age=42), Row(last_name=u&apos;Kennedy&apos;, first_name=u&apos;Jason&apos;, ssn=u&apos;140-30-1898&apos;, occupation=u&apos;Museum/gallery curator&apos;, age=29), Row(last_name=u&apos;Bell&apos;, first_name=u&apos;Nicole&apos;, ssn=u&apos;290-76-5520&apos;, occupation=u&apos;Scientist, physiological&apos;, age=3), Row(last_name=u&apos;Klein&apos;, first_name=u&apos;Brittany&apos;, ssn=u&apos;139-92-8863&apos;, occupation=u&apos;Field seismologist&apos;, age=12), Row(last_name=u&apos;Schroeder&apos;, first_name=u&apos;Cindy&apos;, ssn=u&apos;124-68-4870&apos;, occupation=u&apos;Advertising account planner&apos;, age=33), Row(last_name=u&apos;Stevenson&apos;, first_name=u&apos;Steven&apos;, ssn=u&apos;402-50-4393&apos;, occupation=u&apos;Therapist, occupational&apos;, age=41), Row(last_name=u&apos;Stewart&apos;, first_name=u&apos;Christina&apos;, ssn=u&apos;775-68-4644&apos;, occupation=u&apos;Scientific laboratory technician&apos;, age=33), Row(last_name=u&apos;Singleton&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;015-18-8257&apos;, occupation=u&apos;Textile designer&apos;, age=37), Row(last_name=u&apos;Chen&apos;, first_name=u&apos;Billy&apos;, ssn=u&apos;531-53-5157&apos;, occupation=u&apos;Illustrator&apos;, age=28), Row(last_name=u&apos;Murillo&apos;, first_name=u&apos;Andrew&apos;, ssn=u&apos;324-60-6228&apos;, occupation=u&apos;Psychiatric nurse&apos;, age=17), Row(last_name=u&apos;House&apos;, first_name=u&apos;Cheryl&apos;, ssn=u&apos;145-76-1651&apos;, occupation=u&apos;Accountant, chartered&apos;, age=4), Row(last_name=u&apos;Parker&apos;, first_name=u&apos;Julie&apos;, ssn=u&apos;678-73-6151&apos;, occupation=u&apos;Engineer, building services&apos;, age=5), Row(last_name=u&apos;Fleming&apos;, first_name=u&apos;Brittany&apos;, ssn=u&apos;795-86-9686&apos;, occupation=u&apos;Market researcher&apos;, age=6), Row(last_name=u&apos;Reed&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;134-04-5542&apos;, occupation=u&apos;Designer, ceramics/pottery&apos;, age=28), Row(last_name=u&apos;Obrien&apos;, first_name=u&apos;Jeffery&apos;, ssn=u&apos;794-29-4070&apos;, occupation=u&apos;Airline pilot&apos;, age=45), Row(last_name=u&apos;Green&apos;, first_name=u&apos;Tonya&apos;, ssn=u&apos;165-38-0803&apos;, occupation=u&apos;Microbiologist&apos;, age=12), Row(last_name=u&apos;Hutchinson&apos;, first_name=u&apos;Heidi&apos;, ssn=u&apos;771-80-5961&apos;, occupation=u&apos;Air cabin crew&apos;, age=6), Row(last_name=u&apos;Wood&apos;, first_name=u&apos;Steven&apos;, ssn=u&apos;227-42-4694&apos;, occupation=u&apos;Psychologist, prison and probation services&apos;, age=21), Row(last_name=u&apos;Fritz&apos;, first_name=u&apos;Anthony&apos;, ssn=u&apos;372-30-4591&apos;, occupation=u&apos;Doctor, hospital&apos;, age=27), Row(last_name=u&apos;Jones&apos;, first_name=u&apos;Heather&apos;, ssn=u&apos;108-52-6426&apos;, occupation=u&apos;Arts administrator&apos;, age=23), Row(last_name=u&apos;Shaw&apos;, first_name=u&apos;Zachary&apos;, ssn=u&apos;422-06-8734&apos;, occupation=u&apos;Administrator, arts&apos;, age=25), Row(last_name=u&apos;Whitney&apos;, first_name=u&apos;Rachel&apos;, ssn=u&apos;559-51-9110&apos;, occupation=u&apos;Computer games developer&apos;, age=19), Row(last_name=u&apos;Alexander&apos;, first_name=u&apos;Nicole&apos;, ssn=u&apos;220-34-1674&apos;, occupation=u&apos;Health and safety adviser&apos;, age=36), Row(last_name=u&apos;Reed&apos;, first_name=u&apos;Rose&apos;, ssn=u&apos;309-15-4804&apos;, occupation=u&apos;Broadcast engineer&apos;, age=11), Row(last_name=u&apos;Schaefer&apos;, first_name=u&apos;Tommy&apos;, ssn=u&apos;655-01-3609&apos;, occupation=u&apos;Metallurgist&apos;, age=41), Row(last_name=u&apos;Hensley&apos;, first_name=u&apos;Anne&apos;, ssn=u&apos;255-73-2823&apos;, occupation=u&apos;Writer&apos;, age=6), Row(last_name=u&apos;Douglas&apos;, first_name=u&apos;Chloe&apos;, ssn=u&apos;255-44-2673&apos;, occupation=u&apos;Copywriter, advertising&apos;, age=35), Row(last_name=u&apos;Hopkins&apos;, first_name=u&apos;George&apos;, ssn=u&apos;338-33-5911&apos;, occupation=u&apos;Food technologist&apos;, age=30), Row(last_name=u&apos;Garcia&apos;, first_name=u&apos;Angela&apos;, ssn=u&apos;396-76-2111&apos;, occupation=u&apos;Biomedical engineer&apos;, age=13), Row(last_name=u&apos;Davis&apos;, first_name=u&apos;Terry&apos;, ssn=u&apos;460-94-5596&apos;, occupation=u&apos;Sound technician, broadcasting/film/video&apos;, age=24), Row(last_name=u&apos;Murphy&apos;, first_name=u&apos;Caitlin&apos;, ssn=u&apos;567-09-6990&apos;, occupation=u&apos;Conservator, museum/gallery&apos;, age=33), Row(last_name=u&apos;Turner&apos;, first_name=u&apos;Jonathan&apos;, ssn=u&apos;881-17-0514&apos;, occupation=u&apos;Nature conservation officer&apos;, age=27), Row(last_name=u&apos;Deleon&apos;, first_name=u&apos;Nicole&apos;, ssn=u&apos;091-34-5960&apos;, occupation=u&apos;Biomedical scientist&apos;, age=10), Row(last_name=u&apos;Duncan&apos;, first_name=u&apos;April&apos;, ssn=u&apos;796-52-9036&apos;, occupation=u&apos;Armed forces technical officer&apos;, age=27), Row(last_name=u&apos;Conner&apos;, first_name=u&apos;Anthony&apos;, ssn=u&apos;885-95-6066&apos;, occupation=u&apos;Mining engineer&apos;, age=41), Row(last_name=u&apos;Vargas&apos;, first_name=u&apos;Kim&apos;, ssn=u&apos;211-94-2444&apos;, occupation=u&apos;Conservation officer, historic buildings&apos;, age=0), Row(last_name=u&apos;Graham&apos;, first_name=u&apos;Rebecca&apos;, ssn=u&apos;799-93-0317&apos;, occupation=u&apos;Designer, blown glass/stained glass&apos;, age=46), Row(last_name=u&apos;Butler&apos;, first_name=u&apos;David&apos;, ssn=u&apos;525-46-5238&apos;, occupation=u&apos;Financial trader&apos;, age=15), Row(last_name=u&apos;Meyers&apos;, first_name=u&apos;Francis&apos;, ssn=u&apos;795-44-9040&apos;, occupation=u&apos;Science writer&apos;, age=8), Row(last_name=u&apos;Armstrong&apos;, first_name=u&apos;Jeremy&apos;, ssn=u&apos;875-97-5782&apos;, occupation=u&apos;Environmental health practitioner&apos;, age=43), Row(last_name=u&apos;Bowen&apos;, first_name=u&apos;Barbara&apos;, ssn=u&apos;546-12-5294&apos;, occupation=u&apos;Transport planner&apos;, age=18), Row(last_name=u&apos;Herman&apos;, first_name=u&apos;Kyle&apos;, ssn=u&apos;015-33-6769&apos;, occupation=u&apos;TEFL teacher&apos;, age=10), Row(last_name=u&apos;Oconnor&apos;, first_name=u&apos;Doris&apos;, ssn=u&apos;344-03-7762&apos;, occupation=u&apos;Lawyer&apos;, age=21), Row(last_name=u&apos;Jeremy&apos;, first_name=u&apos;Mr.&apos;, ssn=u&apos;107-99-2067&apos;, occupation=u&apos;Surveyor, quantity&apos;, age=42), Row(last_name=u&apos;Wallace&apos;, first_name=u&apos;Kevin&apos;, ssn=u&apos;432-13-7322&apos;, occupation=u&apos;Clinical molecular geneticist&apos;, age=35), Row(last_name=u&apos;Alvarez&apos;, first_name=u&apos;Robert&apos;, ssn=u&apos;300-97-9034&apos;, occupation=u&apos;Chartered public finance accountant&apos;, age=9), Row(last_name=u&apos;Mcconnell&apos;, first_name=u&apos;Rachel&apos;, ssn=u&apos;169-98-8975&apos;, occupation=u&apos;Sound technician, broadcasting/film/video&apos;, age=20), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Melissa&apos;, ssn=u&apos;250-15-3250&apos;, occupation=u&apos;Warden/ranger&apos;, age=9), Row(last_name=u&apos;Duncan&apos;, first_name=u&apos;Kristin&apos;, ssn=u&apos;670-25-7648&apos;, occupation=u&apos;Web designer&apos;, age=7), Row(last_name=u&apos;Doyle&apos;, first_name=u&apos;Glenn&apos;, ssn=u&apos;775-09-5264&apos;, occupation=u&apos;Clinical cytogeneticist&apos;, age=7), Row(last_name=u&apos;Williams&apos;, first_name=u&apos;Christopher&apos;, ssn=u&apos;737-59-3087&apos;, occupation=u&apos;Tree surgeon&apos;, age=46), Row(last_name=u&apos;Anderson&apos;, first_name=u&apos;Justin&apos;, ssn=u&apos;148-39-2154&apos;, occupation=u&apos;General practice doctor&apos;, age=6), Row(last_name=u&apos;Sanchez&apos;, first_name=u&apos;Jason&apos;, ssn=u&apos;571-16-2099&apos;, occupation=u&apos;Physiotherapist&apos;, age=28), Row(last_name=u&apos;Osborne&apos;, first_name=u&apos;Megan&apos;, ssn=u&apos;204-86-0308&apos;, occupation=u&apos;Loss adjuster, chartered&apos;, age=33), Row(last_name=u&apos;Cochran&apos;, first_name=u&apos;Kimberly&apos;, ssn=u&apos;636-28-6507&apos;, occupation=u&apos;Horticulturist, amenity&apos;, age=2), Row(last_name=u&apos;Love&apos;, first_name=u&apos;Daniel&apos;, ssn=u&apos;182-75-0710&apos;, occupation=u&apos;Primary school teacher&apos;, age=31), Row(last_name=u&apos;Trevino&apos;, first_name=u&apos;Donald&apos;, ssn=u&apos;463-85-8663&apos;, occupation=u&apos;Scientist, biomedical&apos;, age=26), Row(last_name=u&apos;Gordon&apos;, first_name=u&apos;Cynthia&apos;, ssn=u&apos;313-29-5464&apos;, occupation=u&apos;Gaffer&apos;, age=18), Row(last_name=u&apos;Baker&apos;, first_name=u&apos;Kenneth&apos;, ssn=u&apos;874-54-8992&apos;, occupation=u&apos;Operational researcher&apos;, age=17), Row(last_name=u&apos;Knight&apos;, first_name=u&apos;Megan&apos;, ssn=u&apos;700-42-7671&apos;, occupation=u&apos;Forest/woodland manager&apos;, age=2), Row(last_name=u&apos;Mckee&apos;, first_name=u&apos;Alexander&apos;, ssn=u&apos;152-22-4238&apos;, occupation=u&apos;Careers information officer&apos;, age=37), Row(last_name=u&apos;Harris&apos;, first_name=u&apos;Noah&apos;, ssn=u&apos;020-28-0931&apos;, occupation=u&apos;Journalist, broadcasting&apos;, age=5), Row(last_name=u&apos;Duarte&apos;, first_name=u&apos;Amber&apos;, ssn=u&apos;242-14-4963&apos;, occupation=u&apos;Petroleum engineer&apos;, age=25), Row(last_name=u&apos;Bennett&apos;, first_name=u&apos;Katherine&apos;, ssn=u&apos;873-29-4212&apos;, occupation=u&apos;Immunologist&apos;, age=26), Row(last_name=u&apos;Richardson&apos;, first_name=u&apos;Michael&apos;, ssn=u&apos;690-53-3209&apos;, occupation=u&apos;Restaurant manager, fast food&apos;, age=33), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Taylor&apos;, ssn=u&apos;036-23-5717&apos;, occupation=u&apos;General practice doctor&apos;, age=41), Row(last_name=u&apos;Beck&apos;, first_name=u&apos;Destiny&apos;, ssn=u&apos;142-96-3152&apos;, occupation=u&apos;Computer games developer&apos;, age=31), Row(last_name=u&apos;Matthews&apos;, first_name=u&apos;Valerie&apos;, ssn=u&apos;303-29-8281&apos;, occupation=u&apos;Pilot, airline&apos;, age=12), Row(last_name=u&apos;Morales&apos;, first_name=u&apos;Amber&apos;, ssn=u&apos;390-13-1476&apos;, occupation=u&apos;Engineer, energy&apos;, age=41), Row(last_name=u&apos;Smith&apos;, first_name=u&apos;Daniel&apos;, ssn=u&apos;358-70-2192&apos;, occupation=u&apos;Publishing rights manager&apos;, age=38), Row(last_name=u&apos;Kirk&apos;, first_name=u&apos;Mark&apos;, ssn=u&apos;515-10-9930&apos;, occupation=u&apos;Nature conservation officer&apos;, age=35), Row(last_name=u&apos;Casey&apos;, first_name=u&apos;Mr.&apos;, ssn=u&apos;269-50-7945&apos;, occupation=u&apos;Surveyor, commercial/residential&apos;, age=4), Row(last_name=u&apos;Gutierrez&apos;, first_name=u&apos;Peter&apos;, ssn=u&apos;129-93-0064&apos;, occupation=u&apos;Chiropractor&apos;, age=41), Row(last_name=u&apos;Wallace&apos;, first_name=u&apos;Andrew&apos;, ssn=u&apos;047-1... skipped 1078465 bytes ...\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;subDF&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-2-1dc6c48a2cee&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Let&apos;s collect the data</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>results <span class=\"ansiyellow\">=</span> subDF<span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansigreen\">print</span> results<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;subDF&apos; is not defined\n</div>","workflows":[],"startTime":1.476674422078E12,"submitTime":1.47667442755E12,"finishTime":1.47667442242E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ead0755f-1b13-48ae-8386-991223986192"},{"version":"CommandV1","origId":1305471881462045,"guid":"0e5e117b-34bd-4db1-a7bf-8f89ce4f1c88","subtype":"command","commandType":"auto","position":58.0,"command":"%md\nA better way to visualize the data is to use the `show()` method. If you don't tell `show()` how many rows to display, it displays 20 rows.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491032E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cf0872e6-bbd5-4b41-ba83-394372f78f50"},{"version":"CommandV1","origId":1305471881462046,"guid":"2969fb2d-fccd-46ed-a05b-0111da32a439","subtype":"command","commandType":"auto","position":59.0,"command":"subDF.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------+-----------+-----------+--------------------+---+\n|last_name| first_name|        ssn|          occupation|age|\n+---------+-----------+-----------+--------------------+---+\n|   Curtis|    Kristen|688-09-1018|Administrator, ch...|  7|\n| Richards|      David|201-66-6752|   Building surveyor| 23|\n|   Parker|Christopher|784-44-1690|         Proofreader| 11|\n|     Wood|   Jeremiah|645-25-9468| Librarian, academic|  5|\n|    Arias|     Sandra|460-22-4420|Engineer, electrical| 43|\n|    Green|      David|588-46-6358|Scientist, biomed...|  0|\n|    Glenn|    Derrick|337-51-5287|     Patent attorney|  6|\n|    Evans|       Leah|163-56-3569|Pharmacist, hospital| 36|\n|   Snyder|       Tara|842-77-4305|Administrator, ed...| 26|\n|   Miller|    Tiffany|527-33-8046|Lighting technici...|  3|\n|    Boyer|    Tiffany|855-14-4693|    Graphic designer|  4|\n|    Mills|      Kevin|701-33-5126|     Engineer, water| 23|\n|    Glenn|      Karen|894-73-1777|Investment banker...| 30|\n|    Brady|   Patricia|175-38-4379|           Mudlogger| 21|\n|   Juarez|       Kyle|612-98-0866|   Market researcher| 44|\n|   Cooper|  Catherine|245-56-5385|Medical technical...| 19|\n|   Nelson|       John|732-19-3869|Commercial hortic...|  3|\n|   Taylor|      Jamie|189-24-2509|Tourist informati...| 27|\n|     Reed|      James|508-63-4298|Physiological sci...| 16|\n| Williams|    Richard|430-04-3230|     Ophthalmologist|  8|\n+---------+-----------+-----------+--------------------+---+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674502305E12,"submitTime":1.476674507788E12,"finishTime":1.476674502479E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4d271af6-ed14-42d8-b2d0-2c1319c500d1"},{"version":"CommandV1","origId":1305471881462047,"guid":"c92ce632-4fbe-48a9-9bf8-debf6912e87a","subtype":"command","commandType":"auto","position":60.0,"command":"%md\nIf you'd prefer that `show()` not truncate the data, you can tell it not to:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491071E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6404c2cb-31bb-4323-af9b-3d9e010dee6b"},{"version":"CommandV1","origId":1305471881462048,"guid":"1cd77266-eb1d-46fd-bf89-3772272a317e","subtype":"command","commandType":"auto","position":61.0,"command":"subDF.show(n=30, truncate=False)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------+-----------+-----------+------------------------------------------------+---+\n|last_name|first_name |ssn        |occupation                                      |age|\n+---------+-----------+-----------+------------------------------------------------+---+\n|Curtis   |Kristen    |688-09-1018|Administrator, charities/voluntary organisations|7  |\n|Richards |David      |201-66-6752|Building surveyor                               |23 |\n|Parker   |Christopher|784-44-1690|Proofreader                                     |11 |\n|Wood     |Jeremiah   |645-25-9468|Librarian, academic                             |5  |\n|Arias    |Sandra     |460-22-4420|Engineer, electrical                            |43 |\n|Green    |David      |588-46-6358|Scientist, biomedical                           |0  |\n|Glenn    |Derrick    |337-51-5287|Patent attorney                                 |6  |\n|Evans    |Leah       |163-56-3569|Pharmacist, hospital                            |36 |\n|Snyder   |Tara       |842-77-4305|Administrator, education                        |26 |\n|Miller   |Tiffany    |527-33-8046|Lighting technician, broadcasting/film/video    |3  |\n|Boyer    |Tiffany    |855-14-4693|Graphic designer                                |4  |\n|Mills    |Kevin      |701-33-5126|Engineer, water                                 |23 |\n|Glenn    |Karen      |894-73-1777|Investment banker, corporate                    |30 |\n|Brady    |Patricia   |175-38-4379|Mudlogger                                       |21 |\n|Juarez   |Kyle       |612-98-0866|Market researcher                               |44 |\n|Cooper   |Catherine  |245-56-5385|Medical technical officer                       |19 |\n|Nelson   |John       |732-19-3869|Commercial horticulturist                       |3  |\n|Taylor   |Jamie      |189-24-2509|Tourist information centre manager              |27 |\n|Reed     |James      |508-63-4298|Physiological scientist                         |16 |\n|Williams |Richard    |430-04-3230|Ophthalmologist                                 |8  |\n|Hudson   |Jeff       |361-38-1225|Fitness centre manager                          |11 |\n|Kathryn  |Mrs.       |029-47-4555|Scientific laboratory technician                |44 |\n|Stephens |Scott      |287-59-2532|Patent attorney                                 |29 |\n|Johnson  |Norma      |473-06-8214|Horticultural therapist                         |26 |\n|Campbell |Matthew    |755-53-2711|Tree surgeon                                    |4  |\n|William  |Dr.        |603-84-8464|Call centre manager                             |33 |\n|Morgan   |Lorraine   |304-86-9496|Engineer, maintenance (IT)                      |13 |\n|Lee      |Lisa       |138-97-9782|Clinical embryologist                           |22 |\n|Lopez    |Heather    |519-48-8761|Nurse, children&apos;s                               |14 |\n|Patrick  |Doris      |781-48-3096|Music tutor                                     |46 |\n+---------+-----------+-----------+------------------------------------------------+---+\nonly showing top 30 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674512449E12,"submitTime":1.476674517932E12,"finishTime":1.476674512522E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"850f5f96-0eb6-40a5-a72f-6bb56fc40661"},{"version":"CommandV1","origId":1305471881462049,"guid":"0911e11b-ddc5-43ef-b1aa-30a82c723953","subtype":"command","commandType":"auto","position":62.0,"command":"%md\nIn Databricks, there's an even nicer way to look at the values in a DataFrame: The `display()` helper function.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491116E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b9b07d1-ae90-4d0e-8d82-cef46b746715"},{"version":"CommandV1","origId":1305471881462050,"guid":"939521ea-5109-4c99-ba0f-da4a0d4d6563","subtype":"command","commandType":"auto","position":63.0,"command":"display(subDF)","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Curtis","Kristen","688-09-1018","Administrator, charities/voluntary organisations",7.0],["Richards","David","201-66-6752","Building surveyor",23.0],["Parker","Christopher","784-44-1690","Proofreader",11.0],["Wood","Jeremiah","645-25-9468","Librarian, academic",5.0],["Arias","Sandra","460-22-4420","Engineer, electrical",43.0],["Green","David","588-46-6358","Scientist, biomedical",0.0],["Glenn","Derrick","337-51-5287","Patent attorney",6.0],["Evans","Leah","163-56-3569","Pharmacist, hospital",36.0],["Snyder","Tara","842-77-4305","Administrator, education",26.0],["Miller","Tiffany","527-33-8046","Lighting technician, broadcasting/film/video",3.0],["Boyer","Tiffany","855-14-4693","Graphic designer",4.0],["Mills","Kevin","701-33-5126","Engineer, water",23.0],["Glenn","Karen","894-73-1777","Investment banker, corporate",30.0],["Brady","Patricia","175-38-4379","Mudlogger",21.0],["Juarez","Kyle","612-98-0866","Market researcher",44.0],["Cooper","Catherine","245-56-5385","Medical technical officer",19.0],["Nelson","John","732-19-3869","Commercial horticulturist",3.0],["Taylor","Jamie","189-24-2509","Tourist information centre manager",27.0],["Reed","James","508-63-4298","Physiological scientist",16.0],["Williams","Richard","430-04-3230","Ophthalmologist",8.0],["Hudson","Jeff","361-38-1225","Fitness centre manager",11.0],["Kathryn","Mrs.","029-47-4555","Scientific laboratory technician",44.0],["Stephens","Scott","287-59-2532","Patent attorney",29.0],["Johnson","Norma","473-06-8214","Horticultural therapist",26.0],["Campbell","Matthew","755-53-2711","Tree surgeon",4.0],["William","Dr.","603-84-8464","Call centre manager",33.0],["Morgan","Lorraine","304-86-9496","Engineer, maintenance (IT)",13.0],["Lee","Lisa","138-97-9782","Clinical embryologist",22.0],["Lopez","Heather","519-48-8761","Nurse, children's",14.0],["Patrick","Doris","781-48-3096","Music tutor",46.0],["Howard","Erika","199-19-3835","Rural practice surveyor",14.0],["Lopez","Collin","484-43-0522","Health and safety adviser",6.0],["Hanson","Tina","577-26-2113","Petroleum engineer",23.0],["Moreno","Glenn","227-97-4319","IT technical support officer",19.0],["Lopez","Cynthia","678-06-1255","Engineer, structural",43.0],["Vargas","Mary","198-76-2470","Research scientist (life sciences)",23.0],["Barnes","Michael","751-08-1097","Broadcast engineer",15.0],["Hines","Brandon","073-36-3206","Landscape architect",34.0],["Ramos","Tracy","297-94-7225","Photographer",5.0],["Lang","Jessica","521-20-2148","Scientist, audiological",4.0],["Lawrence","Cesar","054-75-3019","Educational psychologist",45.0],["Monroe","Dwayne","202-52-0122","Tree surgeon",12.0],["Lee","Rodney","302-24-1795","Veterinary surgeon",29.0],["Jackson","Laura","411-60-4473","Waste management officer",15.0],["Kennedy","Caitlin","431-98-3022","Geologist, engineering",39.0],["Ward","Brett","181-70-5815","Barrister's clerk",39.0],["Huffman","Timothy","614-07-0799","Fish farm manager",17.0],["Cruz","Michael","767-70-5269","Licensed conveyancer",3.0],["Key","Jeremy","449-64-2814","Newspaper journalist",16.0],["Smith","Frances","337-33-6058","Tourist information centre manager",23.0],["Williams","Mark","196-76-2218","Primary school teacher",33.0],["Wright","Terri","558-81-0423","Hospital doctor",16.0],["Smith","Sarah","725-06-9596","Telecommunications researcher",12.0],["Webb","Julian","757-82-5438","Administrator",15.0],["Michelle","Miss","318-47-6860","Writer",37.0],["Bailey","David","230-38-2189","Merchandiser, retail",35.0],["Spears","Sandra","661-42-2121","Surveyor, land/geomatics",44.0],["Murray","Scott","061-87-6153","Financial manager",19.0],["Thompson","Carrie","465-02-5429","Teacher, music",2.0],["Byrd","Jerome","047-57-3233","Occupational psychologist",21.0],["Farmer","Martin","435-04-0320","TEFL teacher",18.0],["Martin","Denise","232-33-6223","Primary school teacher",30.0],["Gross","Madison","158-08-6750","Mental health nurse",2.0],["Frederick","Daniel","505-21-9276","Production engineer",5.0],["Clark","Amy","183-30-3218","Education officer, museum",36.0],["Garner","Laura","861-38-0228","Museum/gallery conservator",25.0],["Ramirez","Gerald","186-92-1482","Producer, radio",35.0],["Miles","James","891-37-2762","Health visitor",7.0],["Carey","Michelle","803-55-7506","Scientist, research (maths)",41.0],["Harris","Joshua","152-55-8567","Nutritional therapist",42.0],["Flores","Debra","848-01-8689","Architect",41.0],["Brown","Tina","690-20-9271","Furniture conservator/restorer",35.0],["Davis","Destiny","361-58-2113","Designer, ceramics/pottery",39.0],["Williams","Laurie","714-17-6911","Financial manager",13.0],["Carpenter","Sarah","250-25-5903","Actuary",21.0],["Ward","Terri","151-76-1895","Plant breeder/geneticist",23.0],["Miller","Mariah","179-55-6664","Advertising art director",13.0],["Martin","Curtis","703-58-0090","Medical physicist",14.0],["Clements","Jesse","670-40-5655","Teacher, adult education",41.0],["Ortiz","Kristen","865-07-2179","Control and instrumentation engineer",34.0],["Myers","Paula","025-56-5469","Research scientist (maths)",24.0],["Anderson","Lisa","123-02-6786","Psychotherapist, child",9.0],["Bates","Kristina","008-38-0836","Probation officer",10.0],["Solis","Michael","011-79-8500","Production assistant, radio",5.0],["Cowan","Randall","230-07-6182","English as a second language teacher",26.0],["Hudson","Maria","071-69-8159","Sub",7.0],["Kramer","Shannon","291-73-3440","Surgeon",5.0],["Frederick","Michael","629-98-7923","Medical sales representative",3.0],["Young","John","308-70-4051","Further education lecturer",13.0],["Burgess","Aaron","804-83-3583","Chartered public finance accountant",14.0],["Foster","Kristi","657-12-3077","Paediatric nurse",29.0],["Estrada","Jonathon","614-72-0253","Engineer, chemical",46.0],["Hensley","Erica","881-90-4738","Garment/textile technologist",7.0],["Elliott","Duane","359-64-0476","Restaurant manager",32.0],["Hunter","Brian","392-83-0709","Nature conservation officer",42.0],["Bailey","Sydney","276-05-6482","Insurance claims handler",18.0],["Nguyen","Erika","276-57-8816","Field seismologist",39.0],["Bryant","Charles","360-58-9234","Clinical cytogeneticist",8.0],["Lopez","Chelsea","185-33-2334","Chartered certified accountant",37.0],["Durham","Sarah","682-48-9485","Environmental education officer",37.0],["White","Christina","431-03-2203","Accounting technician",5.0],["Perry","Chad","799-31-2527","Operational investment banker",10.0],["Rhodes","William","703-34-5967","Advertising account planner",22.0],["Bartlett","James","394-67-0604","Designer, blown glass/stained glass",36.0],["Myers","Kelsey","073-13-7973","Special effects artist",26.0],["Nixon","Derrick","742-70-0051","Food technologist",6.0],["Valentine","Melissa","062-75-8765","Designer, television/film set",3.0],["Jones","Natalie","889-40-2800","Museum/gallery conservator",4.0],["Murphy","Thomas","573-45-1181","Seismic interpreter",24.0],["Smith","Tracy","387-28-8771","Private music teacher",8.0],["Rodriguez","Bryan","742-94-9047","Occupational psychologist",18.0],["Davis","David","358-29-8499","Publishing rights manager",6.0],["Marshall","Matthew","794-36-6085","Counsellor",5.0],["Riley","Jessica","171-92-9984","Artist",25.0],["Cooper","Daniel","485-36-0896","Recycling officer",20.0],["Perry","Jessica","517-53-3991","Horticulturist, commercial",37.0],["Herrera","John","248-29-5580","Therapist, horticultural",11.0],["Francis","Joel","559-19-9896","Recycling officer",10.0],["Sutton","Joseph","163-97-7959","Investment banker, operational",43.0],["Barry","Jesus","652-82-6121","Product designer",26.0],["Mckinney","Brett","852-77-2607","Graphic designer",11.0],["Moore","Amy","209-33-3136","Technical brewer",38.0],["Leonard","Brooke","810-99-6228","Geographical information systems officer",10.0],["Hopkins","Andrea","130-82-3102","Immunologist",33.0],["Hernandez","Omar","289-24-7458","IT consultant",13.0],["Matthews","Carrie","537-11-4295","Community education officer",22.0],["Mayo","Lucas","809-18-4668","Surveyor, building",24.0],["Bailey","Heidi","022-86-7761","Actor",41.0],["Horn","Brent","481-86-9803","Photographer",40.0],["Johnson","Ashley","707-27-2864","Industrial buyer",42.0],["Higgins","Antonio","217-47-2995","Geoscientist",12.0],["Garcia","Sarah","885-76-7474","Trade mark attorney",22.0],["Hampton","Nicholas","344-07-0218","Clinical cytogeneticist",34.0],["Orr","Victoria","738-07-2960","Therapist, nutritional",25.0],["Lynch","Eileen","389-63-8648","Electronics engineer",10.0],["Willis","Justin","646-87-5378","Tree surgeon",13.0],["Riley","Shane","449-77-3538","Music therapist",3.0],["Carter","Angel","255-41-3386","Sales promotion account executive",9.0],["Melissa","Mrs.","043-99-8032","Lawyer",24.0],["Reyes","Misty","035-93-2365","Energy manager",34.0],["Ramirez","Dustin","723-48-4040","Print production planner",33.0],["Simmons","Timothy","154-10-8220","Programmer, applications",17.0],["Anderson","Tiffany","446-74-9493","Electronics engineer",30.0],["Kelley","Christopher","861-78-9237","Records manager",4.0],["Taylor","Melissa","057-86-1542","Scientist, marine",16.0],["Wilkinson","Joshua","508-96-5519","Corporate treasurer",31.0],["Le","Chase","310-32-0801","Horticultural therapist",13.0],["Barker","Sarah","426-44-8612","Records manager",3.0],["Garcia","William","250-14-6199","Production assistant, radio",36.0],["Perkins","Lawrence","421-42-7657","Designer, interior/spatial",21.0],["Gallegos","Joseph","260-65-5995","Investment banker, operational",2.0],["Thompson","Amy","311-31-7843","Cartographer",2.0],["Thomas","Daryl","823-26-0650","Engineer, water",41.0],["Lewis","Robert","453-07-1148","Social worker",13.0],["Reeves","Jennifer","545-98-2229","Politician's assistant",42.0],["Barrett","Mary","442-43-1113","Acupuncturist",31.0],["Hernandez","Jacqueline","712-58-1239","Production engineer",8.0],["Lewis","Joseph","453-91-2434","Forensic scientist",14.0],["Parker","Kristi","790-19-7296","Electrical engineer",25.0],["Young","Craig","068-45-9639","Psychologist, clinical",3.0],["Horton","Traci","516-86-7759","Social worker",40.0],["Berg","Walter","175-01-6307","Engineer, manufacturing",27.0],["Welch","Elizabeth","668-76-9591","Engineer, biomedical",25.0],["Mann","Mark","558-40-9113","Education officer, community",26.0],["Adams","Anne","600-21-6179","Scientist, research (life sciences)",46.0],["Ortega","Jennifer","785-14-6169","Drilling engineer",23.0],["Williams","David","013-52-1674","Systems analyst",42.0],["Butler","Terry","689-27-1416","Leisure centre manager",43.0],["Torres","Brittany","632-88-8876","Mining engineer",32.0],["Martin","Renee","222-51-5019","Conservation officer, historic buildings",13.0],["Logan","Nicholas","275-17-8229","Psychiatrist",11.0],["Myers","Sharon","471-91-8967","Clinical biochemist",14.0],["Hardin","Natalie","201-91-0679","Engineer, chemical",37.0],["Perry","Jodi","736-34-8801","Geologist, engineering",24.0],["John","Dr.","548-64-9480","Production manager",3.0],["Ramirez","William","250-77-9423","Administrator",16.0],["Stewart","Jason","722-83-8739","Exhibitions officer, museum/gallery",20.0],["Hawkins","Anna","331-24-5030","Colour technologist",17.0],["Randolph","Joe","680-43-7591","Meteorologist",31.0],["Clark","Cheryl","573-17-4360","Systems analyst",8.0],["Reyes","Jill","294-05-3175","Electrical engineer",21.0],["Taylor","Ashlee","775-86-2123","Higher education careers adviser",44.0],["Hunt","Patrick","101-72-0975","Therapist, art",43.0],["Ortiz","Dillon","196-21-2698","Clinical cytogeneticist",41.0],["Young","Jamie","234-05-7032","Colour technologist",16.0],["Hampton","Derrick","512-16-9100","Clinical embryologist",40.0],["Garcia","Sherri","509-83-6533","Control and instrumentation engineer",18.0],["Kennedy","Allison","885-07-2518","Market researcher",5.0],["Rice","Christina","496-94-2666","Public relations account executive",10.0],["Williams","Erin","705-79-6682","Cabin crew",9.0],["Summers","Carrie","546-39-8666","Producer, television/film/video",7.0],["Elliott","Jamie","414-29-5329","Local government officer",1.0],["Anderson","Erin","893-27-4992","Radiation protection practitioner",27.0],["Perkins","James","508-17-4643","Graphic designer",1.0],["Schultz","Whitney","227-48-8117","Engineer, maintenance",17.0],["Arnold","Yvonne","007-87-0678","Gaffer",24.0],["Johnson","Ryan","831-42-6981","Chemist, analytical",13.0],["Vaughn","Jessica","729-94-2091","Product designer",25.0],["Barajas","Sharon","828-48-0650","Video editor",41.0],["Martinez","Dale","321-88-4917","Scientist, research (maths)",16.0],["Miller","Michelle","844-46-8482","Designer, interior/spatial",3.0],["Lee","Antonio","053-17-0216","Volunteer coordinator",31.0],["Allen","Troy","155-92-1405","Engineer, production",40.0],["Patel","Keith","207-79-4285","Probation officer",21.0],["Anderson","Meagan","332-98-2465","Web designer",14.0],["Mercado","Denise","283-03-4911","Glass blower/designer",30.0],["Wood","Michael","537-02-6134","Midwife",7.0],["Nichols","Steven","733-58-3920","Scientist, biomedical",18.0],["Howard","Kathy","716-74-0340","Legal secretary",32.0],["Fox","Jacqueline","774-97-6217","Naval architect",32.0],["Schultz","Victoria","711-54-8521","Network engineer",20.0],["Shaw","Audrey","195-89-6409","Health and safety inspector",9.0],["King","Nicholas","319-80-5824","Optometrist",14.0],["Roberts","Adam","696-69-7269","Diagnostic radiographer",1.0],["Nelson","Erika","222-91-9492","Designer, blown glass/stained glass",25.0],["Rowland","Jason","696-93-1973","Financial controller",29.0],["Davis","Leah","895-59-6262","Environmental consultant",37.0],["Johnson","Lindsey","426-26-2328","Product designer",21.0],["House","Paul","667-09-0898","Fast food restaurant manager",31.0],["Freeman","Christopher","627-65-3521","Engineer, manufacturing",0.0],["Rangel","Howard","474-85-9840","Volunteer coordinator",20.0],["Price","Benjamin","854-58-3882","Medical physicist",34.0],["Solomon","Angela","357-64-9278","Purchasing manager",45.0],["Murphy","James","683-53-8426","Psychologist, counselling",27.0],["Wise","Ariel","417-19-2373","Scientific laboratory technician",31.0],["Hamilton","Craig","105-15-4161","Holiday representative",22.0],["Prince","Walter","805-69-6874","Quarry manager",15.0],["Ellison","Donald","504-79-8513","Sales promotion account executive",44.0],["Anderson","Ricky","665-44-3213","Production manager",8.0],["Taylor","Christopher","520-92-1427","Editor, commissioning",37.0],["Coleman","Debbie","165-10-1998","Research scientist (life sciences)",23.0],["Heath","Jesse","517-56-4629","Building services engineer",14.0],["Williams","Nicole","847-49-2168","Private music teacher",44.0],["Morales","Brian","805-26-1774","Conservation officer, historic buildings",43.0],["Zuniga","Carrie","173-87-2245","Arboriculturist",36.0],["Ross","Tabitha","415-32-9374","Trade union research officer",37.0],["Willie","Mr.","736-18-2420","Accountant, chartered public finance",19.0],["Drake","April","166-25-0395","Dance movement psychotherapist",28.0],["Lopez","Janet","459-70-7429","Phytotherapist",13.0],["Taylor","William","159-45-9638","Magazine journalist",21.0],["Caldwell","John","152-49-8466","Administrator, Civil Service",3.0],["Stewart","Gregory","639-29-8863","Microbiologist",46.0],["Ibarra","Catherine","203-66-8715","Aid worker",45.0],["Vargas","Bradley","059-24-3625","Geophysicist/field seismologist",20.0],["Decker","Timothy","475-58-6500","Paramedic",26.0],["Villarreal","Ashley","016-70-5168","Public house manager",17.0],["Burton","Kevin","882-83-3824","Engineer, maintenance (IT)",15.0],["Rodriguez","Matthew","098-77-3826","Designer, multimedia",12.0],["Garcia","Brenda","327-73-4507","Bonds trader",4.0],["Mcgee","Brian","613-36-4485","Engineer, control and instrumentation",45.0],["Bowman","Robert","071-70-4229","Occupational hygienist",33.0],["Rose","Jerry","031-18-6271","Educational psychologist",34.0],["Adams","Steven","056-05-6165","Physiological scientist",39.0],["Bennett","Johnathan","389-02-5406","Quality manager",36.0],["Ramirez","Lauren","836-11-8095","Television/film/video producer",35.0],["Russell","Miguel","882-39-9841","Engineer, materials",46.0],["Mata","Matthew","705-65-8373","Accountant, chartered management",34.0],["Davidson","Kendra","684-63-6241","Medical illustrator",10.0],["Flores","Paul","360-73-9441","Pharmacologist",43.0],["Clark","Crystal","509-53-8700","Sound technician, broadcasting/film/video",41.0],["James","Dr.","687-94-5466","Oncologist",9.0],["Williams","Jeffrey","871-32-3550","Engineer, petroleum",10.0],["Jordan","William","457-37-9828","Artist",22.0],["Rodriguez","Jack","873-30-7193","Statistician",1.0],["Osborne","Allison","680-55-9136","Librarian, academic",31.0],["Rodgers","Ronald","179-02-8263","Surveyor, hydrographic",29.0],["King","Charles","849-82-4978","Financial trader",31.0],["Wilson","Robert","657-46-9119","Broadcast journalist",35.0],["Holmes","Randy","433-14-9255","Research scientist (maths)",28.0],["Le","Laura","467-14-0692","Government social research officer",43.0],["Heather","Dr.","349-90-5947","Administrator, Civil Service",11.0],["Sims","Stephen","305-66-2112","Software engineer",16.0],["Garcia","Sarah","231-08-7297","Administrator, local government",3.0],["Downs","Alyssa","172-09-8917","Dispensing optician",19.0],["Collins","David","100-90-0643","Public relations officer",3.0],["Washington","Jean","073-82-5103","Dietitian",8.0],["Jordan","Gerald","526-79-3061","Counselling psychologist",37.0],["Hernandez","Lindsay","033-35-8210","Electronics engineer",15.0],["Johnson","Kelly","661-70-8200","Therapist, occupational",19.0],["Jackson","William","374-02-3134","Chemical engineer",34.0],["Foley","Danny","257-05-0070","Pathologist",15.0],["Jones","Amanda","806-82-3781","Investment banker, corporate",41.0],["Smith","Tracy","594-74-5478","Environmental education officer",14.0],["Chaney","Elizabeth","884-45-7908","Engineer, aeronautical",20.0],["Figueroa","Lisa","760-08-9332","Fitness centre manager",21.0],["Hanson","Jessica","330-25-0904","Health and safety inspector",14.0],["Smith","Phyllis","122-31-9779","Mudlogger",1.0],["Combs","Heather","782-94-8814","Logistics and distribution manager",10.0],["Franklin","James","229-52-2327","Surveyor, insurance",25.0],["Cochran","Michele","602-36-4532","Veterinary surgeon",10.0],["Ferrell","Robin","223-93-5412","Fast food restaurant manager",35.0],["Thompson","Gary","676-25-7220","Mining engineer",11.0],["Collins","John","653-92-4623","Information systems manager",20.0],["Sweeney","James","286-52-6505","Engineer, communications",22.0],["White","Benjamin","700-58-4881","Oceanographer",42.0],["Ramirez","Jessica","287-86-9559","Advertising art director",18.0],["Conner","Joshua","093-62-2648","Press sub",29.0],["Perez","Michelle","553-44-3525","Engineer, materials",14.0],["Powell","Erin","512-57-9489","Special educational needs teacher",34.0],["Nguyen","Robert","471-50-0214","Engineer, civil (consulting)",39.0],["Hanson","Tiffany","237-20-2813","Administrator, arts",2.0],["Cannon","Mark","520-83-7981","Communications engineer",10.0],["Harrison","James","339-65-0720","Cytogeneticist",5.0],["Thompson","Abigail","633-24-3685","Trading standards officer",34.0],["Cooper","Jeremy","566-35-7226","Tax inspector",35.0],["Cunningham","Sean","160-59-3705","Production designer, theatre/television/film",23.0],["Gill","Lisa","202-33-9222","Health and safety adviser",37.0],["Cruz","Martin","391-64-3452","Industrial/product designer",23.0],["Wright","Michaela","092-01-4448","Charity officer",24.0],["Moses","Jeffery","692-69-1858","Scientist, clinical (histocompatibility and immunogenetics)",35.0],["Turner","Mary","888-94-3982","Fisheries officer",35.0],["Simpson","David","133-15-6670","Toxicologist",24.0],["Hampton","Terry","093-28-8829","Ranger/warden",2.0],["Nelson","Kelly","055-64-3061","Doctor, general practice",19.0],["Martinez","Andrew","822-15-0277","Radiographer, diagnostic",6.0],["Hansen","Tanner","841-32-0448","Museum/gallery exhibitions officer",32.0],["Woods","Christopher","680-19-8510","Operations geologist",25.0],["Ward","Ronald","023-33-0385","Careers adviser",23.0],["King","Emily","284-23-0250","Air broker",8.0],["Wagner","Elizabeth","728-52-9871","Ergonomist",0.0],["Jenkins","Patricia","534-97-5524","Operational researcher",0.0],["Salinas","Russell","514-89-7885","Medical laboratory scientific officer",35.0],["Reid","Cynthia","326-19-6213","Farm manager",46.0],["Hall","Justin","761-05-1148","Legal secretary",41.0],["Nelson","Cheryl","354-14-6437","Music tutor",29.0],["Garcia","Rachel","329-36-2503","Animal technologist",2.0],["Torres","Michael","448-33-4134","Phytotherapist",41.0],["Brown","Angela","016-08-8726","Cartographer",28.0],["Ward","Michael","086-98-3792","Social research officer, government",7.0],["Reed","Karen","452-59-5983","Tourism officer",11.0],["Johnson","Sabrina","703-80-7437","Retail merchandiser",19.0],["Butler","Raymond","342-14-1447","Production designer, theatre/television/film",44.0],["Sanchez","Joseph","526-92-4482","Data processing manager",15.0],["Brown","Mackenzie","333-56-4194","Research scientist (physical sciences)",13.0],["Bates","Chad","463-70-8041","Engineer, electrical",40.0],["Love","Jose","264-11-9753","Magazine features editor",46.0],["Ferguson","Lauren","410-49-4207","Teacher, early years/pre",7.0],["Mullen","Arthur","261-03-9503","Education officer, community",11.0],["Hurst","Alexis","811-15-1318","Production manager",17.0],["Wade","Jeremiah","150-87-5073","Scientist, audiological",17.0],["Ross","Kathleen","027-64-5393","Restaurant manager, fast food",40.0],["Guerra","Jenna","363-80-9072","Nutritional therapist",38.0],["Nguyen","Joseph","699-42-7795","Structural engineer",5.0],["Dixon","Michelle","770-38-3561","Media planner",6.0],["Hayden","Mark","434-88-7304","Accounting technician",33.0],["Kennedy","Samantha","728-22-5257","Actuary",32.0],["Perez","George","771-96-8998","Tourism officer",17.0],["Anderson","Kathryn","642-05-3114","Telecommunications researcher",27.0],["Stanley","Christopher","531-49-5070","Medical secretary",44.0],["Myers","Tonya","824-04-8860","Leisure centre manager",35.0],["Hill","Ronald","358-65-8691","Printmaker",26.0],["Martin","Renee","313-49-8921","Copywriter, advertising",13.0],["Orr","Jenna","441-97-5845","Ceramics designer",19.0],["Durham","Diane","205-17-8750","Scientist, forensic",30.0],["Graham","Randy","803-50-3586","Industrial/product designer",9.0],["Rodriguez","Alan","840-96-3667","Product designer",40.0],["Norman","Linda","236-11-7139","Clinical embryologist",15.0],["Rodriguez","Lauren","715-39-0614","Psychiatric nurse",23.0],["Peters","Edward","865-39-3313","Chartered legal executive (England and Wales)",29.0],["Torres","Vincent","442-94-5813","Occupational therapist",20.0],["Spencer","Holly","375-47-4203","Radio producer",45.0],["Miller","Randy","025-44-5431","Hydrogeologist",38.0],["Washington","Jason","860-02-0305","Diplomatic Services operational officer",6.0],["Gordon","Joseph","080-16-1239","Restaurant manager",41.0],["Caldwell","Kevin","422-79-3596","Research officer, trade union",2.0],["Swanson","Billy","634-87-9566","Oncologist",8.0],["Bass","Thomas","040-96-7792","Geochemist",11.0],["Nielsen","David","056-01-4808","Trading standards officer",22.0],["Coleman","Anne","321-78-6381","Travel agency manager",46.0],["Warner","Angel","551-19-4398","Retail manager",42.0],["Kennedy","Jason","140-30-1898","Museum/gallery curator",29.0],["Bell","Nicole","290-76-5520","Scientist, physiological",3.0],["Klein","Brittany","139-92-8863","Field seismologist",12.0],["Schroeder","Cindy","124-68-4870","Advertising account planner",33.0],["Stevenson","Steven","402-50-4393","Therapist, occupational",41.0],["Stewart","Christina","775-68-4644","Scientific laboratory technician",33.0],["Singleton","Michael","015-18-8257","Textile designer",37.0],["Chen","Billy","531-53-5157","Illustrator",28.0],["Murillo","Andrew","324-60-6228","Psychiatric nurse",17.0],["House","Cheryl","145-76-1651","Accountant, chartered",4.0],["Parker","Julie","678-73-6151","Engineer, building services",5.0],["Fleming","Brittany","795-86-9686","Market researcher",6.0],["Reed","Michael","134-04-5542","Designer, ceramics/pottery",28.0],["Obrien","Jeffery","794-29-4070","Airline pilot",45.0],["Green","Tonya","165-38-0803","Microbiologist",12.0],["Hutchinson","Heidi","771-80-5961","Air cabin crew",6.0],["Wood","Steven","227-42-4694","Psychologist, prison and probation services",21.0],["Fritz","Anthony","372-30-4591","Doctor, hospital",27.0],["Jones","Heather","108-52-6426","Arts administrator",23.0],["Shaw","Zachary","422-06-8734","Administrator, arts",25.0],["Whitney","Rachel","559-51-9110","Computer games developer",19.0],["Alexander","Nicole","220-34-1674","Health and safety adviser",36.0],["Reed","Rose","309-15-4804","Broadcast engineer",11.0],["Schaefer","Tommy","655-01-3609","Metallurgist",41.0],["Hensley","Anne","255-73-2823","Writer",6.0],["Douglas","Chloe","255-44-2673","Copywriter, advertising",35.0],["Hopkins","George","338-33-5911","Food technologist",30.0],["Garcia","Angela","396-76-2111","Biomedical engineer",13.0],["Davis","Terry","460-94-5596","Sound technician, broadcasting/film/video",24.0],["Murphy","Caitlin","567-09-6990","Conservator, museum/gallery",33.0],["Turner","Jonathan","881-17-0514","Nature conservation officer",27.0],["Deleon","Nicole","091-34-5960","Biomedical scientist",10.0],["Duncan","April","796-52-9036","Armed forces technical officer",27.0],["Conner","Anthony","885-95-6066","Mining engineer",41.0],["Vargas","Kim","211-94-2444","Conservation officer, historic buildings",0.0],["Graham","Rebecca","799-93-0317","Designer, blown glass/stained glass",46.0],["Butler","David","525-46-5238","Financial trader",15.0],["Meyers","Francis","795-44-9040","Science writer",8.0],["Armstrong","Jeremy","875-97-5782","Environmental health practitioner",43.0],["Bowen","Barbara","546-12-5294","Transport planner",18.0],["Herman","Kyle","015-33-6769","TEFL teacher",10.0],["Oconnor","Doris","344-03-7762","Lawyer",21.0],["Jeremy","Mr.","107-99-2067","Surveyor, quantity",42.0],["Wallace","Kevin","432-13-7322","Clinical molecular geneticist",35.0],["Alvarez","Robert","300-97-9034","Chartered public finance accountant",9.0],["Mcconnell","Rachel","169-98-8975","Sound technician, broadcasting/film/video",20.0],["Smith","Melissa","250-15-3250","Warden/ranger",9.0],["Duncan","Kristin","670-25-7648","Web designer",7.0],["Doyle","Glenn","775-09-5264","Clinical cytogeneticist",7.0],["Williams","Christopher","737-59-3087","Tree surgeon",46.0],["Anderson","Justin","148-39-2154","General practice doctor",6.0],["Sanchez","Jason","571-16-2099","Physiotherapist",28.0],["Osborne","Megan","204-86-0308","Loss adjuster, chartered",33.0],["Cochran","Kimberly","636-28-6507","Horticulturist, amenity",2.0],["Love","Daniel","182-75-0710","Primary school teacher",31.0],["Trevino","Donald","463-85-8663","Scientist, biomedical",26.0],["Gordon","Cynthia","313-29-5464","Gaffer",18.0],["Baker","Kenneth","874-54-8992","Operational researcher",17.0],["Knight","Megan","700-42-7671","Forest/woodland manager",2.0],["Mckee","Alexander","152-22-4238","Careers information officer",37.0],["Harris","Noah","020-28-0931","Journalist, broadcasting",5.0],["Duarte","Amber","242-14-4963","Petroleum engineer",25.0],["Bennett","Katherine","873-29-4212","Immunologist",26.0],["Richardson","Michael","690-53-3209","Restaurant manager, fast food",33.0],["Smith","Taylor","036-23-5717","General practice doctor",41.0],["Beck","Destiny","142-96-3152","Computer games developer",31.0],["Matthews","Valerie","303-29-8281","Pilot, airline",12.0],["Morales","Amber","390-13-1476","Engineer, energy",41.0],["Smith","Daniel","358-70-2192","Publishing rights manager",38.0],["Kirk","Mark","515-10-9930","Nature conservation officer",35.0],["Casey","Mr.","269-50-7945","Surveyor, commercial/residential",4.0],["Gutierrez","Peter","129-93-0064","Chiropractor",41.0],["Wallace","Andrew","047-11-0094","Advertising account planner",17.0],["Jennifer","Mrs.","262-70-0123","Telecommunications researcher",6.0],["Gregory","Nathan","190-76-3180","Industrial/product designer",33.0],["Hill","Sara","223-90-8361","Museum/gallery conservator",39.0],["Williams","Trevor","198-56-1881","Counsellor",42.0],["Gray","Caitlin","739-79-3610","Librarian, public",40.0],["Wolf","Rose","612-80-1559","Stage manager",13.0],["Key","Erica","228-54-2686","Systems developer",35.0],["Li","Bradley","393-88-7970","Housing manager/officer",19.0],["Tanner","Anthony","832-72-3066","Electronics engineer",43.0],["Turner","Steve","667-97-7420","Chartered legal executive (England and Wales)",9.0],["Brown","Christina","769-36-8630","Building surveyor",45.0],["Rodriguez","Theresa","037-57-6293","Engineering geologist",13.0],["Lowery","Amy","393-42-0375","Engineer, aeronautical",0.0],["Gomez","Scott","230-98-7126","Industrial buyer",43.0],["Lawson","Kaitlin","223-03-1093","Ceramics designer",25.0],["Shah","Anthony","624-61-2745","Adult guidance worker",10.0],["Roberts","Brent","400-68-0799","Office manager",41.0],["Coleman","Benjamin","601-87-9998","Race relations officer",15.0],["Hernandez","Melinda","436-56-8980","Research scientist (life sciences)",7.0],["Kaufman","Sarah","034-92-8913","Investment analyst",28.0],["Patton","Kevin","549-26-5447","Charity officer",12.0],["Rivera","Thomas","469-87-4612","Print production planner",28.0],["Parker","Shelly","058-45-0379","Psychotherapist, child",44.0],["Barajas","Amanda","871-32-9096","Acupuncturist",28.0],["Walsh","Jenna","102-54-0363","Intelligence analyst",35.0],["Hansen","David","123-30-0085","Surveyor, rural practice",32.0],["Johns","Angela","301-01-2385","Producer, television/film/video",11.0],["Mejia","Susan","133-54-8396","Sales professional, IT",3.0],["Alexander","Joseph","546-87-1980","Building services engineer",28.0],["Scott","Nathan","208-43-4115","Public librarian",44.0],["Walker","Belinda","686-66-3142","Merchandiser, retail",2.0],["Cunningham","Emily","263-40-9189","Artist",29.0],["Crawford","Amy","038-54-8119","Immunologist",2.0],["Butler","Olivia","667-41-1753","Web designer",22.0],["Webster","Kenneth","462-69-2868","Toxicologist",40.0],["Bowman","Alison","620-73-8531","Operational researcher",37.0],["Williams","Katie","846-05-5665","Speech and language therapist",26.0],["Hill","Damon","352-70-1960","Engineer, electrical",15.0],["Villegas","Alison","210-40-3499","Facilities manager",0.0],["Evans","Nicole","795-25-0640","Engineer, energy",31.0],["Gardner","Joe","807-91-0727","Cartographer",12.0],["Boone","Mary","493-27-0379","Insurance underwriter",7.0],["Quinn","Kelsey","785-12-6275","Purchasing manager",3.0],["Hunt","Jason","229-63-0568","Rural practice surveyor",14.0],["Cabrera","Sarah","642-20-6057","Development worker, community",15.0],["Washington","Roger","315-71-5985","Field seismologist",29.0],["Barrera","Elizabeth","744-05-2136","Insurance claims handler",32.0],["Simpson","Mark","692-33-1440","Charity fundraiser",3.0],["Gallagher","Timothy","591-75-3551","Insurance account manager",8.0],["Stewart","Roy","847-09-1905","Music therapist",10.0],["Santiago","William","085-04-1604","Location manager",0.0],["Brown","Adam","596-29-5219","Wellsite geologist",25.0],["Torres","Melissa","091-88-1315","Database administrator",29.0],["Lopez","Rebecca","805-72-5522","Programmer, systems",9.0],["Herring","Michelle","706-53-7620","Designer, blown glass/stained glass",28.0],["Martinez","Ashley","827-39-8944","Farm manager",37.0],["Gibson","Anne","009-76-6221","Radiographer, diagnostic",15.0],["Alexander","Sean","014-23-2367","Sub",10.0],["Sanders","Craig","659-84-0855","Recruitment consultant",34.0],["Keller","Yvonne","507-56-3863","Nurse, children's",6.0],["Glen","Mr.","284-91-8275","Therapist, drama",15.0],["Michelle","Dr.","582-53-1808","Civil engineer, consulting",37.0],["Johnson","David","474-14-0510","International aid/development worker",19.0],["Brown","Rebecca","669-66-0503","Accommodation manager",28.0],["Watts","Jennifer","098-35-4540","Engineer, building services",20.0],["Morrison","Cassandra","188-07-3537","Bonds trader",23.0],["Anderson","Beverly","621-47-4981","Hydrographic surveyor",17.0],["Howard","Michelle","705-54-1723","Tree surgeon",33.0],["Smith","Lisa","671-77-6074","Mining engineer",10.0],["Bailey","James","568-66-3391","Technical sales engineer",46.0],["Carr","Walter","730-98-7879","Primary school teacher",13.0],["White","Jaime","892-12-7919","Town planner",28.0],["Campos","Karen","543-64-5573","Garment/textile technologist",44.0],["Jones","Bernard","580-49-0002","Sales executive",28.0],["Moon","Jason","594-79-2253","Armed forces training and education officer",22.0],["Hicks","Bethany","299-56-4579","Actuary",44.0],["Flores","Kimberly","205-49-2835","Production designer, theatre/television/film",23.0],["Smith","Heather","009-06-3934","Financial risk analyst",3.0],["Johnson","Amanda","048-46-5874","Sports administrator",2.0],["Reeves","Katelyn","693-76-2464","Financial adviser",24.0],["Dunn","Amanda","772-52-8712","Freight forwarder",34.0],["Park","Kristen","070-19-0596","Training and development officer",40.0],["Wilson","Jean","765-60-0491","Television production assistant",14.0],["White","Anna","771-69-8980","Translator",39.0],["Pineda","Adam","309-42-4500","Camera operator",5.0],["Blanchard","Scott","563-01-2874","Radiation protection practitioner",20.0],["Salazar","Kenneth","513-02-4021","Commercial horticulturist",33.0],["Myers","Kelly","804-96-1113","Fashion designer",11.0],["Hayden","Susan","308-85-1044","Dentist",4.0],["Rojas","Terrence","185-52-0395","Embryologist, clinical",3.0],["Kim","Ian","272-64-3509","Ophthalmologist",44.0],["Mendoza","John","073-69-7198","Psychotherapist",25.0],["Stevens","David","739-65-7988","Theatre stage manager",8.0],["Richardson","Walter","470-61-4867","Aeronautical engineer",22.0],["Pope","Jonathan","045-84-1899","Administrator, Civil Service",27.0],["Avila","Johnny","319-66-2094","Careers information officer",28.0],["Davis","Steve","148-50-4594","Tree surgeon",27.0],["Osborne","Jacqueline","780-50-1666","Surveyor, building control",27.0],["Brewer","Kim","140-71-2817","Chemist, analytical",25.0],["Parker","Matthew","329-94-2950","Academic librarian",40.0],["Sanders","Christina","731-69-8091","Trade mark attorney",35.0],["Morris","Richard","076-46-6106","Recycling officer",22.0],["Sanchez","Nicole","475-88-6808","Interior and spatial designer",25.0],["Martin","Sheri","398-38-3139","Youth worker",16.0],["Morris","Scott","476-41-8394","Photographer",17.0],["Livingston","Jose","285-99-7026","Print production planner",10.0],["Harrell","Michele","265-16-4343","Newspaper journalist",5.0],["Boone","Nicholas","453-58-1977","Land/geomatics surveyor",6.0],["Gonzales","Daniel","488-87-8933","Technical sales engineer",8.0],["Bishop","Steven","675-79-0218","Conservation officer, historic buildings",33.0],["Jenkins","Gina","217-05-1810","Geoscientist",33.0],["Webb","Nicole","345-46-0943","Armed forces training and education officer",29.0],["Kelly","Joseph","015-05-3715","Investment analyst",46.0],["Mckenzie","Jennifer","753-70-7912","Seismic interpreter",33.0],["Norton","Pamela","773-86-7734","Scientist, research (life sciences)",43.0],["Alvarado","Joseph","061-34-7567","Purchasing manager",30.0],["Peck","Donald","662-69-4481","International aid/development worker",6.0],["Lozano","Malik","695-67-9630","Jewellery designer",45.0],["Cooper","Eric","296-74-2960","Armed forces training and education officer",19.0],["Graham","Nicolas","361-74-9732","Production engineer",37.0],["Hall","Jacob","083-37-2279","Counselling psychologist",33.0],["Benson","Nicole","465-88-3874","Advice worker",40.0],["Pacheco","Kristen","452-74-8420","Planning and development surveyor",10.0],["Robinson","Amber","630-80-0217","Clinical scientist, histocompatibility and immunogenetics",23.0],["Anderson","Jeffrey","011-71-4630","Scientist, physiological",1.0],["Jones","Robert","668-70-5552","Educational psychologist",7.0],["Moreno","Andrew","155-04-6493","Regulatory affairs officer",0.0],["Jones","Mitchell","899-28-1426","Scientific laboratory technician",12.0],["Goodwin","Brandi","418-65-7232","Engineer, maintenance (IT)",32.0],["Smith","Peter","121-90-1398","Social worker",24.0],["Jackson","Chelsea","333-84-5533","Recruitment consultant",44.0],["Wolf","Julian","378-32-6867","Equality and diversity officer",16.0],["Bernard","Kelly","349-62-6606","Designer, television/film set",38.0],["Norman","Danny","224-25-6407","Child psychotherapist",25.0],["Burns","Carrie","239-49-9602","Science writer",45.0],["Jackson","Nancy","891-29-7355","Land",15.0],["Hodge","Andrew","403-63-8461","Phytotherapist",26.0],["Carter","Aaron","037-31-1002","Operations geologist",21.0],["Mccormick","Tara","362-06-0117","Historic buildings inspector/conservation officer",38.0],["Strong","Anita","771-56-3362","Health and safety inspector",34.0],["Barr","Jesse","684-19-4522","Database administrator",10.0],["Espinoza","Melissa","011-69-1134","Environmental health practitioner",14.0],["Jensen","Danielle","086-97-9711","Multimedia specialist",44.0],["Larson","John","558-74-1178","Education officer, environmental",7.0],["Nelson","Phillip","707-68-9664","Town planner",2.0],["King","Rachel","031-56-3190","Accountant, chartered certified",30.0],["Davis","Heather","662-43-3308","Medical laboratory scientific officer",32.0],["Hall","Kristina","177-79-6020","Land",9.0],["Rodriguez","Melissa","220-02-0739","Systems analyst",37.0],["Meadows","Samantha","531-73-3151","Hotel manager",28.0],["Howell","Edward","270-19-9947","Engineer, communications",32.0],["Page","Austin","181-06-0870","Private music teacher",42.0],["Newton","William","686-56-4297","Designer, jewellery",16.0],["Smith","Daniel","480-94-9613","Medical physicist",34.0],["Johnson","Sandra","058-62-3415","Food technologist",34.0],["Wood","Linda","647-42-6972","Social researcher",44.0],["Gonzalez","Ashley","005-85-6907","Interior and spatial designer",35.0],["Jimenez","Dawn","818-41-4248","Community pharmacist",43.0],["Fuller","John","843-83-8178","Retail banker",46.0],["Mcconnell","Seth","169-01-9850","Information systems manager",31.0],["Hill","Kelsey","445-26-7831","Architect",14.0],["Garcia","Jennifer","293-22-4349","Education administrator",26.0],["Smith","Tammy","638-16-6944","Engineer, civil (consulting)",9.0],["Crawford","Maurice","728-55-9980","Magazine journalist",17.0],["Young","Andrew","427-17-4074","Surveyor, planning and development",45.0],["Phillips","Heather","592-85-4470","Scientist, audiological",16.0],["Mathews","Andrew","149-07-6505","Horticultural therapist",32.0],["Dillon","Tiffany","741-09-0003","Water quality scientist",27.0],["Campbell","Mark","409-88-4284","Press sub",42.0],["Brown","Kimberly","674-01-3788","Lecturer, higher education",6.0],["Taylor","Kimberly","729-84-2100","Surveyor, mining",17.0],["Cruz","Jeffery","587-98-0341","Intelligence analyst",10.0],["Fletcher","Kimberly","720-86-1617","Engineer, drilling",2.0],["Reynolds","Jerry","774-55-7651","Rural practice surveyor",21.0],["Jackson","Lisa","028-47-2822","Manufacturing engineer",2.0],["Snyder","Scott","667-67-0176","Horticultural therapist",19.0],["Singh","John","214-38-0370","Scientist, research (physical sciences)",29.0],["Dawson","Lauren","156-12-5404","Music tutor",14.0],["Simmons","Sheila","613-90-7054","Therapist, nutritional",44.0],["Payne","Pamela","245-81-4830","Retail manager",42.0],["Vincent","Roger","540-40-8809","Database administrator",39.0],["Silva","Jessica","393-72-4891","Dispensing optician",1.0],["Elliott","Amy","618-30-2449","Production engineer",19.0],["Wong","Benjamin","898-18-0335","Legal secretary",5.0],["Morris","Jennifer","549-28-7516","Retail buyer",31.0],["Ward","Kendra","588-08-6723","Loss adjuster, chartered",5.0],["Munoz","Curtis","679-83-8302","Field seismologist",2.0],["Moore","Michael","216-24-7392","Advertising account executive",29.0],["Ortiz","Ronnie","294-90-3564","Commercial art gallery manager",27.0],["Cooper","Matthew","207-04-6639","Producer, radio",14.0],["Khan","Joseph","712-80-0904","Investment banker, corporate",0.0],["Maxwell","Christine","203-05-2797","Medical illustrator",24.0],["Beasley","David","369-68-1067","Higher education careers adviser",34.0],["Frazier","Patricia","282-68-1430","Surveyor, insurance",38.0],["Garcia","Amy","742-48-5822","Trade union research officer",6.0],["Morris","Tanya","521-97-1453","Clothing/textile technologist",44.0],["Schultz","Troy","352-82-5872","Investment banker, corporate",1.0],["Preston","Kathryn","899-76-6116","Programmer, multimedia",30.0],["Hernandez","Christopher","759-83-0439","Mechanical engineer",43.0],["Vega","Robert","247-20-5024","Dealer",26.0],["Wilkins","Anna","185-37-6648","Dietitian",26.0],["Walker","Samantha","178-14-9574","Music therapist",22.0],["Robbins","Ricky","026-45-3224","Bonds trader",44.0],["Jacobs","Denise","335-02-0572","Armed forces training and education officer",32.0],["Robinson","Lauren","033-05-3378","Environmental education officer",46.0],["Ibarra","Eric","883-12-3211","Museum/gallery curator",41.0],["Murray","Shawn","575-34-7180","Geophysicist/field seismologist",29.0],["Webb","Jeremy","252-11-6931","Museum/gallery exhibitions officer",29.0],["Steele","Edward","721-17-9107","Graphic designer",20.0],["Gomez","Emily","103-84-4663","Architectural technologist",36.0],["Thompson","Tina","147-41-1068","Energy engineer",23.0],["Lutz","Andrea","773-72-6602","Scientist, clinical (histocompatibility and immunogenetics)",18.0],["Turner","Gary","561-88-0156","Town planner",4.0],["Bullock","Raymond","182-32-3958","Theatre director",44.0],["Brown","Daniel","859-80-6118","Scientist, forensic",22.0],["Maxwell","Kellie","798-81-7717","Leisure centre manager",25.0],["Bowers","Kimberly","453-76-0342","Dispensing optician",17.0],["Kim","Natalie","483-98-9692","Publishing rights manager",40.0],["Yates","Debra","656-26-6080","Chemist, analytical",6.0],["Dixon","Laura","867-24-4631","Personnel officer",7.0],["Wilson","Timothy","628-10-8805","Oncologist",41.0],["Lawrence","Cassandra","736-53-6339","Copy",27.0],["Harrison","Keith","067-67-5102","Medical physicist",36.0],["Vaughn","Cynthia","814-35-4953","Exercise physiologist",46.0],["Hudson","Jessica","166-67-9568","Engineering geologist",39.0],["Briggs","Cody","428-81-7700","Science writer",6.0],["Smith","Andrea","224-74-9388","Programmer, multimedia",41.0],["Gutierrez","David","302-99-3694","Engineer, building services",14.0],["Flowers","Deborah","187-85-0640","Air cabin crew",32.0],["Warren","Eric","259-07-5904","Teaching laboratory technician",23.0],["James","Heather","424-52-7377","Surveyor, rural practice",46.0],["Monroe","Ann","823-90-8785","Health visitor",10.0],["Hoover","Michael","386-26-6588","Designer, textile",2.0],["Cline","David","104-93-2335","Public affairs consultant",17.0],["Samuel","Mr.","317-51-6962","Veterinary surgeon",27.0],["Robbins","Erik","317-84-9516","Nutritional therapist",15.0],["Morrow","Paul","361-89-8753","Video editor",13.0],["Cruz","Sandra","622-67-5069","Market researcher",1.0],["Gray","Rebecca","537-27-4534","Conference centre manager",30.0],["Fisher","Mary","525-33-1920","Designer, fashion/clothing",43.0],["Jackson","Michael","133-20-6611","Engineer, site",27.0],["Guzman","Shawn","125-18-2035","Journalist, broadcasting",6.0],["Mccann","April","289-13-8594","Waste management officer",10.0],["Hamilton","Samantha","163-19-1512","Academic librarian",8.0],["Barker","Jared","085-35-9457","Therapist, nutritional",28.0],["Hayes","Kevin","626-68-2333","Estate agent",31.0],["Johnson","Richard","354-01-1537","Personal assistant",46.0],["Gonzalez","Michael","141-93-3638","Engineer, land",39.0],["Robinson","Jacob","205-86-5314","Merchant navy officer",37.0],["Barnes","Joyce","244-07-0582","Mining engineer",37.0],["Graves","David","755-64-3936","Transport planner",40.0],["Johnson","Andrew","297-51-0577","Control and instrumentation engineer",45.0],["Collins","Joy","424-82-4981","Medical physicist",12.0],["Allen","Carla","271-07-0097","Scientist, forensic",3.0],["Ware","Derek","616-75-4113","Retail merchandiser",22.0],["Weiss","Christopher","162-85-1316","Futures trader",29.0],["Flores","Carolyn","696-59-2547","Pharmacist, community",12.0],["Perez","Elizabeth","805-70-5311","Warehouse manager",35.0],["Bradley","Rose","792-85-6577","Production assistant, radio",43.0],["Gomez","Brittany","160-39-0076","Television/film/video producer",27.0],["Kennedy","Bryan","177-33-6587","Exhibitions officer, museum/gallery",34.0],["Gray","Katelyn","889-16-8409","Corporate treasurer",40.0],["Tucker","Melissa","719-96-9807","Scientist, biomedical",9.0],["Perry","Tara","815-08-1522","Surveyor, building",16.0],["Herrera","Brandon","167-32-3072","Buyer, industrial",9.0],["Dominguez","Jennifer","025-56-6011","Radio producer",15.0],["Dunlap","Katie","133-62-0708","Charity officer",42.0],["Black","Valerie","272-94-6439","English as a second language teacher",6.0],["Ritter","Calvin","805-98-7013","Art gallery manager",13.0],["Gay","Lacey","881-11-5438","Market researcher",44.0],["Jones","Makayla","064-99-6951","Editor, commissioning",24.0],["Lynch","Samuel","814-08-7929","Theatre stage manager",23.0],["Wheeler","Jennifer","221-10-3082","Clothing/textile technologist",38.0],["Solis","Jessica","664-79-3660","Embryologist, clinical",5.0],["Lopez","Jeremy","298-87-7394","Civil Service fast streamer",2.0],["Ortega","Amy","291-29-0102","Engineer, land",45.0],["Sanchez","Joseph","027-28-8530","Engineer, land",3.0],["Alexander","Michael","869-73-2493","Lecturer, further education",9.0],["Lowe","Angelica","405-78-9760","Systems analyst",20.0],["Daniels","Michael","124-69-5221","Museum/gallery exhibitions officer",11.0],["Ryan","Christopher","275-31-7361","Facilities manager",30.0],["Mason","Ruben","439-02-5160","Textile designer",9.0],["Ryan","Theresa","623-59-0903","Naval architect",23.0],["Freeman","Stephanie","267-13-4091","Tour manager",8.0],["Ryan","Ronald","457-81-8145","Interior and spatial designer",28.0],["Dominguez","Gene","394-14-2738","Equities trader",34.0],["Rivas","Alexis","031-47-9767","IT consultant",44.0],["Tran","Melanie","121-79-7624","Journalist, magazine",43.0],["Johns","Amanda","858-64-1177","Scientist, research (physical sciences)",34.0],["Lewis","Sharon","897-53-9398","International aid/development worker",2.0],["Smith","Bryan","586-02-7087","Translator",8.0],["Baker","Christine","374-87-7884","Surveyor, mining",40.0],["Figueroa","Robin","642-98-6482","Conservation officer, historic buildings",40.0],["Smith","Jamie","624-72-5616","Trade union research officer",29.0],["Sullivan","Ricardo","729-36-3853","Engineer, structural",45.0],["Hughes","Cassidy","054-52-8029","Mining engineer",6.0],["Kelly","Robert","601-29-7204","Geneticist, molecular",35.0],["Nunez","Edward","569-69-2984","Social research officer, government",28.0],["Walker","Margaret","344-92-2074","Fashion designer",14.0],["Tucker","Kyle","024-96-2604","Fisheries officer",22.0],["Berry","Olivia","655-64-6286","Environmental manager",22.0],["Jones","Nicole","793-27-9482","Equities trader",25.0],["Hampton","Heather","077-87-0623","Physiotherapist",4.0],["Burke","Craig","708-61-6015","Educational psychologist",23.0],["Arnold","Thomas","341-92-1356","Farm manager",46.0],["Tate","Brandon","380-43-1881","Scientist, research (maths)",5.0],["Hayes","Darryl","115-96-8588","Editor, magazine features",46.0],["Smith","Kurt","015-94-0014","Buyer, industrial",18.0],["Barrett","Tiffany","191-89-9543","Osteopath",32.0],["Baker","Andre","280-70-5820","Barrister's clerk",17.0],["Mcgrath","Joseph","578-40-9293","Engineer, energy",41.0],["Allen","Jennifer","672-48-3900","Charity fundraiser",24.0],["Gray","Emily","515-15-7424","Scientific laboratory technician",2.0],["Schroeder","Erin","456-27-7059","Theatre manager",39.0],["Kline","Karen","580-31-7992","Journalist, newspaper",30.0],["Patel","Kimberly","757-43-9893","Radio producer",21.0],["Thomas","Tracey","449-41-4560","Materials engineer",17.0],["Brewer","Phillip","697-99-4294","Naval architect",26.0],["Hall","John","524-77-5695","Banker",26.0],["Brown","David","754-91-2578","Medical secretary",15.0],["Bowman","Jonathan","563-77-3115","Engineer, building services",43.0],["Fields","Stephen","425-24-5284","Surveyor, hydrographic",2.0],["Price","David","362-49-3978","Animator",23.0],["Jones","Benjamin","076-97-4369","Market researcher",27.0],["Collier","Brittany","102-61-3983","Mining engineer",32.0],["Hartman","Lisa","684-44-8427","Secretary/administrator",15.0],["Dunn","Charles","010-77-7593","Nurse, adult",8.0],["Thomas","Brent","451-88-7373","Psychiatric nurse",20.0],["Stanton","James","032-46-1412","Acupuncturist",19.0],["Wood","Javier","673-69-0340","Art gallery manager",24.0],["Solis","Jonathan","338-14-7217","Learning disability nurse",44.0],["Morris","Terry","703-61-7203","Sales professional, IT",7.0],["Doyle","David","639-96-6361","Production manager",33.0],["Pope","Russell","832-66-8555","Optician, dispensing",12.0],["Frazier","David","140-68-2113","Control and instrumentation engineer",40.0],["Martin","William","759-77-2240","Trade mark attorney",18.0],["Singh","Steven","408-76-8800","Mudlogger",7.0],["Morrison","Tyler","028-89-0043","Network engineer",42.0],["Clay","Tammy","024-14-2816","Health visitor",9.0],["Gallegos","James","654-24-1767","Archaeologist",20.0],["Jennifer","Mrs.","656-39-9639","Education officer, community",13.0],["Gonzalez","Carly","156-61-2502","Engineer, maintenance",38.0],["Martin","Christine","846-60-9551","Radio producer",24.0],["Hess","Jeremy","750-77-3395","Financial manager",43.0],["Santiago","Robert","522-83-3410","Chartered legal executive (England and Wales)",45.0],["Carter","Michael","057-45-0736","Telecommunications researcher",45.0],["Reilly","Lisa","855-34-8642","Fish farm manager",46.0],["Shelton","Christopher","051-40-5875","Learning disability nurse",3.0],["Garcia","Brandi","037-79-5585","Clinical biochemist",9.0],["Fritz","Richard","703-01-5527","Equities trader",26.0],["Mcconnell","Brandon","718-85-3307","Scientist, research (physical sciences)",46.0],["Phillips","Barbara","569-57-8719","Teaching laboratory technician",42.0],["Nash","Elizabeth","306-26-0940","Actor",28.0],["Singleton","Samuel","568-65-5768","IT technical support officer",29.0],["Morris","Austin","243-89-4326","Community education officer",32.0],["Frank","Julie","872-92-6257","Psychotherapist, child",30.0],["Benson","Jeanette","400-04-9949","Economist",33.0],["Lopez","Anthony","411-78-3576","Art therapist",43.0],["Williams","Andrea","151-45-4306","Scientist, biomedical",40.0],["Jenkins","Andrew","465-78-0001","Police officer",34.0],["Foley","Anthony","299-65-4888","Designer, interior/spatial",31.0],["Wood","Donna","879-86-6931","Emergency planning/management officer",21.0],["Carr","Linda","658-82-3362","Warden/ranger",7.0],["Sanders","Jesse","134-21-2257","Psychologist, educational",34.0],["Chang","Melissa","574-34-2491","Microbiologist",17.0],["Reid","David","476-20-0982","Nurse, mental health",23.0],["Griffin","Shawn","600-92-5137","Maintenance engineer",41.0],["Smith","Heather","824-21-8949","Animator",23.0],["Williams","Diana","456-14-3902","Oncologist",9.0],["Brooks","Gina","305-20-3994","Field seismologist",37.0],["Klein","Lisa","791-61-6443","Air broker",15.0],["Stephens","Matthew","813-83-7236","Animal technologist",42.0],["Wise","James","614-70-9285","Media planner",45.0],["Campbell","Lisa","105-58-1342","Tax inspector",9.0],["Stevens","Amber","775-60-1424","Retail buyer",25.0],["Campbell","Brian","224-43-7235","Garment/textile technologist",37.0],["Griffith","Joseph","331-47-6698","Television/film/video producer",41.0],["Williams","Jordan","317-55-2600","Sports therapist",32.0],["Webb","Alicia","101-28-6102","Therapeutic radiographer",42.0],["Brown","Tina","797-91-9393","Furniture conservator/restorer",0.0],["Brown","Stephanie","119-37-1286","Teacher, primary school",13.0],["Atkinson","Tiffany","236-39-3583","Editor, film/video",19.0],["Frazier","Jerry","401-05-8540","Careers information officer",5.0],["Short","Randy","227-74-3247","Exhibitions officer, museum/gallery",1.0],["Murphy","Lori","241-50-9517","Call centre manager",25.0],["Flores","Frederick","775-11-3299","Meteorologist",5.0],["Villegas","Mark","347-81-7848","Publishing rights manager",12.0],["Terrell","Eric","508-84-2917","Acupuncturist",3.0],["Webster","Deborah","819-17-4922","Designer, multimedia",39.0],["Bell","Karen","249-44-8029","Communications engineer",19.0],["Small","Brent","135-27-9079","Tax adviser",27.0],["Bush","Barbara","343-38-6214","IT technical support officer",42.0],["Carson","Emily","131-99-1858","Museum/gallery curator",26.0],["Douglas","Kathryn","432-38-7115","Librarian, academic",45.0],["Wilkinson","Amy","829-63-8659","Retail buyer",33.0],["Craig","Omar","036-41-3244","Tree surgeon",27.0],["Banks","Randy","285-45-5040","Conservator, furniture",13.0],["Reynolds","Dana","404-85-0742","Surveyor, planning and development",20.0],["Gibson","Cindy","142-62-5610","Broadcast journalist",14.0],["Wells","Wendy","233-72-7751","Chiropodist",17.0],["Wilson","Victoria","109-96-2906","Magazine features editor",27.0],["Montgomery","Jennifer","443-41-3506","Stage manager",44.0],["Mccoy","Joshua","525-30-0815","Operational investment banker",35.0],["Gaines","Kim","358-55-2318","Insurance underwriter",9.0],["Wilson","Carolyn","375-45-7081","Loss adjuster, chartered",33.0],["Garcia","William","217-91-3248","Analytical chemist",39.0],["Hamilton","Ryan","872-11-9470","Lexicographer",24.0],["Jones","Phillip","587-69-3661","Health and safety inspector",27.0],["Williams","Tiffany","053-19-5139","Visual merchandiser",21.0],["Pacheco","William","576-13-6722","Geoscientist",1.0],["Ortiz","Joel","565-31-6541","Recycling officer",32.0],["Jensen","Stephen","276-26-4146","Magazine journalist",38.0],["Lawson","Dakota","068-82-9518","Banker",35.0],["Willis","Ricardo","710-53-9181","Farm manager",13.0],["Randall","Nathaniel","743-47-6268","Farm manager",32.0],["Page","Lucas","567-34-2041","Engineer, chemical",15.0],["Padilla","Heather","762-53-5566","Ranger/warden",21.0],["Clark","Robert","311-79-6056","Television camera operator",45.0],["Rowe","Holly","082-93-8771","Curator",39.0],["Greer","Barbara","148-87-6240","Clinical cytogeneticist",26.0],["Holland","Jasmine","423-76-7121","Software engineer",34.0],["James","Rachel","290-44-4228","Higher education careers adviser",46.0],["Kennedy","Jonathan","687-53-1300","Merchandiser, retail",30.0],["White","Kimberly","355-21-1656","Petroleum engineer",7.0],["Johnson","Brian","892-78-9752","Runner, broadcasting/film/video",18.0],["Byrd","Justin","081-21-5128","Statistician",2.0],["Mann","Julia","323-55-7191","Engineer, production",12.0],["Hughes","Lucas","664-87-0940","Heritage manager",9.0],["Medina","Jeffrey","840-71-9011","Cytogeneticist",12.0],["Lucas","Kellie","059-90-7992","Animal technologist",2.0],["Carter","Brandon","016-94-0738","Public relations account executive",0.0],["Bush","Jacob","628-49-4189","Marine scientist",9.0],["Mason","Jacob","398-29-3809","Hospital doctor",37.0],["Hardin","Edward","383-01-5460","Commercial/residential surveyor",31.0],["Franklin","Keith","838-54-1413","Financial risk analyst",18.0],["Ortiz","Jeremy","413-31-0068","Scientist, audiological",43.0],["Hughes","Richard","895-59-6262","Dancer",22.0],["Long","Daniel","102-66-4295","Health and safety adviser",12.0],["Sanchez","Ashley","103-74-3069","Scientist, research (medical)",35.0],["Friedman","Amanda","047-84-7307","Health and safety adviser",39.0],["Craig","Krystal","525-59-5144","Administrator, sports",24.0],["Hebert","Jenna","742-45-9931","TEFL teacher",23.0],["Smith","Frances","429-57-7715","Corporate treasurer",45.0],["King","Joseph","065-32-0895","Designer, graphic",29.0],["Blankenship","Shannon","298-23-8274","Control and instrumentation engineer",29.0],["Davis","Patricia","059-45-4716","Lawyer",13.0],["Jones","Ricardo","380-78-6955","Artist",7.0],["Mora","Shari","586-20-1478","Technical author",18.0],["Perry","Roberta","089-10-9220","Information systems manager",11.0],["Bell","Samuel","647-60-7999","Actuary",5.0],["Sanders","Brian","178-45-0122","Pension scheme manager",19.0],["Palmer","Chad","668-18-2559","Waste management officer",38.0],["Patterson","Rebecca","867-16-9525","Armed forces operational officer",30.0],["Mooney","Laura","196-40-4783","Administrator, local government",43.0],["Evans","Ashley","303-63-9314","Engineer, agricultural",13.0],["Smith","Judith","552-26-4824","Outdoor activities/education manager",15.0],["Griffith","Dustin","739-88-7892","Travel agency manager",44.0],["Lynch","John","660-17-0277","Surveyor, hydrographic",46.0],["Mcguire","Joshua","182-91-6708","Administrator, sports",43.0],["Cline","Morgan","482-41-9932","Furniture conservator/restorer",42.0],["Anderson","Terry","772-36-4886","Politician's assistant",15.0],["Moran","Megan","500-89-9157","Chemical engineer",43.0],["Stevens","Brittany","861-83-8790","Educational psychologist",25.0],["Anderson","Anthony","538-93-0988","Environmental manager",9.0],["Stewart","Lisa","459-82-4870","Textile designer",36.0],["Baker","Matthew","010-76-9923","Production designer, theatre/television/film",39.0],["Ortiz","Carol","678-42-6323","Programmer, multimedia",21.0],["Williams","Joseph","020-04-3587","Medical secretary",8.0],["Walsh","Katrina","079-11-1104","Education officer, environmental",19.0],["Ellison","Lauren","029-78-5712","Solicitor",8.0],["Torres","Victoria","268-42-9050","Education officer, museum",13.0],["Guerrero","Joseph","481-79-4458","Psychologist, educational",17.0],["Roberts","Anthony","222-48-9049","Therapist, speech and language",32.0],["Wells","Kevin","441-69-8919","Engineer, mining",10.0],["Cantrell","Chase","267-56-8452","Technical sales engineer",32.0],["Clark","Sarah","557-16-1982","Licensed conveyancer",2.0],["Kane","Kimberly","437-37-5863","Music tutor",17.0],["Russell","Samuel","527-83-1791","Air broker",27.0],["Bond","Francis","120-14-0822","Visual merchandiser",10.0],["Rodgers","Billy","777-92-4157","Agricultural consultant",24.0],["Torres","Alexandria","236-53-6722","Medical technical officer",6.0],["Evans","Melissa","626-01-9995","Therapist, speech and language",25.0],["Murray","Gary","497-17-2114","Restaurant manager",15.0],["Perez","Keith","649-22-4858","Osteopath",9.0],["Bennett","Amy","485-08-4565","Industrial/product designer",20.0],["Morgan","Donald","579-13-2264","Illustrator",10.0],["Hopkins","William","083-34-8597","Town planner",15.0],["Castillo","Ryan","833-80-6234","Government social research officer",17.0],["Caldwell","James","459-99-1079","Land",7.0],["Smith","Erin","760-72-7953","Animal nutritionist",6.0],["May","Michael","612-45-3713","Forensic scientist",44.0],["Lyons","Adam","289-03-6776","Energy manager",24.0],["Estrada","Justin","386-88-3134","Surveyor, insurance",39.0],["Faulkner","Cynthia","249-40-0242","Games developer",37.0],["Sexton","Lynn","236-19-5944","Engineer, water",9.0],["Harvey","Melanie","867-92-5477","Herbalist",41.0],["Bishop","Kimberly","320-43-6786","Designer, jewellery",22.0],["Miller","Gwendolyn","364-54-1349","Theatre stage manager",17.0],["Sweeney","Lori","346-31-4855","Doctor, general practice",12.0],["Young","Barbara","658-79-8638","Ergonomist",22.0],["Jordan","Marc","794-34-0349","Financial planner",24.0],["Solomon","Sabrina","425-88-6209","Horticultural therapist",15.0],["Cox","Leslie","042-04-8101","Diagnostic radiographer",8.0],["Johnson","Patricia","429-19-1249","Barrister's clerk",41.0],["Doyle","Lisa","552-20-7838","Educational psychologist",26.0],["Mckee","Jesse","542-36-5483","Surveyor, mining",32.0],["Cook","Richard","361-21-9143","Geoscientist",10.0],["Wong","Keith","392-26-5526","Radiographer, therapeutic",0.0],["Lyons","Amanda","368-50-5700","Surveyor, insurance",34.0],["Snyder","Kevin","341-40-8665","Tourist information centre manager",21.0],["Henderson","Daniel","521-25-1616","Television camera operator",7.0],["Garcia","Melissa","514-75-9795","Secretary/administrator",5.0],["Parker","Rebecca","882-75-5586","Tourist information centre manager",7.0],["Johnson","Sarah","325-57-6036","Field seismologist",22.0],["Glass","Gina","318-25-0593","Psychotherapist, dance movement",42.0],["Gutierrez","Michelle","368-93-8707","Fashion designer",17.0],["Wilson","Jordan","691-24-4454","Warehouse manager",43.0],["Carter","Stephanie","659-58-2181","Actuary",12.0],["Williams","Tami","201-23-5971","Sports administrator",40.0],["Samantha","Mrs.","826-78-3283","Quality manager",14.0],["Shelton","Tasha","761-47-9089","Engineer, chemical",14.0],["Marshall","Joel","758-76-5747","Pensions consultant",14.0],["Brooks","Shannon","422-84-1333","Recruitment consultant",39.0],["Gallegos","Barbara","453-85-3081","Passenger transport manager",17.0],["Fox","Jennifer","448-46-7427","Psychiatric nurse",46.0],["Taylor","Joseph","074-23-0965","Engineer, agricultural",8.0],["West","Timothy","204-74-1886","Teacher, primary school",32.0],["Armstrong","Janet","460-52-7820","Investment banker, operational",28.0],["Chambers","Victoria","853-14-6929","Bonds trader",30.0],["David","Mr.","033-71-8699","Product/process development scientist",45.0],["Randall","Shawn","183-72-9734","Product/process development scientist",33.0],["Smith","Brandon","551-79-9960","Geographical information systems officer",41.0],["Hammond","Phillip","060-39-2021","Scientific laboratory technician",18.0],["Dillon","Christina","542-37-1725","Charity fundraiser",38.0],["Moreno","Brady","029-46-1973","Bonds trader",14.0],["Walker","Brian","334-31-9694","Information officer",26.0],["Kline","Rachel","572-10-0342","Editor, commissioning",46.0],["Lambert","Lucas","708-86-3050","Buyer, industrial",23.0],["Welch","Shannon","053-10-8837","Ergonomist",33.0],["Nichols","Alicia","688-93-8275","Physiotherapist",45.0],["Shah","David","232-92-2566","Forensic psychologist",20.0],["Vazquez","Lisa","141-49-2345","Marine scientist",45.0],["Briggs","Louis","253-26-8959","Careers adviser",31.0],["Smith","Denise","434-34-6675","Cytogeneticist",3.0],["Mendez","Amber","285-97-8239","Occupational psychologist",16.0],["Eaton","Jerry","482-89-3773","Research scientist (medical)",9.0],["White","Jacob","825-90-9020","Drilling engineer",4.0],["Dunn","Jacqueline","181-07-2276","Programmer, multimedia",1.0],["Horn","Destiny","412-40-5331","Geneticist, molecular",25.0],["Vasquez","Erica","423-03-9615","Psychologist, forensic",33.0],["Miller","Miranda","499-03-9330","Make",32.0],["Finley","James","493-63-7322","Museum/gallery curator",39.0],["Jones","Sally","505-81-1719","Civil engineer, contracting",1.0],["Short","Nicole","463-21-2211","Medical secretary",14.0],["Chen","Nancy","365-08-7897","Customer service manager",45.0],["Clark","Joseph","005-71-0571","Records manager",44.0],["Casey","Todd","416-43-7729","Mudlogger",37.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"last_name","type":"\"string\""},{"name":"first_name","type":"\"string\""},{"name":"ssn","type":"\"string\""},{"name":"occupation","type":"\"string\""},{"name":"age","type":"\"long\""}],"overflow":true,"aggData":[[0.0,177.0],[0.92,221.0],[1.84,218.0],[2.7600000000000002,206.0],[3.68,186.0],[4.6000000000000005,222.0],[5.5200000000000005,225.0],[6.44,216.0],[7.36,216.0],[8.280000000000001,226.0],[9.200000000000001,208.0],[10.120000000000001,234.0],[11.96,220.0],[12.88,226.0],[13.8,196.0],[14.72,223.0],[15.64,188.0],[16.560000000000002,212.0],[17.48,223.0],[18.400000000000002,212.0],[19.32,203.0],[20.240000000000002,204.0],[21.16,228.0],[23.0,206.0],[23.92,219.0],[24.84,223.0],[25.76,230.0],[26.68,215.0],[27.6,251.0],[28.52,230.0],[29.44,211.0],[30.360000000000003,180.0],[31.28,226.0],[32.2,195.0],[33.120000000000005,215.0],[34.96,217.0],[35.88,230.0],[36.800000000000004,190.0],[37.72,206.0],[38.64,208.0],[39.56,195.0],[40.480000000000004,240.0],[41.4,204.0],[42.32,198.0],[43.24,202.0],[44.160000000000004,211.0],[46.0,208.0]],"aggSchema":[{"name":"__DATABRICKS_INTERNAL_HISTOGRAM_BIN_FIELD__","type":"\"double\""},{"name":"age","type":"\"long\""}],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"histogram","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674520107E12,"submitTime":1.476674525566E12,"finishTime":1.476674524679E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"histogram","width":"905","height":"467","xColumns":[],"yColumns":["age"],"pivotColumns":[],"pivotAggregation":"count","customPlotOptions":{"histogram":[{"key":"bins","value":"50"}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"061a04a9-4375-4f54-8b2c-f99bc0b85bf8"},{"version":"CommandV1","origId":1305471881462051,"guid":"de40d81b-4bd1-419d-a08f-70282fe716c0","subtype":"command","commandType":"auto","position":64.0,"command":"%md\n### (3e) Use _count_ to get total\n\nOne of the most basic jobs that we can run is the `count()` job which will count the number of elements in a DataFrame, using the `count()` action. Since `select()` creates a new DataFrame with the same number of elements as the starting DataFrame, we expect that applying `count()` to each DataFrame will return the same result.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/cs105x/diagram-3e.png\" style=\"height:700px;float:right\"/>\n\nNote that because `count()` is an action operation, if we had not already performed an action with `collect()`, then Spark would now perform the transformation operations when we executed `count()`.\n\nEach task counts the entries in its partition and sends the result to your SparkContext, which adds up all of the counts. The figure on the right shows what would happen if we ran `count()` on a small example dataset with just four partitions.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491163E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"047a0bc9-dafd-4323-ba7b-eecf7cdfc824"},{"version":"CommandV1","origId":1305471881462052,"guid":"3f868005-2e12-420a-b585-982cde380af2","subtype":"command","commandType":"auto","position":65.0,"command":"print dataDF.count()\nprint subDF.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">10000\n10000\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.471137507177E12,"submitTime":1.471137491187E12,"finishTime":1.471137507611E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"db62645d-c40e-40dd-a1bd-59be41227787"},{"version":"CommandV1","origId":1305471881462053,"guid":"b9215860-0c83-4fdd-a27b-b5193eb25454","subtype":"command","commandType":"auto","position":66.0,"command":"%md\n### (3f) Apply transformation _filter_ and view results with _collect_\n\nNext, we'll create a new DataFrame that only contains the people whose ages are less than 10. To do this, we'll use the `filter()` transformation. (You can also use `where()`, an alias for `filter()`, if you prefer something more SQL-like). The `filter()` method is a transformation operation that creates a new DataFrame from the input DataFrame, keeping only values that match the filter expression.\n\nThe figure shows how this might work on the small four-partition dataset.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/cs105x/diagram-3f.png\" style=\"height:700px;float:right\"/>\n\nTo view the filtered list of elements less than 10, we need to create a new list on the driver from the distributed data on the executor nodes.  We use the `collect()` method to return a list that contains all of the elements in this filtered DataFrame to the driver program.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491201E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2407edeb-0704-40dc-9e67-f1ab065bde69"},{"version":"CommandV1","origId":1305471881462054,"guid":"f04abc58-b07b-4e1c-8938-81adcda2babb","subtype":"command","commandType":"auto","position":67.0,"command":"filteredDF = subDF.filter(subDF.age < 10)\nfilteredDF.show(truncate=False)\nfilteredDF.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------+----------+-----------+------------------------------------------------+---+\n|last_name|first_name|ssn        |occupation                                      |age|\n+---------+----------+-----------+------------------------------------------------+---+\n|Curtis   |Kristen   |688-09-1018|Administrator, charities/voluntary organisations|7  |\n|Wood     |Jeremiah  |645-25-9468|Librarian, academic                             |5  |\n|Green    |David     |588-46-6358|Scientist, biomedical                           |0  |\n|Glenn    |Derrick   |337-51-5287|Patent attorney                                 |6  |\n|Miller   |Tiffany   |527-33-8046|Lighting technician, broadcasting/film/video    |3  |\n|Boyer    |Tiffany   |855-14-4693|Graphic designer                                |4  |\n|Nelson   |John      |732-19-3869|Commercial horticulturist                       |3  |\n|Williams |Richard   |430-04-3230|Ophthalmologist                                 |8  |\n|Campbell |Matthew   |755-53-2711|Tree surgeon                                    |4  |\n|Lopez    |Collin    |484-43-0522|Health and safety adviser                       |6  |\n|Ramos    |Tracy     |297-94-7225|Photographer                                    |5  |\n|Lang     |Jessica   |521-20-2148|Scientist, audiological                         |4  |\n|Cruz     |Michael   |767-70-5269|Licensed conveyancer                            |3  |\n|Thompson |Carrie    |465-02-5429|Teacher, music                                  |2  |\n|Gross    |Madison   |158-08-6750|Mental health nurse                             |2  |\n|Frederick|Daniel    |505-21-9276|Production engineer                             |5  |\n|Miles    |James     |891-37-2762|Health visitor                                  |7  |\n|Anderson |Lisa      |123-02-6786|Psychotherapist, child                          |9  |\n|Solis    |Michael   |011-79-8500|Production assistant, radio                     |5  |\n|Hudson   |Maria     |071-69-8159|Sub                                             |7  |\n+---------+----------+-----------+------------------------------------------------+---+\nonly showing top 20 rows\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">44</span><span class=\"ansired\">]: </span>2113\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674540754E12,"submitTime":1.476674546236E12,"finishTime":1.476674541181E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8778407f-eaa2-4231-aa1e-1a124e578591"},{"version":"CommandV1","origId":1305471881462055,"guid":"da70b758-c1a3-4c5a-ba84-169939e8042a","subtype":"command","commandType":"auto","position":68.0,"command":"%md\n(These are some _seriously_ precocious children...)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491234E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"10385ea2-9c2a-4db4-a924-07fbec430565"},{"version":"CommandV1","origId":1305471881462056,"guid":"2cff0ec6-2a41-4820-b08c-6c0f7505dc63","subtype":"command","commandType":"auto","position":69.0,"command":"%md\n## Part 4: Python Lambda functions and User Defined Functions\n\nPython supports the use of small one-line anonymous functions that are not bound to a name at runtime.\n\n`lambda` functions, borrowed from LISP, can be used wherever function objects are required. They are syntactically restricted to a single expression. Remember that `lambda` functions are a matter of style and using them is never required - semantically, they are just syntactic sugar for a normal function definition. You can always define a separate normal function instead, but using a `lambda` function is an equivalent and more compact form of coding. Ideally you should consider using `lambda` functions where you want to encapsulate non-reusable code without littering your code with one-line functions.\n\nHere, instead of defining a separate function for the `filter()` transformation, we will use an inline `lambda()` function and we will register that lambda as a Spark _User Defined Function_ (UDF). A UDF is a special wrapper around a function, allowing the function to be used in a DataFrame query.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491254E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8d14d0b4-68c3-4627-a705-73a593a3495e"},{"version":"CommandV1","origId":1305471881462057,"guid":"44336a9a-c7b4-495d-b919-79e4037dbdfc","subtype":"command","commandType":"auto","position":70.0,"command":"from pyspark.sql.types import BooleanType\nless_ten = udf(lambda s: s < 10, BooleanType())\nlambdaDF = subDF.filter(less_ten(subDF.age))\nlambdaDF.show()\nlambdaDF.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------+----------+-----------+--------------------+---+\n|last_name|first_name|        ssn|          occupation|age|\n+---------+----------+-----------+--------------------+---+\n|   Curtis|   Kristen|688-09-1018|Administrator, ch...|  7|\n|     Wood|  Jeremiah|645-25-9468| Librarian, academic|  5|\n|    Green|     David|588-46-6358|Scientist, biomed...|  0|\n|    Glenn|   Derrick|337-51-5287|     Patent attorney|  6|\n|   Miller|   Tiffany|527-33-8046|Lighting technici...|  3|\n|    Boyer|   Tiffany|855-14-4693|    Graphic designer|  4|\n|   Nelson|      John|732-19-3869|Commercial hortic...|  3|\n| Williams|   Richard|430-04-3230|     Ophthalmologist|  8|\n| Campbell|   Matthew|755-53-2711|        Tree surgeon|  4|\n|    Lopez|    Collin|484-43-0522|Health and safety...|  6|\n|    Ramos|     Tracy|297-94-7225|        Photographer|  5|\n|     Lang|   Jessica|521-20-2148|Scientist, audiol...|  4|\n|     Cruz|   Michael|767-70-5269|Licensed conveyancer|  3|\n| Thompson|    Carrie|465-02-5429|      Teacher, music|  2|\n|    Gross|   Madison|158-08-6750| Mental health nurse|  2|\n|Frederick|    Daniel|505-21-9276| Production engineer|  5|\n|    Miles|     James|891-37-2762|      Health visitor|  7|\n| Anderson|      Lisa|123-02-6786|Psychotherapist, ...|  9|\n|    Solis|   Michael|011-79-8500|Production assist...|  5|\n|   Hudson|     Maria|071-69-8159|                 Sub|  7|\n+---------+----------+-----------+--------------------+---+\nonly showing top 20 rows\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">45</span><span class=\"ansired\">]: </span>2113\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674561633E12,"submitTime":1.476674567116E12,"finishTime":1.476674562162E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4ab200de-affe-493f-85c3-0031afc0f4e5"},{"version":"CommandV1","origId":1305471881462058,"guid":"02c65b7d-a83a-4720-be4e-4df9e22ae543","subtype":"command","commandType":"auto","position":71.0,"command":"# Let's collect the even values less than 10\neven = udf(lambda s: s % 2 == 0, BooleanType())\nevenDF = lambdaDF.filter(even(lambdaDF.age))\nevenDF.show()\nevenDF.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------+-----------+-----------+--------------------+---+\n|last_name| first_name|        ssn|          occupation|age|\n+---------+-----------+-----------+--------------------+---+\n|    Green|      David|588-46-6358|Scientist, biomed...|  0|\n|    Glenn|    Derrick|337-51-5287|     Patent attorney|  6|\n|    Boyer|    Tiffany|855-14-4693|    Graphic designer|  4|\n| Williams|    Richard|430-04-3230|     Ophthalmologist|  8|\n| Campbell|    Matthew|755-53-2711|        Tree surgeon|  4|\n|    Lopez|     Collin|484-43-0522|Health and safety...|  6|\n|     Lang|    Jessica|521-20-2148|Scientist, audiol...|  4|\n| Thompson|     Carrie|465-02-5429|      Teacher, music|  2|\n|    Gross|    Madison|158-08-6750| Mental health nurse|  2|\n|   Bryant|    Charles|360-58-9234|Clinical cytogene...|  8|\n|    Nixon|    Derrick|742-70-0051|   Food technologist|  6|\n|    Jones|    Natalie|889-40-2800|Museum/gallery co...|  4|\n|    Smith|      Tracy|387-28-8771|Private music tea...|  8|\n|    Davis|      David|358-29-8499|Publishing rights...|  6|\n|   Kelley|Christopher|861-78-9237|     Records manager|  4|\n| Gallegos|     Joseph|260-65-5995|Investment banker...|  2|\n| Thompson|        Amy|311-31-7843|        Cartographer|  2|\n|Hernandez| Jacqueline|712-58-1239| Production engineer|  8|\n|    Clark|     Cheryl|573-17-4360|     Systems analyst|  8|\n|  Freeman|Christopher|627-65-3521|Engineer, manufac...|  0|\n+---------+-----------+-----------+--------------------+---+\nonly showing top 20 rows\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">46</span><span class=\"ansired\">]: </span>1022\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674565853E12,"submitTime":1.476674571337E12,"finishTime":1.47667456643E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e6122ad7-97d7-47bb-a12d-ee3fd32ca7e7"},{"version":"CommandV1","origId":1305471881462059,"guid":"0cb38ee4-2ac9-475e-8e08-77349ad20d6d","subtype":"command","commandType":"auto","position":72.0,"command":"%md\n## Part 5: Additional DataFrame actions\n\nLet's investigate some additional actions:\n\n* [first()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.first)\n* [take()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.take)\n\nOne useful thing to do when we have a new dataset is to look at the first few entries to obtain a rough idea of what information is available.  In Spark, we can do that using actions like `first()`, `take()`, and `show()`. Note that for the `first()` and `take()` actions, the elements that are returned depend on how the DataFrame is *partitioned*.\n\nInstead of using the `collect()` action, we can use the `take(n)` action to return the first _n_ elements of the DataFrame. The `first()` action returns the first element of a DataFrame, and is equivalent to `take(1)[0]`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.4711374913E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"382d6129-2348-425a-9088-89dfa5926819"},{"version":"CommandV1","origId":1305471881462060,"guid":"2d160679-5364-4455-b2ae-65c452488fd0","subtype":"command","commandType":"auto","position":73.0,"command":"print \"first: {0}\\n\".format(filteredDF.first())\n\nprint \"Four of them: {0}\\n\".format(filteredDF.take(4))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">first: Row(last_name=u&apos;Curtis&apos;, first_name=u&apos;Kristen&apos;, ssn=u&apos;688-09-1018&apos;, occupation=u&apos;Administrator, charities/voluntary organisations&apos;, age=7)\n\nFour of them: [Row(last_name=u&apos;Curtis&apos;, first_name=u&apos;Kristen&apos;, ssn=u&apos;688-09-1018&apos;, occupation=u&apos;Administrator, charities/voluntary organisations&apos;, age=7), Row(last_name=u&apos;Wood&apos;, first_name=u&apos;Jeremiah&apos;, ssn=u&apos;645-25-9468&apos;, occupation=u&apos;Librarian, academic&apos;, age=5), Row(last_name=u&apos;Green&apos;, first_name=u&apos;David&apos;, ssn=u&apos;588-46-6358&apos;, occupation=u&apos;Scientist, biomedical&apos;, age=0), Row(last_name=u&apos;Glenn&apos;, first_name=u&apos;Derrick&apos;, ssn=u&apos;337-51-5287&apos;, occupation=u&apos;Patent attorney&apos;, age=6)]\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674573525E12,"submitTime":1.476674579009E12,"finishTime":1.476674573748E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"04f48ac5-7b2f-461e-bcf2-8c78f8a0712b"},{"version":"CommandV1","origId":1305471881462061,"guid":"ee44d9f8-693a-4833-912e-1e541ec1a02b","subtype":"command","commandType":"auto","position":74.0,"command":"%md\nThis looks better:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491337E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bdf09e78-294d-4b9f-adb1-9b8a84558886"},{"version":"CommandV1","origId":1305471881462062,"guid":"d009648c-503a-450b-8afe-e019f696c19f","subtype":"command","commandType":"auto","position":75.0,"command":"display(filteredDF.take(4))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Curtis","Kristen","688-09-1018","Administrator, charities/voluntary organisations",7.0],["Wood","Jeremiah","645-25-9468","Librarian, academic",5.0],["Green","David","588-46-6358","Scientist, biomedical",0.0],["Glenn","Derrick","337-51-5287","Patent attorney",6.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"last_name","type":"\"string\""},{"name":"first_name","type":"\"string\""},{"name":"ssn","type":"\"string\""},{"name":"occupation","type":"\"string\""},{"name":"age","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674576408E12,"submitTime":1.476674581874E12,"finishTime":1.476674576816E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"836c35a2-4119-4494-938c-e7b9282a76a1"},{"version":"CommandV1","origId":1305471881462063,"guid":"742da08a-937e-4d03-9a14-f0dce12d5b59","subtype":"command","commandType":"auto","position":76.0,"command":"%md\n## Part 6: Additional DataFrame transformations","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491369E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"77adc718-f92d-407c-bf00-03c3c67f6e19"},{"version":"CommandV1","origId":1305471881462064,"guid":"1d60de73-f8e5-4f8b-aaf9-4e4f4ebdbca5","subtype":"command","commandType":"auto","position":77.0,"command":"%md\n### (6a) _orderBy_\n\n[`orderBy()`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.distinct) allows you to sort a DataFrame by one or more columns, producing a new DataFrame.\n\nFor example, let's get the first five oldest people in the original (unfiltered) DataFrame. We can use the `orderBy()` transformation. `orderBy` takes one or more columns, either as _names_ (strings) or as `Column` objects. To get a `Column` object, we use one of two notations on the DataFrame:\n\n* Pandas-style notation: `filteredDF.age`\n* Subscript notation: `filteredDF['age']`\n\nBoth of those syntaxes return a `Column`, which has additional methods like `desc()` (for sorting in descending order) or `asc()` (for sorting in ascending order, which is the default).\n\nHere are some examples:\n\n```\ndataDF.orderBy(dataDF['age'])  # sort by age in ascending order; returns a new DataFrame\ndataDF.orderBy(dataDF.last_name.desc()) # sort by last name in descending order\n```","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491389E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a97ca37f-b225-47b4-9423-6e868a5b6480"},{"version":"CommandV1","origId":557511678098401,"guid":"5855c151-b28d-4dc9-af63-f4fbe49f6bcc","subtype":"command","commandType":"auto","position":77.25,"command":"# Example, desc() is a method of Column class\n# Wrong way\ndisplay(dataDF.orderBy('age'.desc()).take(5))","commandVersion":0,"state":"error","results":null,"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;str&apos; object has no attribute &apos;desc&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-50-6cb228df619a&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Example, desc() is a method of Column class</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>display<span class=\"ansiyellow\">(</span>dataDF<span class=\"ansiyellow\">.</span>orderBy<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;age&apos;</span><span class=\"ansiyellow\">.</span>desc<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>take<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">5</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;str&apos; object has no attribute &apos;desc&apos;\n</div>","workflows":[],"startTime":1.476674863087E12,"submitTime":1.476674863087E12,"finishTime":1.476674863385E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fb370e36-aa51-418f-9af4-a4ad1e72e684"},{"version":"CommandV1","origId":557511678098402,"guid":"cd024044-a0f9-4c1d-adde-f523158ec258","subtype":"command","commandType":"auto","position":77.3125,"command":"# correct way \ndisplay(dataDF.orderBy(dataDF['age'].desc()).take(2))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Patrick","Doris","781-48-3096","Music tutor",47.0],["Estrada","Jonathon","614-72-0253","Engineer, chemical",47.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"last_name","type":"\"string\""},{"name":"first_name","type":"\"string\""},{"name":"ssn","type":"\"string\""},{"name":"occupation","type":"\"string\""},{"name":"age","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.476674933882E12,"submitTime":1.476674939285E12,"finishTime":1.476674934739E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b93d039-916f-4f8b-a91e-65cbe636d4f4"},{"version":"CommandV1","origId":1305471881462065,"guid":"1fcbc425-f5cd-4f63-aefe-058902f96347","subtype":"command","commandType":"auto","position":77.375,"command":"%md\n** Important Note**  \nsome sql functions can take either names(str), i.e, the Column name string , or Column (i.e df[col_name]) as argument. You should know when to use them properly.\n","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7bf9c0f7-818e-45fc-82d8-203c9c7958f0"},{"version":"CommandV1","origId":1305471881462066,"guid":"33de8ffc-2ed9-4834-96c0-066049d1d000","subtype":"command","commandType":"auto","position":77.5,"command":"display(dataDF.orderBy('age').take(5))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Green","David","588-46-6358","Scientist, biomedical",1.0],["Freeman","Christopher","627-65-3521","Engineer, manufacturing",1.0],["Wagner","Elizabeth","728-52-9871","Ergonomist",1.0],["Jenkins","Patricia","534-97-5524","Operational researcher",1.0],["Vargas","Kim","211-94-2444","Conservation officer, historic buildings",1.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"last_name","type":"\"string\""},{"name":"first_name","type":"\"string\""},{"name":"ssn","type":"\"string\""},{"name":"occupation","type":"\"string\""},{"name":"age","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;str&apos; object has no attribute &apos;desc&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-33-021808e7aae2&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>display<span class=\"ansiyellow\">(</span>dataDF<span class=\"ansiyellow\">.</span>orderBy<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;age&apos;</span><span class=\"ansiyellow\">.</span>desc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>take<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">5</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;str&apos; object has no attribute &apos;desc&apos;\n</div>","workflows":[],"startTime":1.476674584761E12,"submitTime":1.476674590245E12,"finishTime":1.476674586104E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7be80ffd-27dd-496a-9681-e71db3f85d6e"},{"version":"CommandV1","origId":1305471881462068,"guid":"3fe4c1f7-991c-4b01-ba1c-961ca150eab8","subtype":"command","commandType":"auto","position":78.0,"command":"# Get the five oldest people in the list. To do that, sort by age in descending order.\ndisplay(dataDF.orderBy(dataDF.age.desc()).take(5))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Patrick","Doris","781-48-3096","Music tutor",47.0],["Estrada","Jonathon","614-72-0253","Engineer, chemical",47.0],["Adams","Anne","600-21-6179","Scientist, research (life sciences)",47.0],["Stewart","Gregory","639-29-8863","Microbiologist",47.0],["Russell","Miguel","882-39-9841","Engineer, materials",47.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"last_name","type":"\"string\""},{"name":"first_name","type":"\"string\""},{"name":"ssn","type":"\"string\""},{"name":"occupation","type":"\"string\""},{"name":"age","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674950667E12,"submitTime":1.47667495616E12,"finishTime":1.476674951357E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"451d34e3-f91b-43da-bddc-349729220e6e"},{"version":"CommandV1","origId":1305471881462069,"guid":"a58fc260-dd00-43cd-acdf-7a41bd5adab5","subtype":"command","commandType":"auto","position":79.0,"command":"%md\nLet's reverse the sort order. Since ascending sort is the default, we can actually use a `Column` object expression or a simple string, in this case. The `desc()` and `asc()` methods are only defined on `Column`. Something like `orderBy('age'.desc())` would not work, because there's no `desc()` method on Python string objects. That's why we needed the column expression. But if we're just using the defaults, we can pass a string column name into `orderBy()`. This is sometimes easier to read.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491448E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"18c1403e-de39-4684-b618-c1fc59ac97ce"},{"version":"CommandV1","origId":1305471881462070,"guid":"7d59988d-50e5-4fe3-ae21-8224e2fded7d","subtype":"command","commandType":"auto","position":80.0,"command":"display(dataDF.orderBy('age').take(5))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Green","David","588-46-6358","Scientist, biomedical",1.0],["Freeman","Christopher","627-65-3521","Engineer, manufacturing",1.0],["Wagner","Elizabeth","728-52-9871","Ergonomist",1.0],["Jenkins","Patricia","534-97-5524","Operational researcher",1.0],["Vargas","Kim","211-94-2444","Conservation officer, historic buildings",1.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"last_name","type":"\"string\""},{"name":"first_name","type":"\"string\""},{"name":"ssn","type":"\"string\""},{"name":"occupation","type":"\"string\""},{"name":"age","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674954243E12,"submitTime":1.476674959736E12,"finishTime":1.476674954885E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"07664078-8388-4d8a-a036-76fb2f18a6ed"},{"version":"CommandV1","origId":1305471881462071,"guid":"1c080b48-71ef-4b79-b923-cc27a90872a1","subtype":"command","commandType":"auto","position":81.0,"command":"%md\n### (6b) _distinct_ and _dropDuplicates_\n\n[`distinct()`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.distinct) filters out duplicate rows, and it considers all columns. Since our data is completely randomly generated (by `fake-factory`), it's extremely unlikely that there are any duplicate rows:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491482E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ca7418c7-4ede-47ba-bc0a-8d51f3bd29ad"},{"version":"CommandV1","origId":1305471881462072,"guid":"86b902b2-8b55-4336-a9bd-b460c3fab963","subtype":"command","commandType":"auto","position":82.0,"command":"print dataDF.count()\nprint dataDF.distinct().count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">10000\n10000\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674959426E12,"submitTime":1.47667496492E12,"finishTime":1.476674960638E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a151d2d8-4b74-4afd-983e-32ab41bf3d27"},{"version":"CommandV1","origId":1305471881462073,"guid":"670f6efb-9d71-42b5-a4ba-677fe0cd4845","subtype":"command","commandType":"auto","position":83.0,"command":"%md\nTo demonstrate `distinct()`, let's create a quick throwaway dataset.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491513E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"88d5efe3-a471-4ead-b911-07a8d8a204ae"},{"version":"CommandV1","origId":1305471881462074,"guid":"12972c1c-8e00-4fb4-abc5-05dcf668fc13","subtype":"command","commandType":"auto","position":84.0,"command":"tempDF = sqlContext.createDataFrame([(\"Joe\", 1), (\"Joe\", 1), (\"Anna\", 15), (\"Anna\", 12), (\"Ravi\", 5)], ('name', 'score'))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674967696E12,"submitTime":1.476674973189E12,"finishTime":1.476674967768E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3ebbc4c1-d312-4e13-be4c-a15f87388b9d"},{"version":"CommandV1","origId":1305471881462075,"guid":"beb940b2-e726-44db-b0b4-5f93fcf8fc87","subtype":"command","commandType":"auto","position":85.0,"command":"tempDF.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+----+-----+\n|name|score|\n+----+-----+\n| Joe|    1|\n| Joe|    1|\n|Anna|   15|\n|Anna|   12|\n|Ravi|    5|\n+----+-----+\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674969321E12,"submitTime":1.476674974815E12,"finishTime":1.476674969544E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cac68a8d-2ceb-464d-9277-50002f8a6582"},{"version":"CommandV1","origId":1305471881462076,"guid":"6c576018-7ef8-49fa-9396-e850213100cb","subtype":"command","commandType":"auto","position":86.0,"command":"tempDF.distinct().show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+----+-----+\n|name|score|\n+----+-----+\n|Ravi|    5|\n|Anna|   12|\n|Anna|   15|\n| Joe|    1|\n+----+-----+\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674973195E12,"submitTime":1.476674978669E12,"finishTime":1.476674973769E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"52c13470-268b-46cf-acd1-0db5de97f980"},{"version":"CommandV1","origId":1305471881462077,"guid":"63079df9-4042-4760-a1a8-ce991a062fda","subtype":"command","commandType":"auto","position":87.0,"command":"%md\nNote that one of the (\"Joe\", 1) rows was deleted, but both rows with name \"Anna\" were kept, because all columns in a row must match another row for it to be considered a duplicate.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491567E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a0be22b3-0ce7-4b38-924b-864d46bb290f"},{"version":"CommandV1","origId":1305471881462078,"guid":"f41e5d04-fde4-49e1-98e1-2f51bb9c9099","subtype":"command","commandType":"auto","position":88.0,"command":"%md\n[`dropDuplicates()`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.dropDuplicates) is like `distinct()`, except that it allows us to specify the columns to compare. For instance, we can use it to drop all rows where the first name and last name duplicates (ignoring the occupation and age columns).","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491589E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"301a2e09-9a4a-461a-91d9-ea2636439972"},{"version":"CommandV1","origId":1305471881462079,"guid":"d4d3f965-c4c4-4d0a-ba4d-8cfb2e0b5035","subtype":"command","commandType":"auto","position":89.0,"command":"print dataDF.count()\nprint dataDF.dropDuplicates(['first_name', 'last_name']).count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">10000\n9331\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674976621E12,"submitTime":1.476674982096E12,"finishTime":1.47667497773E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4530ba0a-37db-4f31-99f8-4c4cd29201e1"},{"version":"CommandV1","origId":1305471881462080,"guid":"5ae6d59a-cf8f-4b14-b29c-7ecfaf54976a","subtype":"command","commandType":"auto","position":90.0,"command":"%md\n### (6c) _drop_\n\n[`drop()`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.drop) is like the opposite of `select()`: Instead of selecting specific columns from a DataFrame, it drops a specifed column from a DataFrame.\n\nHere's a simple use case: Suppose you're reading from a 1,000-column CSV file, and you have to get rid of five of the columns. Instead of selecting 995 of the columns, it's easier just to drop the five you don't want.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491624E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"08165dec-9840-44de-b411-4bb845a69b2e"},{"version":"CommandV1","origId":1305471881462081,"guid":"a35925b2-c771-46d9-ba4a-e8c0b90b68d2","subtype":"command","commandType":"auto","position":91.0,"command":"dataDF.drop('occupation').drop('age').show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+---------+-----------+-----------+\n|last_name| first_name|        ssn|\n+---------+-----------+-----------+\n|   Curtis|    Kristen|688-09-1018|\n| Richards|      David|201-66-6752|\n|   Parker|Christopher|784-44-1690|\n|     Wood|   Jeremiah|645-25-9468|\n|    Arias|     Sandra|460-22-4420|\n|    Green|      David|588-46-6358|\n|    Glenn|    Derrick|337-51-5287|\n|    Evans|       Leah|163-56-3569|\n|   Snyder|       Tara|842-77-4305|\n|   Miller|    Tiffany|527-33-8046|\n|    Boyer|    Tiffany|855-14-4693|\n|    Mills|      Kevin|701-33-5126|\n|    Glenn|      Karen|894-73-1777|\n|    Brady|   Patricia|175-38-4379|\n|   Juarez|       Kyle|612-98-0866|\n|   Cooper|  Catherine|245-56-5385|\n|   Nelson|       John|732-19-3869|\n|   Taylor|      Jamie|189-24-2509|\n|     Reed|      James|508-63-4298|\n| Williams|    Richard|430-04-3230|\n+---------+-----------+-----------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674980227E12,"submitTime":1.476674985721E12,"finishTime":1.476674980349E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6293fe1d-29c8-4151-ad1b-0d51a9ca90be"},{"version":"CommandV1","origId":1305471881462082,"guid":"40750592-2d77-4c91-b112-526071d4f371","subtype":"command","commandType":"auto","position":92.0,"command":"%md\n### (6d) _groupBy_\n\n[`groupBy()`]((http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.groupBy) is one of the most powerful transformations. It allows you to perform aggregations on a DataFrame.\n\nUnlike other DataFrame transformations, `groupBy()` does _not_ return a DataFrame. Instead, it returns a special [GroupedData](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData) object that contains various aggregation functions.\n\nThe most commonly used aggregation function is [count()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.count),\nbut there are others (like [sum()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.sum), [max()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.max), and [avg()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.avg).\n\nThese aggregation functions typically create a new column and return a new DataFrame.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491654E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ae4a7081-dc4c-4f6e-b240-2d1a53a0e40c"},{"version":"CommandV1","origId":1305471881462083,"guid":"cb145880-bee6-4aa7-aa2f-305103469976","subtype":"command","commandType":"auto","position":93.0,"command":"dataDF.groupBy('occupation').count().show(truncate=False)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+------------------------------------+-----+\n|occupation                          |count|\n+------------------------------------+-----+\n|Politician&apos;s assistant              |25   |\n|Public relations officer            |11   |\n|Operational researcher              |17   |\n|Textile designer                    |20   |\n|Personal assistant                  |12   |\n|Agricultural engineer               |13   |\n|Physiological scientist             |15   |\n|Waste management officer            |26   |\n|Geoscientist                        |18   |\n|Engineer, materials                 |10   |\n|Counselling psychologist            |21   |\n|Housing manager/officer             |15   |\n|Hotel manager                       |11   |\n|Outdoor activities/education manager|17   |\n|Therapist, music                    |17   |\n|Fitness centre manager              |26   |\n|Programmer, systems                 |23   |\n|Theatre stage manager               |18   |\n|Fish farm manager                   |21   |\n|Dealer                              |13   |\n+------------------------------------+-----+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674984929E12,"submitTime":1.476674990423E12,"finishTime":1.476674985406E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"410eb2aa-4365-485e-b465-952db7ea86d3"},{"version":"CommandV1","origId":1305471881462084,"guid":"dd8ff71d-1405-4fda-9be8-0caf31d476e1","subtype":"command","commandType":"auto","position":94.0,"command":"dataDF.groupBy().avg('age').show(truncate=False)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+--------+\n|avg(age)|\n+--------+\n|23.9545 |\n+--------+\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674988808E12,"submitTime":1.476674994301E12,"finishTime":1.476674989081E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7395614f-bdd4-4c9c-b84b-01382fd49aab"},{"version":"CommandV1","origId":1305471881462085,"guid":"c1e7664d-0fd0-40ee-ac9d-c15232fba51b","subtype":"command","commandType":"auto","position":95.0,"command":"%md\nWe can also use `groupBy()` to do aother useful aggregations:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491697E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"311b768c-a83e-42f2-b12a-a1df471c22fd"},{"version":"CommandV1","origId":1305471881462086,"guid":"e13171fc-00a7-4bad-90d0-af58ad248ce5","subtype":"command","commandType":"auto","position":96.0,"command":"print \"Maximum age: {0}\".format(dataDF.groupBy().max('age').first()[0])\nprint \"Minimum age: {0}\".format(dataDF.groupBy().min('age').first()[0])","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Maximum age: 47\nMinimum age: 1\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674991013E12,"submitTime":1.476674996489E12,"finishTime":1.476674991337E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"32ea4a84-5f34-4f90-822a-d3fe6ac60407"},{"version":"CommandV1","origId":1305471881462087,"guid":"44af23ca-ca4a-473b-89a9-bf44bf998e23","subtype":"command","commandType":"auto","position":97.0,"command":"%md\n### (6e) _sample_ (optional)\n\nWhen analyzing data, the [`sample()`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sample) transformation is often quite useful. It returns a new DataFrame with a random sample of elements from the dataset.  It takes in a `withReplacement` argument, which specifies whether it is okay to randomly pick the same item multiple times from the parent DataFrame (so when `withReplacement=True`, you can get the same item back multiple times). It takes in a `fraction` parameter, which specifies the fraction elements in the dataset you want to return. (So a `fraction` value of `0.20` returns 20% of the elements in the DataFrame.) It also takes an optional `seed` parameter that allows you to specify a seed value for the random number generator, so that reproducible results can be obtained.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491908E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"697e06e7-a6fe-4a03-af18-5d7166f49a0e"},{"version":"CommandV1","origId":1305471881462088,"guid":"401f0722-fa58-4740-a03d-f3d81ba2cee1","subtype":"command","commandType":"auto","position":98.0,"command":"sampledDF = dataDF.sample(withReplacement=False, fraction=0.10)\nprint sampledDF.count()\nsampledDF.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1030\n+---------+----------+-----------+--------------------+---+\n|last_name|first_name|        ssn|          occupation|age|\n+---------+----------+-----------+--------------------+---+\n| Richards|     David|201-66-6752|   Building surveyor| 24|\n|  William|       Dr.|603-84-8464| Call centre manager| 34|\n|   Howard|     Erika|199-19-3835|Rural practice su...| 15|\n|      Lee|    Rodney|302-24-1795|  Veterinary surgeon| 30|\n|    Myers|     Paula|025-56-5469|Research scientis...| 25|\n|   Kramer|   Shannon|291-73-3440|             Surgeon|  6|\n|  Elliott|     Duane|359-64-0476|  Restaurant manager| 33|\n|  Johnson|    Ashley|707-27-2864|    Industrial buyer| 43|\n|  Simmons|   Timothy|154-10-8220|Programmer, appli...| 18|\n|    Young|     Craig|068-45-9639|Psychologist, cli...|  4|\n|     Mann|      Mark|558-40-9113|Education officer...| 27|\n|     Hunt|   Patrick|101-72-0975|      Therapist, art| 44|\n|  Schultz|   Whitney|227-48-8117|Engineer, mainten...| 18|\n|    Patel|     Keith|207-79-4285|   Probation officer| 22|\n|   Nelson|     Erika|222-91-9492|Designer, blown g...| 26|\n|    Davis|      Leah|895-59-6262|Environmental con...| 38|\n|    Mcgee|     Brian|613-36-4485|Engineer, control...| 46|\n|   Wilson|    Robert|657-46-9119|Broadcast journalist| 36|\n|       Le|     Laura|467-14-0692|Government social...| 44|\n|    Foley|     Danny|257-05-0070|         Pathologist| 16|\n+---------+----------+-----------+--------------------+---+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674994659E12,"submitTime":1.476675000153E12,"finishTime":1.476674994933E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"05ecd8fe-a34c-41e2-8b73-a8fe092d9a5d"},{"version":"CommandV1","origId":1305471881462089,"guid":"a8c2dd68-c533-4d1c-ab38-8d1422d710b3","subtype":"command","commandType":"auto","position":99.0,"command":"print dataDF.sample(withReplacement=False, fraction=0.05).count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">516\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674996309E12,"submitTime":1.476675001784E12,"finishTime":1.476674996532E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0768bf13-3742-4d63-9025-b3c15cbfecf1"},{"version":"CommandV1","origId":1305471881462090,"guid":"6b668d4b-f4a8-42be-989a-04f76a11c650","subtype":"command","commandType":"auto","position":100.0,"command":"%md\n## Part 7: Caching DataFrames and storage options","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137491978E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c749966b-9a7c-4cff-91f1-f010f2cb11d3"},{"version":"CommandV1","origId":1305471881462091,"guid":"574020ca-d6f3-42a0-a58a-316a05845f0e","subtype":"command","commandType":"auto","position":101.0,"command":"%md\n### (7a) Caching DataFrames\n\nFor efficiency Spark keeps your DataFrames in memory. (More formally, it keeps the _RDDs_ that implement your DataFrames in memory.) By keeping the contents in memory, Spark can quickly access the data. However, memory is limited, so if you try to keep too many partitions in memory, Spark will automatically delete partitions from memory to make space for new ones. If you later refer to one of the deleted partitions, Spark will automatically recreate it for you, but that takes time.\n\nSo, if you plan to use a DataFrame more than once, then you should tell Spark to cache it. You can use the `cache()` operation to keep the DataFrame in memory. However, you must still trigger an action on the DataFrame, such as `collect()` or `count()` before the caching will occur. In other words, `cache()` is lazy: It merely tells Spark that the DataFrame should be cached _when the data is materialized_. You have to run an action to materialize the data; the DataFrame will be cached as a side effect. The next time you use the DataFrame, Spark will use the cached data, rather than recomputing the DataFrame from the original data.\n\nYou can see your cached DataFrame in the \"Storage\" section of the Spark web UI. If you click on the name value, you can see more information about where the the DataFrame is stored.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137492007E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b9f146a2-bb1f-4c74-ab9a-991e5abd2d28"},{"version":"CommandV1","origId":1305471881462092,"guid":"42f3001a-44f3-4ca9-823f-88789f3c8a6e","subtype":"command","commandType":"auto","position":102.0,"command":"# Cache the DataFrame\nfilteredDF.cache()\n# Trigger an action\nprint filteredDF.count()\n# Check if it is cached\nprint filteredDF.is_cached","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">2113\nTrue\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476674998722E12,"submitTime":1.476675004216E12,"finishTime":1.476674999105E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3093b911-a392-4173-9110-1020d256c3d3"},{"version":"CommandV1","origId":1305471881462093,"guid":"c4fcddf2-d011-4aa9-a426-e62b00ac227a","subtype":"command","commandType":"auto","position":103.0,"command":"%md\n### (7b) Unpersist and storage options\n\nSpark automatically manages the partitions cached in memory. If it has more partitions than available memory, by default, it will evict older partitions to make room for new ones. For efficiency, once you are finished using cached DataFrame, you can optionally tell Spark to stop caching it in memory by using the DataFrame's `unpersist()` method to inform Spark that you no longer need the cached data.\n\n** Advanced: ** Spark provides many more options for managing how DataFrames cached. For instance, you can tell Spark to spill cached partitions to disk when it runs out of memory, instead of simply throwing old ones away. You can explore the API for DataFrame's [persist()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.persist) operation using Python's [help()](https://docs.python.org/2/library/functions.html?highlight=help#help) command.  The `persist()` operation, optionally, takes a pySpark [StorageLevel](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.StorageLevel) object.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137492049E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ec1eafa4-b780-4730-af98-736f556bc2ac"},{"version":"CommandV1","origId":1305471881462094,"guid":"1a5a953a-affa-4db3-ae22-c425752dbaa0","subtype":"command","commandType":"auto","position":104.0,"command":"# If we are done with the DataFrame we can unpersist it so that its memory can be reclaimed\nfilteredDF.unpersist()\n# Check if it is cached\nprint filteredDF.is_cached","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">False\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476675003187E12,"submitTime":1.476675008661E12,"finishTime":1.476675003228E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"90775bc6-cabb-4785-9dff-731c9ed2eeca"},{"version":"CommandV1","origId":1305471881462095,"guid":"40be8be6-8248-469d-a758-e871ecb70130","subtype":"command","commandType":"auto","position":105.0,"command":"%md\n## ** Part 8: Debugging Spark applications and lazy evaluation **","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137492095E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"eb2b10e3-8cbf-4df1-a8c1-f30921a4c519"},{"version":"CommandV1","origId":1305471881462096,"guid":"9673a1b1-6619-4ad5-9568-0e730a6ca3de","subtype":"command","commandType":"auto","position":106.0,"command":"%md\n### How Python is Executed in Spark\n\nInternally, Spark executes using a Java Virtual Machine (JVM). pySpark runs Python code in a JVM using [Py4J](http://py4j.sourceforge.net). Py4J enables Python programs running in a Python interpreter to dynamically access Java objects in a Java Virtual Machine. Methods are called as if the Java objects resided in the Python interpreter and Java collections can be accessed through standard Python collection methods. Py4J also enables Java programs to call back Python objects.\n\nBecause pySpark uses Py4J, coding errors often result in a complicated, confusing stack trace that can be difficult to understand. In the following section, we'll explore how to understand stack traces.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137492126E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1c99cd66-f751-46d3-833d-c1a1a3e9ae77"},{"version":"CommandV1","origId":1305471881462097,"guid":"490265cf-c29f-4dd0-999f-39e10d8fe6b9","subtype":"command","commandType":"auto","position":107.0,"command":"%md\n### (8a) Challenges with lazy evaluation using transformations and actions\n\nSpark's use of lazy evaluation can make debugging more difficult because code is not always executed immediately. To see an example of how this can happen, let's first define a broken filter function.\nNext we perform a `filter()` operation using the broken filtering function.  No error will occur at this point due to Spark's use of lazy evaluation.\n\nThe `filter()` method will not be executed *until* an action operation is invoked on the DataFrame.  We will perform an action by using the `count()` method to return a list that contains all of the elements in this DataFrame.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47113749215E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"69b6ff8d-6821-4870-9178-a1a39fe01759"},{"version":"CommandV1","origId":1305471881462098,"guid":"edf11d4b-081e-496a-9ed2-eaf04648720e","subtype":"command","commandType":"auto","position":108.0,"command":"def brokenTen(value):\n    \"\"\"Incorrect implementation of the ten function.\n\n    Note:\n        The `if` statement checks an undefined variable `val` instead of `value`.\n\n    Args:\n        value (int): A number.\n\n    Returns:\n        bool: Whether `value` is less than ten.\n\n    Raises:\n        NameError: The function references `val`, which is not available in the local or global\n            namespace, so a `NameError` is raised.\n    \"\"\"\n    if (val < 10):\n        return True\n    else:\n        return False\n\nbtUDF = udf(brokenTen)\nbrokenDF = subDF.filter(btUDF(subDF.age) == True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476675006724E12,"submitTime":1.476675012217E12,"finishTime":1.476675006797E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4c1cd4cd-ea76-4fb7-be37-93503bad4d36"},{"version":"CommandV1","origId":1305471881462099,"guid":"db8b3e3a-651f-431b-b11f-b258ea5fe31e","subtype":"command","commandType":"auto","position":109.0,"command":"# Now we'll see the error\n# Click on the `+` button to expand the error and scroll through the message.\nbrokenDF.count()","commandVersion":0,"state":"error","results":null,"errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 89.0 failed 1 times, most recent failure: Lost task 3.0 in stage 89.0 (TID 1135, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-69-451d05cfceb7&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Now we&apos;ll see the error</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansired\"># Click on the &#96;+&#96; button to expand the error and scroll through the message.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>brokenDF<span class=\"ansiyellow\">.</span>count<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.pyc</span> in <span class=\"ansicyan\">count</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">    267</span>         <span class=\"ansicyan\">2</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    268</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 269</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> int<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>count<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    270</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    271</span>     <span class=\"ansiyellow\">@</span>ignore_unicode_prefix<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">    811</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    812</span>         return_value = get_return_value(\n<span class=\"ansigreen\">--&gt; 813</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">    814</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    815</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.pyc</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     43</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     44</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 45</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     46</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     47</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.9-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    306</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    307</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 308</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    309</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    310</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o840.count.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 89.0 failed 1 times, most recent failure: Lost task 3.0 in stage 89.0 (TID 1135, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 111, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/serializers.py&quot;, line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File &quot;/databricks/spark/python/pyspark/sql/functions.py&quot;, line 1563, in &lt;lambda&gt;\n    func = lambda _, it: map(lambda x: returnType.toInternal(f(*x)), it)\n  File &quot;&lt;ipython-input-67-b6d72c054939&gt;&quot;, line 17, in brokenTen\nNameError: global name &apos;val&apos; is not defined\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.&lt;init&gt;(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.sql.execution.BatchPythonEvaluation$$anonfun$doExecute$1.apply(python.scala:405)\n\tat org.apache.spark.sql.execution.BatchPythonEvaluation$$anonfun$doExecute$1.apply(python.scala:370)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:46)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:235)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1863)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1934)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:166)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectPublic(SparkPlan.scala:174)\n\tat org.apache.spark.sql.DataFrame$$anonfun$org$apache$spark$sql$DataFrame$$execute$1$1.apply(DataFrame.scala:1499)\n\tat org.apache.spark.sql.DataFrame$$anonfun$org$apache$spark$sql$DataFrame$$execute$1$1.apply(DataFrame.scala:1499)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)\n\tat org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:2086)\n\tat org.apache.spark.sql.DataFrame.org$apache$spark$sql$DataFrame$$execute$1(DataFrame.scala:1498)\n\tat org.apache.spark.sql.DataFrame.org$apache$spark$sql$DataFrame$$collect(DataFrame.scala:1505)\n\tat org.apache.spark.sql.DataFrame$$anonfun$count$1.apply(DataFrame.scala:1515)\n\tat org.apache.spark.sql.DataFrame$$anonfun$count$1.apply(DataFrame.scala:1514)\n\tat org.apache.spark.sql.DataFrame.withCallback(DataFrame.scala:2099)\n\tat org.apache.spark.sql.DataFrame.count(DataFrame.scala:1514)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 111, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/serializers.py&quot;, line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File &quot;/databricks/spark/python/pyspark/sql/functions.py&quot;, line 1563, in &lt;lambda&gt;\n    func = lambda _, it: map(lambda x: returnType.toInternal(f(*x)), it)\n  File &quot;&lt;ipython-input-67-b6d72c054939&gt;&quot;, line 17, in brokenTen\nNameError: global name &apos;val&apos; is not defined\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.&lt;init&gt;(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.sql.execution.BatchPythonEvaluation$$anonfun$doExecute$1.apply(python.scala:405)\n\tat org.apache.spark.sql.execution.BatchPythonEvaluation$$anonfun$doExecute$1.apply(python.scala:370)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:46)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:235)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n\n</div>","workflows":[],"startTime":1.476675040777E12,"submitTime":1.476675040777E12,"finishTime":1.47667504119E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fa916c1d-8ac7-4221-b202-82bd8d4e6f30"},{"version":"CommandV1","origId":1305471881462100,"guid":"06c7291b-7701-4bb3-a805-b15ebefefa07","subtype":"command","commandType":"auto","position":110.0,"command":"%md\n### (8b) Finding the bug\n\nWhen the `filter()` method is executed, Spark calls the UDF. Since our UDF has an error in the underlying filtering function `brokenTen()`, an error occurs.\n\nScroll through the output \"Py4JJavaError     Traceback (most recent call last)\" part of the cell and first you will see that the line that generated the error is the `count()` method line. There is *nothing wrong with this line*. However, it is an action and that caused other methods to be executed. Continue scrolling through the Traceback and you will see the following error line:\n\n`NameError: global name 'val' is not defined`\n\nLooking at this error line, we can see that we used the wrong variable name in our filtering function `brokenTen()`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137492216E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5b0bde53-fe4e-4b25-84ba-69e2267e2a90"},{"version":"CommandV1","origId":1305471881462101,"guid":"60b1f8e7-d8c9-4377-9674-9bb5423c2ef1","subtype":"command","commandType":"auto","position":111.0,"command":"%md\n### (8c) Moving toward expert style\n\nAs you are learning Spark, I recommend that you write your code in the form:\n```\n    df2 = df1.transformation1()\n    df2.action1()\n    df3 = df2.transformation2()\n    df3.action2()\n```\nUsing this style will make debugging your code much easier as it makes errors easier to localize - errors in your transformations will occur when the next action is executed.\n\nOnce you become more experienced with Spark, you can write your code with the form: `df.transformation1().transformation2().action()`\n\nWe can also use `lambda()` functions instead of separately defined functions when their use improves readability and conciseness.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47113749224E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ee4469db-ca6e-4493-83d5-16834013e887"},{"version":"CommandV1","origId":1305471881462102,"guid":"32374dbb-e85f-4c4b-93b6-e80dd572e3d4","subtype":"command","commandType":"auto","position":112.0,"command":"# Cleaner code through lambda use\nmyUDF = udf(lambda v: v < 10)\nsubDF.filter(myUDF(subDF.age) == True)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">70</span><span class=\"ansired\">]: </span>DataFrame[last_name: string, first_name: string, ssn: string, occupation: string, age: bigint]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476675041871E12,"submitTime":1.476675047365E12,"finishTime":1.476675041912E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ce141b68-1dc5-4066-921b-693ddba718a5"},{"version":"CommandV1","origId":1305471881462103,"guid":"c4338bbe-f75d-4cde-be8d-fc1273ed8268","subtype":"command","commandType":"auto","position":113.0,"command":"%md\n### (8d) Readability and code style\n\nTo make the expert coding style more readable, enclose the statement in parentheses and put each method, transformation, or action on a separate line.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.471137492286E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4fca68ee-abde-4c65-b400-7ca4422feafe"},{"version":"CommandV1","origId":1305471881462104,"guid":"f2b95987-0f53-405d-b2b7-578c1bdb4e85","subtype":"command","commandType":"auto","position":114.0,"command":"# Final version\nfrom pyspark.sql.functions import *\n(dataDF\n .filter(dataDF.age > 20)\n .select(concat(dataDF.first_name, lit(' '), dataDF.last_name), dataDF.occupation)\n .show(truncate=False)\n )","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+------------------------------+----------------------------------+\n|concat(first_name, ,last_name)|occupation                        |\n+------------------------------+----------------------------------+\n|David Richards                |Building surveyor                 |\n|Sandra Arias                  |Engineer, electrical              |\n|Leah Evans                    |Pharmacist, hospital              |\n|Tara Snyder                   |Administrator, education          |\n|Kevin Mills                   |Engineer, water                   |\n|Karen Glenn                   |Investment banker, corporate      |\n|Patricia Brady                |Mudlogger                         |\n|Kyle Juarez                   |Market researcher                 |\n|Jamie Taylor                  |Tourist information centre manager|\n|Mrs. Kathryn                  |Scientific laboratory technician  |\n|Scott Stephens                |Patent attorney                   |\n|Norma Johnson                 |Horticultural therapist           |\n|Dr. William                   |Call centre manager               |\n|Lisa Lee                      |Clinical embryologist             |\n|Doris Patrick                 |Music tutor                       |\n|Tina Hanson                   |Petroleum engineer                |\n|Cynthia Lopez                 |Engineer, structural              |\n|Mary Vargas                   |Research scientist (life sciences)|\n|Brandon Hines                 |Landscape architect               |\n|Cesar Lawrence                |Educational psychologist          |\n+------------------------------+----------------------------------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1.476675045031E12,"submitTime":1.476675050526E12,"finishTime":1.476675045204E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c25ff85c-474f-48b9-ade2-a1c6f29ffda6"}],"dashboards":[],"guid":"4f42dc31-9ac2-4e1a-9d17-c3aae6141b5b","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
